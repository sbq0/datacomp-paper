<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>DataComp:
In search of the next generation of multimodal datasets</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="main.tex"> 
<link rel="stylesheet" type="text/css" href="main.css"> 
</head><body 
>
<!--l. 212--><p class="noindent" ><a 
 id="x1-2f0"></a><span class="footnote-mark"><a 
 id="fn0x0">  <sup class="textsuperscript"><sup>*</sup></sup></a></span><span 
class="ecrm-0900">Equal contribution, randomly ordered. Correspondence to </span><a 
href="contact@datacomp.ai" class="url" ><span 
class="ectt-0900">contact@datacomp.ai</span></a><span 
class="ecrm-0900">.</span> <sup><span 
class="cmr-6">1</span></sup><span 
class="ecrm-0900">University of Washington</span>
<sup><span 
class="cmr-6">2</span></sup><span 
class="ecrm-0900">Columbia University</span> <sup><span 
class="cmr-6">3</span></sup><span 
class="ecrm-0900">Tel Aviv University</span> <sup><span 
class="cmr-6">4</span></sup><span 
class="ecrm-0900">Apple</span> <sup><span 
class="cmr-6">5</span></sup><span 
class="ecrm-0900">UT Austin</span> <sup><span 
class="cmr-6">6</span></sup><span 
class="ecrm-0900">LAION</span> <sup><span 
class="cmr-6">7</span></sup><span 
class="ecrm-0900">AI2</span> <sup><span 
class="cmr-6">8</span></sup><span 
class="ecrm-0900">Juelich Supercomputing Center,</span>
<span 
class="ecrm-0900">Research Center Juelich</span> <sup><span 
class="cmr-6">9</span></sup><span 
class="ecrm-0900">University of Illinois Urbana-Champaign</span> <sup><span 
class="cmr-6">10</span></sup><span 
class="ecrm-0900">Graz University of Technology</span> <sup><span 
class="cmr-6">11</span></sup><span 
class="ecrm-0900">Hebrew</span>
<span 
class="ecrm-0900">University.</span>
<div class="maketitle">
                                                                                         
                                                                                         
                                                                                         
                                                                                         

<h2 class="titleHead">datacomp:<br />
In search of the next generation of multimodal datasets</h2>
 <div class="author" > Samir Yitzhak Gadre*<span 
class="cmr-8">2</span>    Gabriel Ilharco*<span 
class="cmr-8">1</span>    Alex Fang*<span 
class="cmr-8">1</span>    Jonathan Hayase<span 
class="cmr-8">1</span>    Georgios Smyrnis<span 
class="cmr-8">5</span>
<br />    Thao Nguyen<span 
class="cmr-8">1</span>     Ryan Marten<span 
class="cmr-8">7</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">9</span>     Mitchell Wortsman<span 
class="cmr-8">1</span>     Dhruba Ghosh<span 
class="cmr-8">1</span>     Jieyu Zhang<span 
class="cmr-8">1</span>
<br />     Eyal Orgad<span 
class="cmr-8">3</span>     Rahim Entezari<span 
class="cmr-8">10</span>     Giannis Daras<span 
class="cmr-8">5</span>     Sarah Pratt<span 
class="cmr-8">1</span>     Vivek Ramanujan<span 
class="cmr-8">1</span>
<br />         Yonatan Bitton<span 
class="cmr-8">11</span>     Kalyani Marathe<span 
class="cmr-8">1</span>     Stephen Mussmann<span 
class="cmr-8">1</span>     Richard Vencu<span 
class="cmr-8">6</span>
<br />    Mehdi Cherti<span 
class="cmr-8">6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">8</span>     Ranjay Krishna<span 
class="cmr-8">1</span>     Pang Wei Koh<span 
class="cmr-8">1</span>     Olga Saukh<span 
class="cmr-8">10</span>     Alexander Ratner<span 
class="cmr-8">1</span>
<br />          Shuran Song<span 
class="cmr-8">2</span>     Hannaneh Hajishirzi<span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">7</span>     Ali Farhadi<span 
class="cmr-8">1</span>     Romain Beaumont<span 
class="cmr-8">6</span>
<br />                   Sewoong Oh<span 
class="cmr-8">1</span>     Alexandros G. Dimakis<span 
class="cmr-8">5</span>     Jenia Jitsev<span 
class="cmr-8">6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">8</span>
<br />                   Yair Carmon<span 
class="cmr-8">3</span>     Vaishaal Shankar<span 
class="cmr-8">4</span>     Ludwig Schmidt<span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">7</span> </div>
<br />
<div class="date" ></div>
</div><div 
class="abstract" 
>
<div class="center" 
>
<!--l. 219--><p class="noindent" >
<!--l. 219--><p class="noindent" ><span 
class="ecbx-1000">Abstract</span></div>
     <!--l. 220--><p class="indent" >    <span 
class="ecrm-1000">Large multimodal datasets have been instrumental in recent breakthroughs such as CLIP,</span>
     <span 
class="ecrm-1000">Stable  Diffusion,  and  GPT-4.  At  the  same  time,  datasets  rarely  receive  the  same  research</span>
     <span 
class="ecrm-1000">attention as model architectures or training algorithms. To address this shortcoming in the</span>
     <span 
class="ecrm-1000">machine learning ecosystem, we introduce </span><span 
class="eccc1000-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span><span 
class="ecrm-1000">, a participatory benchmark where the</span>
     <span 
class="ecrm-1000">training  code  is  fixed  and  researchers  innovate  by  proposing  new  training  sets.  Concretely,</span>
     <span 
class="ecrm-1000">we provide a testbed for dataset experiments centered around a new candidate pool of 12.8B</span>
     <span 
class="ecrm-1000">image-text  pairs  from  Common  Crawl.  Participants  in  our  benchmark  design  new  filtering</span>
     <span 
class="ecrm-1000">techniques or curate new data sources and then evaluate their new dataset by running our</span>
     <span 
class="ecrm-1000">standardized CLIP training code and testing the resulting model on 38 downstream test sets.</span>
     <span 
class="ecrm-1000">Our benchmark consists of multiple scales, with four candidate pool sizes and associated compute</span>
     <span 
class="ecrm-1000">budgets ranging from 12.8M to 12.8B samples seen during training. This multi-scale design</span>
     <span 
class="ecrm-1000">facilitates the study of scaling trends and makes the benchmark accessible to researchers with</span>
     <span 
class="ecrm-1000">varying resources.</span>
     <!--l. 228--><p class="indent" >     <span 
class="ecrm-1000">Our baseline experiments show that the </span><span 
class="eccc1000-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span><span 
class="ecrm-1000">workflow is a promising direction for</span>
     <span 
class="ecrm-1000">improving multimodal datasets. We introduce </span><span 
class="eccc1000-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span><span 
class="ecrm-1000">-1B, a dataset created using a simple</span>
     <span 
class="ecrm-1000">filtering  algorithm  applied  to  the  12.8B  candidate  pool.  The  resulting  1.4B  subset  enables</span>
                                                                                         
                                                                                         
     <span 
class="ecrm-1000">training a CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet. Our new</span>
     <span 
class="ecrm-1000">ViT-L/14 model outperforms a larger ViT-g/14 trained on LAION-2B by 0.7 percentage points</span>
     <span 
class="ecrm-1000">while requiring </span><span 
class="cmr-10">9</span><span 
class="cmsy-10">&#x00D7; </span><span 
class="ecrm-1000">less compute during training. We also outperform OpenAI&#8217;s CLIP ViT-L/14</span>
     <span 
class="ecrm-1000">by 3.7 percentage points, which is trained with the same compute budget as our model. These</span>
     <span 
class="ecrm-1000">gains highlight the potential for improving model performance by carefully curating training</span>
     <span 
class="ecrm-1000">sets. We view </span><span 
class="eccc1000-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span><span 
class="ecrm-1000">-1B as only the first step and hope that </span><span 
class="eccc1000-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span><span 
class="ecrm-1000">paves the way</span>
     <span 
class="ecrm-1000">toward the next generation of multimodal datasets.</span>
     <!--l. 236--><p class="indent" >     <span 
class="ecrm-1000">We publicly release our datasets, associated tooling, filtering baselines, and our code for</span>
     <span 
class="ecrm-1000">training and evaluating models at </span><a 
href="www.datacomp.ai" class="url" ><span 
class="ectt-1000">www.datacomp.ai</span></a><span 
class="ecrm-1000">.</span>
</div>
<h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-10001"></a>Introduction</h3>
<!--l. 244--><p class="noindent" >The past two years have seen multiple breakthroughs in multimodal learning. A new family of models
including CLIP&#x00A0;[<a 
href="#Xradford2021learning">104</a>], DALL-E&#x00A0;[<a 
href="#Xramesh2021zero">108</a>,&#x00A0;<a 
href="#Xramesh2022hierarchical">109</a>], Stable Diffusion&#x00A0;[<a 
href="#Xrombach2022high">116</a>], Flamingo&#x00A0;[<a 
href="#Xalayrac2022flamingo">4</a>], and GPT-4&#x00A0;[<a 
href="#Xgpt4">96</a>] offer
unprecedented generalization capabilities in zero-shot classification, text-guided image generation, and
in-context learning. While these advances use different algorithmic techniques such as contrastive learning,
diffusion, or auto-regressive modeling, they all rest on a common foundation: large datasets containing
paired image-text examples. For instance, CLIP&#8217;s training set contains 400 million image-text pairs, and
Stable Diffusion was trained on subsets of LAION-2B&#x00A0;[<a 
href="#Xlaion5b">122</a>], a dataset of more than two billion
image-text pairs. This new generation of image-text datasets is more than 1,000 times larger than
previous training datasets such as the widely used ImageNet, which contains 1.2M images
[<a 
href="#Xdeng2009imagenet">33</a>,&#x00A0;<a 
href="#XILSVRC15">119</a>].
<div class="table">
                                                                                         
                                                                                         
<!--l. 250--><p class="noindent" ><a 
 id="x1-1001r1"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-1002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;1:  </span><span  
class="content">Zero-shot  performance  of  CLIP  models  trained  on  various  datasets.  Our  dataset
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B, assembled with a simple filtering procedure on image-text pairs from Common
Crawl, leads to a model with higher accuracy than previous results while using the same or less
compute. Training compute is measured in the total number of multiply-accumulate operations
during training (MACs). See Section <a 
href="#x1-190003.5">3.5<!--tex4ht:ref: sec:evaluation --></a> for details on the evaluation datasets. </span></div><!--tex4ht:label?: x1-1001r1 -->
<!--l. 261--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-2" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-2-1g"><col 
id="TBL-2-1"><col 
id="TBL-2-2"><col 
id="TBL-2-3"><col 
id="TBL-2-4"><col 
id="TBL-2-5"><col 
id="TBL-2-6"><col 
id="TBL-2-7"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-2-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-1-1"  
class="td11">                     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-2"  
class="td11">            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-3"  
class="td11"> <span 
class="ecrm-1000"># samples  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-4"  
class="td11">            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-5"  
class="td11"> <span 
class="ecrm-1000">Train compute  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-6"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-7"  
class="td11"> <span 
class="ecrm-1000">Avg. performance  </span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-2-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Dataset</span></div>                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Dataset size</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-3"  
class="td11">    <span 
class="ecrm-1000">seen      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-4"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Architecture</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-5"  
class="td11">    <span 
class="ecrm-1000">(MACs)      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-6"  
class="td11"> <span 
class="ecrm-1000">accuracy  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-7"  
class="td11">   <span 
class="ecrm-1000">(38 datasets)     </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-3-1"  
class="td11"> <span 
class="ecrm-1000">OpenAI&#8217;s WIT [</span><a 
href="#Xradford2021learning"><span 
class="ecrm-1000">104</span></a><span 
class="ecrm-1000">]     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-2"  
class="td11">    <span 
class="ecrm-1000">0.4B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-3"  
class="td11">    <span 
class="ecrm-1000">13B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-4"  
class="td11">  <span 
class="ecrm-1000">ViT-L/14    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-5"  
class="td11">   <span 
class="cmr-10">1</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-6"  
class="td11">   <span 
class="ecrm-1000">75.5     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-7"  
class="td11">       <span 
class="ecrm-1000">0.61          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-4-1"  
class="td11"> <span 
class="ecrm-1000">LAION-400M [</span><a 
href="#Xlaion400m"><span 
class="ecrm-1000">121</span></a><span 
class="ecrm-1000">,</span><span 
class="ecrm-1000">&#x00A0;</span><a 
href="#Xcherti2022reproducible"><span 
class="ecrm-1000">24</span></a><span 
class="ecrm-1000">]  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-2"  
class="td11">    <span 
class="ecrm-1000">0.4B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-3"  
class="td11">    <span 
class="ecrm-1000">13B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-4"  
class="td11">  <span 
class="ecrm-1000">ViT-L/14    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-5"  
class="td11">   <span 
class="cmr-10">1</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-6"  
class="td11">   <span 
class="ecrm-1000">73.1     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-7"  
class="td11">       <span 
class="ecrm-1000">0.58          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-5-1"  
class="td11"> <span 
class="ecrm-1000">LAION-2B [</span><a 
href="#Xlaion5b"><span 
class="ecrm-1000">122</span></a><span 
class="ecrm-1000">,</span><span 
class="ecrm-1000">&#x00A0;</span><a 
href="#Xcherti2022reproducible"><span 
class="ecrm-1000">24</span></a><span 
class="ecrm-1000">]     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-2"  
class="td11">    <span 
class="ecrm-1000">2.3B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-3"  
class="td11">    <span 
class="ecrm-1000">13B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-4"  
class="td11">  <span 
class="ecrm-1000">ViT-L/14    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-5"  
class="td11">   <span 
class="cmr-10">1</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-6"  
class="td11">   <span 
class="ecrm-1000">73.1     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-7"  
class="td11">       <span 
class="ecrm-1000">0.59          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-6-1"  
class="td11"> <span 
class="ecrm-1000">LAION-2B [</span><a 
href="#Xlaion5b"><span 
class="ecrm-1000">122</span></a><span 
class="ecrm-1000">,</span><span 
class="ecrm-1000">&#x00A0;</span><a 
href="#Xcherti2022reproducible"><span 
class="ecrm-1000">24</span></a><span 
class="ecrm-1000">]     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-2"  
class="td11">    <span 
class="ecrm-1000">2.3B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-3"  
class="td11">    <span 
class="ecrm-1000">34B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-4"  
class="td11">  <span 
class="ecrm-1000">ViT-L/14    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-5"  
class="td11">   <span 
class="cmr-10">2</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">6 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-6"  
class="td11">   <span 
class="ecrm-1000">75.2     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-7"  
class="td11">       <span 
class="ecrm-1000">0.61          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-7-1"  
class="td11"> <span 
class="ecrm-1000">LAION-2B [</span><a 
href="#Xlaion5b"><span 
class="ecrm-1000">122</span></a><span 
class="ecrm-1000">,</span><span 
class="ecrm-1000">&#x00A0;</span><a 
href="#Xcherti2022reproducible"><span 
class="ecrm-1000">24</span></a><span 
class="ecrm-1000">]     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-2"  
class="td11">    <span 
class="ecrm-1000">2.3B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-3"  
class="td11">    <span 
class="ecrm-1000">34B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-4"  
class="td11">  <span 
class="ecrm-1000">ViT-H/14   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-5"  
class="td11">   <span 
class="cmr-10">6</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-6"  
class="td11">   <span 
class="ecrm-1000">78.0     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-7"  
class="td11">       <span 
class="ecrm-1000">0.64          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-8-1"  
class="td11"> <span 
class="ecrm-1000">LAION-2B [</span><a 
href="#Xlaion5b"><span 
class="ecrm-1000">122</span></a><span 
class="ecrm-1000">,</span><span 
class="ecrm-1000">&#x00A0;</span><a 
href="#Xcherti2022reproducible"><span 
class="ecrm-1000">24</span></a><span 
class="ecrm-1000">]     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-2"  
class="td11">    <span 
class="ecrm-1000">2.3B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-3"  
class="td11">    <span 
class="ecrm-1000">34B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-4"  
class="td11">  <span 
class="ecrm-1000">ViT-g/14    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-5"  
class="td11">   <span 
class="cmr-10">9</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">9 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-6"  
class="td11">   <span 
class="ecrm-1000">78.5     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-7"  
class="td11">       <span 
class="ecrm-1000">0.64          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-9-1"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span><span 
class="ecrm-1000">-1B (ours)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-2"  
class="td11">    <span 
class="ecrm-1000">1.4B       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-3"  
class="td11">    <span 
class="ecrm-1000">13B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-4"  
class="td11">  <span 
class="ecrm-1000">ViT-L/14    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-5"  
class="td11">   <span 
class="cmr-10">1</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-6"  
class="td11">   <span 
class="ecbx-1000">79.2    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-7"  
class="td11">      <span 
class="ecbx-1000">0.66         </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-10-1"  
class="td11">                      </td></tr></table>                                                                                         </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
</div>
<!--l. 283--><p class="noindent" >Despite the central role large image-text datasets play in multimodal learning, little is known about them.
Many state-of-the-art datasets are proprietary and only available in corporate research labs, as in the case
of CLIP [<a 
href="#Xradford2021learning">104</a>], DALL-E [<a 
href="#Xramesh2021zero">108</a>,&#x00A0;<a 
href="#Xramesh2022hierarchical">109</a>], Flamingo [<a 
href="#Xalayrac2022flamingo">4</a>], and GPT-4 [<a 
href="#Xgpt4">96</a>]. But even for public datasets such as
LAION-2B [<a 
href="#Xlaion5b">122</a>], it is unclear how design choices during dataset construction, such as the data source or
filtering techniques, affect the resulting models. While there are thousands of ablation studies for
algorithmic design choices (loss function, optimizer, model architecture, etc.), datasets are usually treated
as monolithic artifacts without detailed investigation or further improvements. Moreover, datasets
currently lack the benchmark-driven development process that has enabled the community to produce a
steady stream of advances on the model side. These issues impede further progress in multimodal
learning, as evidenced by recent work showing that public datasets currently do not match the
scaling behavior of proprietary alternatives [<a 
href="#Xcherti2022reproducible">24</a>]. A key difficulty for improving datasets is the
scarcity of data-centric benchmarks that isolate dataset enhancements from changes to the
model.
<!--l. 291--><p class="noindent" >In this paper, we take a step towards a more rigorous dataset development process via five contributions.
Our first and central contribution is <span 
class="ecxc-1095">DataComp</span><span 
class="ecbx-1095">, a new benchmark for multimodal dataset</span>
<span 
class="ecbx-1095">design</span>. <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>flips the traditional benchmarking paradigm in machine learning where the dataset is
fixed and the research community proposes new training algorithms. Instead of a fixed dataset, we hold the
training code, model, and computational budget constant so that participants innovate by proposing new
training sets. To evaluate the quality of a training set, we score the resulting model with a broad
testbed of 38 classification and retrieval tasks such as ImageNet [<a 
href="#Xdeng2009imagenet">33</a>], ImageNetV2 [<a 
href="#Ximagenetv2">114</a>], DTD
[<a 
href="#Xdtd">26</a>], EuroSAT [<a 
href="#Xeurosat">57</a>], PatchCamelyon [<a 
href="#Xpatchcamelyon">133</a>], SUN-397 [<a 
href="#Xsun397">137</a>], MSCOCO [<a 
href="#Xmscoco">22</a>], and WinoGAViL
[<a 
href="#Xbitton2022winogavil">13</a>].
<!--l. 297--><p class="noindent" ><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>focuses on two key challenges that arise when assembling large training datasets: what data
sources to train on, and how to filter a given data source. Each challenge corresponds to one track in our
benchmark. To facilitate the <span 
class="ecti-1095">filtering track</span>, our second contribution is <span 
class="ecxc-1095">CommonPool</span><span 
class="ecbx-1095">, a dataset of</span>
<span 
class="ecbx-1095">12.8B image-text pairs collected from Common Crawl</span>. In the filtering track, the goal
of participants is to find the best subset of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>to train on. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is
currently the largest publicly released image-text dataset, exceeding the size of LAION-5B
by a factor of <span 
class="cmr-10x-x-109">2</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">5</span><span 
class="cmsy-10x-x-109">&#x00D7;</span>. Additionally, we apply explicit content checks and face blurring when
constructing <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>to improve the safety of image-text datasets. In the second track, <span 
class="ecti-1095">Bring</span>
<span 
class="ecti-1095">Your Own Data </span>(<span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>), participants can leverage any data source of their choice, as long
as the training data does not overlap with our evaluation testbed. Taken together, our two
tracks provide a controlled environment to better understand dataset curation for multimodal
learning.
<!--l. 307--><p class="noindent" >Our third contribution is an investigation of <span 
class="ecbx-1095">scaling trends for dataset design</span>. In particular,
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>contains <span 
class="ecti-1095">four </span>distinct compute and data scales. On the data side, the candidate pool for
filtering ranges from 12.8M samples to 12.8B samples. On the compute side, the training budget scales
accordingly from 12.8M to 12.8B samples seen during training. This choice of pool size and compute
budget leads to the natural baseline of training on the entire candidate pool with a single training pass
and no filtering. Expressed in GPU hours, the cost of a single training run ranges from 4 to
40,000 GPU hours on the A100 cluster we used for development. This 10,000<span 
class="cmsy-10x-x-109">&#x00D7; </span>range stems
                                                                                         
                                                                                         
from a factor 1,000<span 
class="cmsy-10x-x-109">&#x00D7; </span>in pool size and another factor <span 
class="cmr-10x-x-109">10</span><span 
class="cmsy-10x-x-109">&#x00D7; </span>from scaling the model size. The
different scales enable researchers with different resources to participate in our benchmark.
Moreover, the multi-scale format facilitates studying scaling trends. Our results show that the
order of several filtering approaches is largely consistent across multiple compute and data
scales.
                                                                                         
                                                                                         
<!--l. 319--><p class="noindent" ><a 
 id="x1-1003r1"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 321--><p class="noindent" > <img 
src="figures/workflow-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-1004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">Participant workflow. A) Participants first choose a scale, <span 
class="ectt-1000">small</span>, <span 
class="ectt-1000">medium</span>, <span 
class="ectt-1000">large </span>or <span 
class="ectt-1000">xlarge</span>,
based  on  their  resource  constraints  (submission  to  multiple  scales  is  allowed).  B)  Participants
create  a  candidate  dataset,  choosing  one  of  two  tracks:  <span 
class="ecti-1095">filtering</span>,  where  only  image-text  pairs
from <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>are allowed; or <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>, where any data source (including <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>) is
permitted. C) Participants train a CLIP model on their candidate pool using a fixed architecture
and hyperparameters (Section <a 
href="#x1-180003.4">3.4<!--tex4ht:ref: sec:training --></a>). D) Participants evaluate the trained model on a suite of diverse
downstream tasks (Section <a 
href="#x1-190003.5">3.5<!--tex4ht:ref: sec:evaluation --></a>) and submit to our leaderboard.</span></div><!--tex4ht:label?: x1-1003r1 -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 327--><p class="noindent" >Our fourth contribution are <span 
class="ecbx-1095">over three hundred baseline experiments </span>and resulting insights into how
dataset curation methods compare. Our baselines span basic techniques such as removing small
images or non-English captions, querying captions for relevant keywords, filtering based on
image embeddings, and applying a threshold on CLIP scores. A key result from our baselines
experiments is that smaller, more stringently filtered datasets can lead to models that generalize
<span 
class="ecti-1095">better </span>than larger datasets coming from the same pool. At the 12.8B scale, our best filtering
baseline increases ImageNet zero-shot accuracy by 6.9 percentage points (pp) relative to the
unfiltered pool (see <a 
href="#x1-28001r3">Table&#x00A0;3</a>). For the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track, our initial experiments with multiple data
sources find that 109M additional data points (less than 1% of the pool size) improve the
CLIP-filtered subsets of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>by up to 1.2 pp ImageNet accuracy at the 12.8B scale (see
<a 
href="#x1-32001r4">Table&#x00A0;4</a>).
<!--l. 333--><p class="noindent" >Finally, our fifth contribution is <span 
class="ecxc-1095">DataComp</span><span 
class="ecbx-1095">-1B, a new state-of-the-art multimodal dataset </span>that
can be used as a drop-in replacement for previous image-text datasets such as LAION-2B.
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B is a filtered subset of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>containing 1.4B image-text pairs and demonstrates
that improving data curation can yield large performance gains. We obtained <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B
by combining our two most promising baselines from smaller scale experiments: CLIP score
filtering and image-based filtering. <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B enables training a CLIP ViT-L/14 model
with a compute budget of 12.8B samples to an ImageNet zero-shot accuracy of 79.2% (see
<a 
href="#x1-1001r1">Table&#x00A0;1</a>). This model, trained on <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B, outperforms a larger CLIP ViT-g/14 model
trained on LAION-2B for about <span 
class="cmr-10x-x-109">3</span><span 
class="cmsy-10x-x-109">&#x00D7; </span>longer (34B samples seen), corresponding to a an <span 
class="cmr-10x-x-109">9</span><span 
class="cmsy-10x-x-109">&#x00D7;</span>
overall reduction in compute cost. Moreover, our model outperforms OpenAI&#8217;s original CLIP
ViT-L/14 by 3.7 percentage points, which is trained with the same compute budget of 12.8B
samples as our model. We view <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B as only the first new dataset coming out of
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>and expect that future work will leverage our benchmark to discover further dataset
improvements.
<!--l. 341--><p class="noindent" >We hope that <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>serves as a starting point for new creative research on dataset curation by
making it easier to conduct controlled experiments in a shared experimental setting. To enable future
work, we publicly release our candidate pools, our tooling for assembling these pools, our filtering
baselines, and our code for training and evaluating models at <a 
href="www.datacomp.ai" class="url" ><span 
class="ectt-1095">www.datacomp.ai</span></a>. We present an overview of
the participant workflow in Figure <a 
href="#x1-1003r1">1<!--tex4ht:ref: fig:workflow --></a>. We believe that our infrastructure will help put research on dataset
curation on rigorous empirical foundations, draw attention to this understudied research area, and lead to
the next generation of multimodal datasets.
<h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-20002"></a>Related Work</h3>
<!--l. 349--><p class="noindent" >Due to space constraints, we discuss work that is closest to <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>here and refer the reader to
Appendix <a 
href="#x1-80000C">C<!--tex4ht:ref: sec:more-relatedwork --></a> for additional related work.
<!--l. 351--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-30002"></a><span 
class="ecbx-1095">The effects of data curation.</span></span>
Classical work considers dataset cleaning and outlier removal [<a 
href="#Xjiang2001two">66</a>,&#x00A0;<a 
href="#Xyu2002findout">143</a>,&#x00A0;<a 
href="#Xrousseeuw2011robust">117</a>,&#x00A0;<a 
href="#Xrousseeuw2018anomaly">118</a>] to discard samples
                                                                                         
                                                                                         
that may lead to undesirable model bias. A related line of work develops coreset selection
algorithms [<a 
href="#Xharpeled2004coresets">55</a>,&#x00A0;<a 
href="#Xagarwal2004approximating">3</a>,&#x00A0;<a 
href="#XFeldman2011Scalable">42</a>,&#x00A0;<a 
href="#Xpmlr-v37-bachem15">7</a>,&#x00A0;<a 
href="#Xlucic2018gaussian">87</a>,&#x00A0;<a 
href="#Xpmlr-v37-wei15">136</a>,&#x00A0;<a 
href="#Xcohen2017input">28</a>], which aim to select data subsets that lead to the same
performance as training on the entire dataset. These techniques are known to scale poorly to
larger data regimes [<a 
href="#Xguo2022deepcore">47</a>,&#x00A0;<a 
href="#Xabbas2023semdedup">2</a>], which are critical for modern deep learning algorithms. More recent
efforts in subset selection often operate on already curated datasets [<a 
href="#Xcraig">91</a>,&#x00A0;<a 
href="#Xtoneva2018empirical">132</a>,&#x00A0;<a 
href="#Xsener2018active">123</a>,&#x00A0;<a 
href="#Xbirodkar2019semantic">12</a>,&#x00A0;<a 
href="#Xcoleman2020selection">29</a>,&#x00A0;<a 
href="#Xdatadiet">99</a>]
like CIFAR-10, ImageNet or on smaller data regimes (e.g., YFCC-15M [<a 
href="#Xradford2021learning">104</a>,&#x00A0;<a 
href="#Xyfcc100m">131</a>]). These
settings often do not reflect newer training paradigms that involve (1) <span 
class="ecti-1095">noisy </span>image-text pairs
instead of category labeled images and (2) large scale datasets (e.g., billions of samples). While
data-centric investigations have led to community competitions like <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">c</span><span 
class="small-caps">b</span><span 
class="small-caps">e</span><span 
class="small-caps">n</span><span 
class="small-caps">c</span><span 
class="small-caps">h</span> </span>[<a 
href="#Xdcbench">39</a>] and <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">p</span><span 
class="small-caps">e</span><span 
class="small-caps">r</span><span 
class="small-caps">f</span></span>
[<a 
href="#Xdataperf">90</a>], existing benchmarks have likewise operated at small data scales [<a 
href="#Xdatacentric">93</a>], especially when
compared to datasets like LAION-2B [<a 
href="#Xlaion5b">122</a>], which contains over two billion images. <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>
bridges this gap to better align dataset curation algorithms with modern large scale image-text
training.
<!--l. 360--><p class="noindent" >There has also been renewed interest in dataset pruning and deduplication. Sorscher et&#x00A0;al.&#x00A0;[<a 
href="#Xsorscher2022beyond">126</a>] show that
data pruning can be used to outperform traditional power-law scaling trends on ImageNet, but
do not consider image-text training or larger datasets. Raffel et&#x00A0;al.&#x00A0;[<a 
href="#Xraffel2020exploring">106</a>] attempt to remove
sentence redundancies when creating the C4 corpus. Subsequent work further demonstrated the
benefits of deduplication for better language modeling [<a 
href="#XLee2021DeduplicatingTD">83</a>]. Radenovic et&#x00A0;al.&#x00A0;[<a 
href="#Xrdk+23">103</a>] introduce
CAT filtering for image-text datasets&#8212;a rule based system to retain high quality samples.
Abbas et&#x00A0;al.&#x00A0;[<a 
href="#Xabbas2023semdedup">2</a>] introduce SemDeDup, which starts with the CAT-filtered LAION-440M subset,
further employing a clustering method to removes semantic duplicates. SemDeDup improves
training speed; however, the resulting models show similar zero-shot ImageNet performance
when compared to models trained on the original dataset. At our largest scale, we introduce a
pool of 12.8B image-text pairs, which is an order of magnitude larger than the data pools
considered in either CAT or SemDeDup. Hence, we hope the <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>benchmark will
bootstrap future data-centric exploration at a scale that is unprecedented in non-proprietary
research.
<!--l. 370--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-40002"></a><span 
class="ecbx-1095">Large-scale multimodal datasets.</span></span>
Datasets have been instrumental to build multimodal models like CLIP&#x00A0;[<a 
href="#Xradford2021learning">104</a>], Flamingo&#x00A0;[<a 
href="#Xalayrac2022flamingo">4</a>], Stable
Diffusion &#x00A0;[<a 
href="#Xrombach2022high">116</a>], DALL-E&#x00A0;[<a 
href="#Xramesh2021zero">108</a>,&#x00A0;<a 
href="#Xramesh2022hierarchical">109</a>] and GPT-4 [<a 
href="#Xgpt4">96</a>]. These methods succeeded by training on large,
heterogeneous datasets rather than solely through advanced modelling techniques. For example, OpenAI&#8217;s
CLIP trains on 400M image-text pairs from the web, roughly <span 
class="cmr-10x-x-109">300</span><span 
class="cmsy-10x-x-109">&#x00D7; </span>the size of ImageNet&#x00A0;[<a 
href="#Xdeng2009imagenet">33</a>]. Prior work
on scaling image-text datasets also provides promising trends with respect to zero-shot model
performance&#x00A0;[<a 
href="#Xjia2021scaling">65</a>,&#x00A0;<a 
href="#Xpham2021scaling">100</a>]. Additional large scale datasets like FILIP-300M [<a 
href="#Xfilip">140</a>], FLD-900M [<a 
href="#Xyuan2021florence">144</a>], and
PaLI-10B [<a 
href="#Xchen2022pali">21</a>] were constructed to train multimodal models. However, many datasets used to train such
models (including the dataset for OpenAI&#8217;s CLIP) are proprietary, making it hard to conduct data-centric
investigations.
<!--l. 377--><p class="noindent" >Even for public image-text datasets like SBU&#x00A0;[<a 
href="#Xsbu">97</a>], Flickr30k [<a 
href="#Xflickr30k">142</a>], MS-COCO [<a 
href="#Xmscoco">22</a>], Conceptual Captions
[<a 
href="#Xsharma2018conceptual">124</a>], CC12M [<a 
href="#Xchangpinyo2021conceptual">20</a>], RedCaps [<a 
href="#Xdesai2021redcaps">34</a>], WIT [<a 
href="#Xsrinivasan2021wit">127</a>], Shutterstock [<a 
href="#Xnguyen2022quality">94</a>], YFCC-100M [<a 
href="#Xyfcc100m">131</a>], COYO-700M [<a 
href="#Xcoyo700m">16</a>],
LAION-400M [<a 
href="#Xlaion400m">121</a>], or LAION-2B [<a 
href="#Xlaion5b">122</a>] little is known about what constitutes a good image-text dataset.
Preliminary analysis suggests that different image-text data sources lead to CLIP models with different
properties&#x00A0;[<a 
href="#Xnguyen2022quality">94</a>]. However, previous work is limited to smaller scale data (10-15M examples). Our work
                                                                                         
                                                                                         
provides a testbed for conducting controlled experiments on how different data curation techniques affect
models. Our benchmark spans several orders of magnitude in compute and data scale. It includes the
largest publicly available collection of image-text pairs, with 12.8B samples. Birhane et&#x00A0;al.&#x00A0;[<a 
href="#XBirhane2021MultimodalDM">11</a>]
examine the LAION-400M dataset and find a plethora of problematic content, including NSFW
imagery and racial slurs. In doing so, they center the dangers in web-scale multimodal datasets.
In an effort to combat toxicity, we preprocess dataset samples with NSFW models during
pool construction and remove flagged content. We also blur faces detected in images to make
individuals less recognizable. For more details on our safety preprocessing see Section&#x00A0;<a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a>,
Appendices&#x00A0;<a 
href="#x1-82000E">E<!--tex4ht:ref: app:nsfw --></a>&#x00A0;and&#x00A0;<a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a>.
<!--l. 381--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-50003"></a><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span></h3>
<!--l. 384--><p class="noindent" >The goal of <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>is to place dataset curation on rigorous empirical foundations, making it easier to
conduct controlled experiments in a shared experimental setting. In contrast to traditional
benchmarks where participants iterate on model design and hyperparameter tuning, <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>asks
participants to design datasets that lead to high accuracy under fixed experimental conditions
on the modeling side. Our benchmark focuses on large image-text datasets and evaluates a
new dataset by training a CLIP model on the dataset from scratch [<a 
href="#Xradford2021learning">104</a>]. To facilitate such
investigations, we provide a candidate pool of uncurated image-text pairs crawled from the public
internet.
<!--l. 389--><p class="noindent" >Our benchmark offers two tracks: one where participants must use only samples from the pools we
provide, and another where participants can use external data in addition to samples from our
pool. Moreover, <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>is structured to accommodate participants with diverse levels of
computational resources: each track is broken down into four scales with varying compute
requirements.
<!--l. 392--><p class="noindent" >In this section, we discuss several design considerations including the benchmark tracks, experimental
details for training, datasets used for evaluation, and the rules of the competition.
<!--l. 395--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">3.1   </span> <a 
 id="x1-60003.1"></a>Competition design</h4>
<!--l. 396--><p class="noindent" >The first question when designing a datasets benchmark is how to enable meaningful comparisons
between different datasets. In numerous areas of machine learning, larger datasets lead to better
performance&#x00A0;[<a 
href="#Xkrizhevsky2012imagenet">80</a>,&#x00A0;<a 
href="#Xkaplan2020scaling">71</a>,&#x00A0;<a 
href="#Xjia2021scaling">65</a>,&#x00A0;<a 
href="#Xpham2021scaling">100</a>,&#x00A0;<a 
href="#Xchinchilla">60</a>,&#x00A0;<a 
href="#Xcherti2022reproducible">24</a>,&#x00A0;<a 
href="#Xgpt3">15</a>,&#x00A0;<a 
href="#Xradford2021learning">104</a>,&#x00A0;<a 
href="#Xradford2022robust">105</a>]. Hence a natural starting point for a
dataset benchmark would be to compare datasets of the same size only. While intuitive, this
approach is flawed when it comes to contemporary large training sets for multimodal models. In
particular, controlling the dataset size ignores the creation process behind the dataset and
thereby fails to control for the actually relevant quantities: pool size and training compute. To
illustrate this point, we now briefly summarize how state-of-the-art multimodal datasets are
assembled.
                                                                                         
                                                                                         
<!--l. 403--><p class="noindent" >At a high level, assembling a dataset such as LAION-2B consists of two steps. The first step is to identify
one or multiple <span 
class="ecti-1095">data sources</span>, e.g., a web crawl such as Common Crawl or a widely used website such as
Reddit. The data source should provide many training examples covering a broad distribution and come
with supervision signals such as nearby text. After identifying a suitable set of data sources, the next step
is to <span 
class="ecti-1095">filter </span>the data source to remove data points with low-quality annotations or other deficiencies (blurry
images, etc.). The final dataset then contains all examples from the data sources that pass the data
curation filters.
<!--l. 409--><p class="noindent" >An important aspect of this dataset creation process is that <span 
class="ecti-1095">the final dataset size is a design choice </span>and
not fixed ahead of time by the data sources. In particular, the dataset designer faces a trade-off between
the dataset size (more data points are better) and data quality (higher quality data points are better).
Hence the true data constraint in web-scale training set curation is not the size of the final dataset, but the
size of the <span 
class="ecti-1095">candidate pool</span>. To make <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>a realistic benchmark for dataset curation
that can inform future dataset projects, we therefore fix the candidate pool participants work
with in the filtering track, but otherwise give participants full control over the training set
size.
<!--l. 414--><p class="noindent" >Besides the size of the candidate pool, the other practically relevant constraint when training a model is
the compute cost. In order to put training sets of different size on equal footing, we specify the training
compute in terms of the total <span 
class="ecti-1095">number of samples seen </span>during training, not in terms of how many passes
(epochs) the training run makes over the training set. As a concrete example, consider the 12.8B candidate
pool, for which we fix a compute budget of 12.8B examples seen. A participant may choose to
build a training set <span 
class="cmmi-10x-x-109">A </span>with 3.2B data points by removing 75% of the candidate pool. The
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>training code would then make four passes over this training set <span 
class="cmmi-10x-x-109">A</span>. Alternatively, a
participant may filter more aggressively and end up with a dataset <span 
class="cmmi-10x-x-109">B </span>containing only 1.6B
examples (i.e., removing 87.5% of the candidate pool). In this case, the training code would
make eight passes over training set <span 
class="cmmi-10x-x-109">B </span>so that the total amount of training compute remains
constant (12.8B samples seen). A key result from our baselines experiments in <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>is that
smaller, more stringently filtered datasets can lead to models that generalize <span 
class="ecti-1095">better </span>than larger
datasets coming from the same pool of images when the total amount of training compute is
constant.
<!--l. 423--><p class="noindent" >This realistic, pool-centric perspective on dataset curation is one of they key design decisions in
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>. We now briefly review the other design decisions such as the division into two competition
tracks, our multi-scale structure and the construction of the candidate pool. Additional design
decisions including our training and evaluation protocols are discussed in Sections <a 
href="#x1-180003.4">3.4<!--tex4ht:ref: sec:training --></a> and
<a 
href="#x1-190003.5">3.5<!--tex4ht:ref: sec:evaluation --></a>.
<!--l. 427--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-70003.1"></a><span 
class="ecbx-1095">Competition tracks.</span></span>
As mentioned above, the two key steps in assembling a training dataset are filtering an existing pool of
data [<a 
href="#Xlaion400m">121</a>,&#x00A0;<a 
href="#Xlaion5b">122</a>,&#x00A0;<a 
href="#Xcoyo700m">16</a>] and aggregating different data sources [<a 
href="#Xdave2020tao">32</a>,&#x00A0;<a 
href="#Xdeng2009imagenet">33</a>]. To compare methods for these two
approaches separately, <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>has two tracks: <span 
class="ecti-1095">filtering</span>, where participants must select a subset of the
samples from <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, and <span 
class="ecti-1095">Bring Your Own Data </span>(<span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>), where participants are
allowed to use any source of external data. The tracks are described in Sections <a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a> and <a 
href="#x1-170003.3">3.3<!--tex4ht:ref: sec:byod --></a>,
respectively.
                                                                                         
                                                                                         
<div class="table">
                                                                                         
                                                                                         
<!--l. 432--><p class="noindent" ><a 
 id="x1-7001r2"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-7002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;2: </span><span  
class="content">Experimental configuration for each scale. The number of samples seen during training
at the largest scale is chosen to match the experimental setup from Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>]. Training
compute is measured in the total number of multiply-accumulate operations (MACs).</span></div><!--tex4ht:label?: x1-7001r3 -->
<div class="tabular"> <table id="TBL-3" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-3-1g"><col 
id="TBL-3-1"><col 
id="TBL-3-2"><col 
id="TBL-3-3"><col 
id="TBL-3-4"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-3-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-1-1"  
class="td
11">  <span 
class="ecrm-1000">Scale    </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-1-2"  
class="td11">  <span 
class="ecrm-1000">Model       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-3"  
class="td11">  <span 
class="ecrm-1000">Train compute (MACs)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-4"  
class="td11">  <span 
class="ecrm-1000">Pool size and # samples seen   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-2-1"  
class="td11">  <span 
class="ectt-1000">small   </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-2-2"  
class="td11">  <span 
class="ecrm-1000">ViT-B/32   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-2-3"  
class="td11">       <span 
class="cmr-10">9</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">16</span></sup>              </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-2-4"  
class="td11">           <span 
class="ecrm-1000">12.8M                  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-3-1"  
class="td11">  <span 
class="ectt-1000">medium  </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-3-2"  
class="td11">  <span 
class="ecrm-1000">ViT-B/32   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-3"  
class="td11">       <span 
class="cmr-10">9</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">17</span></sup>              </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-4"  
class="td11">            <span 
class="ecrm-1000">128M                  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-4-1"  
class="td11">  <span 
class="ectt-1000">large   </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-4-2"  
class="td11">  <span 
class="ecrm-1000">ViT-B/16   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-3"  
class="td11">       <span 
class="cmr-10">2</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">6 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">19</span></sup>              </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-4"  
class="td11">            <span 
class="ecrm-1000">1.28B                  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-5-1"  
class="td11">  <span 
class="ectt-1000">xlarge  </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-5-2"  
class="td11">  <span 
class="ecrm-1000">ViT-L/14   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-5-3"  
class="td11">       <span 
class="cmr-10">1</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>              </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-5-4"  
class="td11">            <span 
class="ecrm-1000">12.8B                  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-6-1"  
class="td11">         </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
</div>
<!--l. 451--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-80003.1"></a><span 
class="ecbx-1095">Competition scales.</span></span>
To facilitate the study of scaling trends and accommodate participants with various levels of
computational resources, we structure <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>using four scales of compute: <span 
class="ectt-1000">small</span>, <span 
class="ectt-1000">medium</span>, <span 
class="ectt-1000">large </span>and
<span 
class="ectt-1000">xlarge</span>. Each new scale increases the number of samples seen during training by 10<span 
class="cmsy-10x-x-109">&#x00D7; </span>(from 12.8M to
12.8B samples seen), and the pool we provide by the same factor (from 12.8M samples to
12.8B samples). Table <a 
href="#x1-7001r2">2<!--tex4ht:ref: tab:scale-hparams --></a> describes the experimental configuration used for training at each
scale.
<!--l. 453--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-90003.1"></a><span 
class="ecbx-1095">Preprocessing and safety.</span></span>
Creating a dataset from a noisy web source such as Common Crawl involves many design decisions, e.g.,
whether one should de-duplicate images, keep only English captions, or restrict the image sizes. We
decided to grant participants a high degree of autonomy and kept our initial preprocessing of
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>to a minimum, leaving these design decisions open for exploration. Our only initial
preprocessing steps are to eliminate images that appear in downstream evaluation datasets or are flagged
due to safety considerations. For the latter, we take steps to eliminate illegal and explicit content and to
protect the privacy of individuals. Specifically, we remove unsafe images and captions with automated
filters and obfuscate faces in the candidate images we provide. Section <a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a> describes these steps in more
detail.
<!--l. 460--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-100003.1"></a><span 
class="ecbx-1095">Competition rules.</span></span>
We include comprehensive rules in Appendix&#x00A0;<a 
href="#x1-56000A">A<!--tex4ht:ref: sec:full-competition-rules --></a>. Briefly, for the filtering track, we do not allow usage of
test images from our evaluation suite, but do allow users to use the training images for their filtering
algorithms. For <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>, we like-wise allow the use of training sets, but lift the restriction that
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>must be used.
<!--l. 464--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">3.2   </span> <a 
 id="x1-110003.2"></a><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>generation</h4>
<!--l. 466--><p class="noindent" >We construct <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, a large-scale dataset of image-text pairs sourced from Common
Crawl.<span class="footnote-mark"><a 
href="main2.html#fn1x0"><sup class="textsuperscript">1</sup></a></span><a 
 id="x1-11001f1"></a> 
Our pool construction pipeline has four major steps: URL extraction and data download, NSFW detection,
evaluation test set deduplication, and face blurring. We additionally provide metadata (e.g., CLIP
                                                                                         
                                                                                         
features) for each sample in the pool. Starting from the <span 
class="ectt-1000">xlarge </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, we take successive
random subsets to create <span 
class="ectt-1000">large</span>, <span 
class="ectt-1000">medium</span>, and <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>(e.g., <span 
class="ectt-1000">medium </span>is a subset of
<span 
class="ectt-1000">large</span>). An overview of the effect of each step in our pool generation pipeline in shown in Figure
<a 
href="#x1-11002r2">2<!--tex4ht:ref: fig:data_pipeline --></a>.
                                                                                         
                                                                                         
<!--l. 472--><p class="noindent" ><a 
 id="x1-11002r2"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 473--><p class="noindent" > <img 
src="figures/appx-datapipeline-.png" alt="PIC"  
width="446" height="446" >
<a 
 id="x1-11003"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2:  </span><span  
class="content">Data  funnel  going  from  potential  samples  found  in  Common  Crawl  to  the  13.1B
image-text pairs that were suitable for <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. We sampled uniformly 12.8B datapoints for
the <span 
class="ectt-1000">xlarge </span><span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span><span 
class="ecrm-1000">.</span></span></div><!--tex4ht:label?: x1-11002r3 -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 479--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-120003.2"></a><span 
class="ecbx-1095">Extracting urls and dowloading data.</span></span>
We first use cc2dataset<span class="footnote-mark"><a 
href="main3.html#fn2x0"><sup class="textsuperscript">2</sup></a></span><a 
 id="x1-12001f2"></a> ,
which utilizes Apache Spark&#x00A0;[<a 
href="#Xzaharia2016apache">146</a>], to 1) extract image urls with nonempty alt-text from all Common
Crawl dumps from 2014 to 2022 and 2) deduplicate and randomly shuffle the resulting set of image url,
alt-text pairs. Our processing results in in <span 
class="cmsy-10x-x-109">~</span>88B possible samples. Not all samples are downloadable due
to dead links; other samples are not suitable for inclusion in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>due to NSFW
content or overlap with our evaluation sets. Hence, we attempt to download <span 
class="cmsy-10x-x-109">~</span>40B samples using
img2dataset<span class="footnote-mark"><a 
href="main4.html#fn3x0"><sup class="textsuperscript">3</sup></a></span><a 
 id="x1-12002f3"></a> 
resulting in <span 
class="cmsy-10x-x-109">~</span>16.8B successfully downloaded image-text pairs. For details, see Appendix <a 
href="#x1-81000D">D<!--tex4ht:ref: app:parse-cc --></a>.
<!--l. 483--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-130003.2"></a><span 
class="ecbx-1095">NSFW preprocessing.</span></span>
Since Common Crawl is a snapshot of the internet, we require strict preprocessing to remove unsafe
content. We first use Detoxify&#x00A0;[<a 
href="#XDetoxify">54</a>] to prune samples that contain unsafe text (e.g., obscene, sexually
explicit, or threatening language). We also employ an image classifier to discard explicit visual content. To
do so, we train a classifier on CLIP ViT-L/14 [<a 
href="#Xradford2021learning">104</a>] features, using the NSFW dataset used in
LAION-5B&#x00A0;[<a 
href="#Xlaion5b">122</a>]. We validate our classifier against the Google commercial image safety API. See
Appendix <a 
href="#x1-82000E">E<!--tex4ht:ref: app:nsfw --></a> for details. Overall, <span 
class="cmsy-10x-x-109">~</span>19% of image-text pairs are considered NSFW, taking our pool of
<span 
class="cmsy-10x-x-109">~</span>16.8B downloads to <span 
class="cmsy-10x-x-109">~</span>13.6B samples.
<!--l. 488--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-140003.2"></a><span 
class="ecbx-1095">Evaluation set deduplication.</span></span>
To prevent accidental overfitting to certain test sets in our evaluation suite, we perform a thorough
near-duplicate removal between the candidate pool and our evaluation sets, using a state-of-the-art image
deduplication model&#x00A0;[<a 
href="#XYokoo2021Dedup">141</a>]. Appendix <a 
href="#x1-83000F">F<!--tex4ht:ref: app:dedup --></a> contains additional details. The model flags <span 
class="cmsy-10x-x-109">~</span>3% of the 16.8B
images as near-duplicates, reducing the <span 
class="cmsy-10x-x-109">~</span>13.6B pool to <span 
class="cmsy-10x-x-109">~</span>13.1B samples. From here we select a random
subset to get the <span 
class="ectt-1000">xlarge </span>pool of 12.8B samples.
<!--l. 493--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-150003.2"></a><span 
class="ecbx-1095">Face detection &amp; blurring.</span></span>
To protect the privacy of individuals, we detect and blur faces from images in our pool using a face
detector&#x00A0;[<a 
href="#Xguo2021sample">49</a>]. As observed by Yang et&#x00A0;al.&#x00A0;[<a 
href="#Xyang2022study">139</a>], obfuscating faces has little impact on model performance,
as we also observe in our experiments (Appendix <a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a>).
                                                                                         
                                                                                         
<!--l. 495--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-160003.2"></a><span 
class="ecbx-1095">Pool metadata.</span></span>
Motivated by the LAION-400M data curation procedure, which employs similarity scores between CLIP
image and text features, we compute additional metadata for each sample in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. To bootstrap
participants in their exploration of filtering algorithms, we provide image url, alt-text, original image width
and height, CLIP image and text features, and CLIP image-text similarity scores. We also release a
SHA256 hash of each image to guard against data poisoning in subsequent <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>downloads [<a 
href="#Xcarlini2023poisoning">18</a>].
For additional details see Appendix <a 
href="#x1-85000H">H<!--tex4ht:ref: app:metadata --></a>. Metadata is meant to ease the computational burden on
participants; however, we encourage exploring curation techniques that go beyond the provided
metadata.
<!--l. 505--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">3.3   </span> <a 
 id="x1-170003.3"></a>Bring your own data (<span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>)</h4>
<!--l. 508--><p class="noindent" >While <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>can be used to study different filtering techniques, state-of-the-art models are often
trained on heterogeneous data pools from different sources. For instance, the Flamingo model&#x00A0;[<a 
href="#Xalayrac2022flamingo">4</a>] uses both
curated data from multimodal massive web (M3W) and the ALIGN dataset&#x00A0;[<a 
href="#Xjia2021scaling">65</a>]. To facilitate
non-proprietary research on curating data from many sources, we instantiate a separate track in
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>to allow participants to combine multiple data streams. For example, participants could
construct a training set from CC12M&#x00A0;[<a 
href="#Xchangpinyo2021conceptual">20</a>], YFCC100M&#x00A0;[<a 
href="#Xyfcc100m">131</a>], and data sources they label
themselves. In Section <a 
href="#x1-280004.2">4.2<!--tex4ht:ref: sec:byod-baselines --></a> and Appendix <a 
href="#x1-105000O.2">O.2<!--tex4ht:ref: app:byod --></a> we describe our exploration of using other public
datasets.
<!--l. 513--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">3.4   </span> <a 
 id="x1-180003.4"></a>Training</h4>
<!--l. 516--><p class="noindent" >We create a common experimental setting that enables controlled and comparable experiments by fixing
the training procedure (i.e., model architecture, optimizer, loss, hyperparameters, etc.) and compute at
each scale. We closely follow the training recipe used to train state-of-the-art CLIP models from Radford
et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>], training models from scratch with a contrastive objective over images and captions. Given a
set of image-caption pairs, we train an image encoder and a text encoder such that the similarity between
the representations of images and their corresponding text is maximized relative to unaligned
pairs.<span class="footnote-mark"><a 
href="main5.html#fn4x0"><sup class="textsuperscript">4</sup></a></span><a 
 id="x1-18001f4"></a> 
                                                                                         
                                                                                         
<!--l. 524--><p class="noindent" >For each scale, we use a fixed model architecture and set of hyperparameters. We pick Vision
Transformers (ViTs) [<a 
href="#Xdosovitskiy2021an">35</a>] as the image encoder, considering the better scaling trends observed by
Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>] compared to ResNets [<a 
href="#Xhe2016deep">56</a>]. The size of the model varies with the scale, using
a ViT-B/32 for the <span 
class="ectt-1000">small </span>and <span 
class="ectt-1000">medium </span>scales, a ViT-B/16 for the <span 
class="ectt-1000">large </span>scale and ViT-L/14
for the <span 
class="ectt-1000">xlarge </span>scale. Models are trained for a fixed number of steps determined by the scale
(Table <a 
href="#x1-7001r2">2<!--tex4ht:ref: tab:scale-hparams --></a>), using the OpenCLIP repository [<a 
href="#Xilharco2021openclip">62</a>]. We closely follow the training procedure from
Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>], using the Adam optimizer [<a 
href="#Xkingma2014adam">73</a>] with decoupled weight decay [<a 
href="#Xloshchilov2018decoupled">86</a>] on all
weights except gains or biases with <span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">1</span></sub> <span 
class="cmr-10x-x-109">= 0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">9</span>, <span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">2</span></sub> <span 
class="cmr-10x-x-109">= 0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">98 </span>and weight decay of <span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">2</span>. For the <span 
class="ectt-1000">xlarge</span>
scale, we use <span 
class="cmmi-10x-x-109">&#x03B2;</span><sub><span 
class="cmr-8">2</span></sub> <span 
class="cmr-10x-x-109">= 0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">95 </span>to prevent instability. The models are trained with automatic mixed
precision and a cosine annealing learning rate schedule [<a 
href="#Xloshchilov2016sgdr">85</a>]. For the <span 
class="ectt-1000">small </span>scale, our internal
training runs took four hours on one A100 GPU, and for the <span 
class="ectt-1000">xlarge </span>scale, 81 hours on 512
GPUs. Additional details including other scale-specific hyperparameters are shown in Appendix
<a 
href="#x1-90000M">M<!--tex4ht:ref: app:train --></a>.
<h4 class="subsectionHead"><span class="titlemark">3.5   </span> <a 
 id="x1-190003.5"></a>Evaluation</h4>
<!--l. 530--><p class="noindent" >We evaluate on an extensive suite of 38 image classification and retrieval tasks. We also provide an
in-depth analysis on two fairness-related datasets, detailed in Section&#x00A0;<a 
href="#x1-290005">5<!--tex4ht:ref: sec:analysis --></a> and Appendix&#x00A0;<a 
href="#x1-107000P">P<!--tex4ht:ref: app:fairness --></a>. Image
classification datasets range from satellite imagery recognition to classifying metastatic tissues from
histopathologic scans, including (with some overlap): 22 of the datasets evaluated in Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>],
6 ImageNet distribution shifts, 11 datasets from the Visual Task Adaptation Benchmark (VTAB) [<a 
href="#Xvtab">147</a>],
and 3 datasets from the WILDS benchmark [<a 
href="#Xwilds2021">76</a>,&#x00A0;<a 
href="#Xsagawa2022extending">120</a>]. Retrieval datasets include the Flickr30k [<a 
href="#Xflickr30k">142</a>] and
MSCOCO image and text retrieval datasets [<a 
href="#Xmscoco">22</a>], as well as the WinoGAViL commonsense image-text
associations task [<a 
href="#Xbitton2022winogavil">13</a>]. To aggregate results over all evaluation tasks, we average the preferred metric for
each task. As discussed in Section <a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a>, we remove all test set images from the pool we provide to avoid
contamination.
<!--l. 536--><p class="noindent" ><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>adopts a zero-shot evaluation protocol, which means models are tested without training on the
evaluation tasks. This approach is computationally efficient and measures a model&#8217;s ability to perform well
without any additional training, in contrast to methods such as linear probing or end-to-end fine-tuning.
As an additional validation step, we find a strong correlation (<span 
class="cmmi-10x-x-109">&#x003E;</span><span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">99</span>) between performance using a linear
probe and that in a zero-shot setting, as seen in Appendix Figure <a 
href="#x1-94001r17">17<!--tex4ht:ref: fig:linear-probes --></a>. Additional details are in
Appendix&#x00A0;<a 
href="#x1-91000N">N<!--tex4ht:ref: sec:app-eval --></a>.
<!--l. 539--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">4   </span> <a 
 id="x1-200004"></a>Baselines</h3>
<!--l. 543--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">4.1   </span> <a 
 id="x1-210004.1"></a>Filtering baselines</h4>
<!--l. 545--><p class="noindent" >We study six simple filtering methods for the filtering track; see <a 
href="#x1-97000O.1">Section&#x00A0;O.1</a> for further details.
                                                                                         
                                                                                         
<!--l. 547--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-220004.1"></a><span 
class="ecbx-1095">No filtering.</span></span>
We simply use the entire pool as the subset, without any filtering. Since each pool size is equal to the
sample budget, training consists of one pass over the data.
<!--l. 549--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-230004.1"></a><span 
class="ecbx-1095">Random subsets.</span></span>
To isolate the effects of increasing the compute budget from increasing the dataset size, we form subsets
consisting of 1%, 10%, 25%, 50% and 75% of the pool chosen at random.
<!--l. 551--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-240004.1"></a><span 
class="ecbx-1095">Basic filtering.</span></span>
We consider a number of simple filtering operations inspired by Schuhmann et&#x00A0;al.&#x00A0;[<a 
href="#Xlaion400m">121</a>] and Byeon
et&#x00A0;al.&#x00A0;[<a 
href="#Xcoyo700m">16</a>]: filtering by <span 
class="ecti-1095">language </span>(only English captions, using either fasttext&#x00A0;[<a 
href="#Xjoulin2017bag">69</a>] or cld3&#x00A0;[<a 
href="#Xcld3">1</a>]); filtering by
<span 
class="ecti-1095">caption length </span>(over two words and 5 characters); and filtering by <span 
class="ecti-1095">image size </span>(smaller dimension above 200
pixels and aspect ratio below 3). We also experiment with combining the first two methods
(language + caption length) and all three (language + caption length + image size). Unless
otherwise specified, &#8220;basic&#8221; refers to filtering by fasttext language, caption length, and image
size.
<!--l. 553--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-250004.1"></a><span 
class="ecbx-1095">CLIP score and LAION filtering.</span></span>
We experiment with the main filtering strategy employed by LAION, where we take only
examples where the cosine similarity score between CLIP image and text embeddings exceeds a
pre-defined threshold. We investigate a range of thresholds and two OpenAI CLIP models for
computing the scores: the ViT-B/32 model (as in LAION) and the ViT-L/14. Furthermore,
we combine CLIP score thresholds and English filtering using cld3 in order to reproduce the
LAION-2B filtering scheme. <a 
href="#x1-99001r14">Table&#x00A0;14</a> in <a 
href="#x1-97000O.1">Section&#x00A0;O.1</a> summarizes the different CLIP score threshold
configurations.
<!--l. 555--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-260004.1"></a><span 
class="ecbx-1095">Text-based filtering.</span></span>
We select examples that contain text overlapping with ImageNet class names, which serves as a
proxy for relevance to downstream tasks. Specifically, we select English captions (according
to fasttext) that contain words from synsets corresponding to classes in ImageNet-21K or
ImageNet-1K&#x00A0;[<a 
href="#Xdeng2009imagenet">33</a>].
<!--l. 557--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-270004.1"></a><span 
class="ecbx-1095">Image-based filtering.</span></span>
We select a subset of examples whose visual content overlaps with ImageNet classes. After applying
language (fasttext) and caption length filtering on the data, we cluster the image embeddings extracted
from the OpenAI ViT-L/14 model of the candidate pool into 100K groups using Faiss&#x00A0;[<a 
href="#Xjohnson2019billion">67</a>]. We then find
                                                                                         
                                                                                         
the nearest neighbor cluster center for every ImageNet training example, and keep examples whose
corresponding cluster center is a nearest neighbor to at least one ImageNet image. We apply this
procedure using either ImageNet-21K (14M images) or ImageNet-1K (1.2M images), forming two
subsets.
<!--l. 559--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">4.2   </span> <a 
 id="x1-280004.2"></a><span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>baselines</h4>
<!--l. 560--><p class="noindent" >We experiment with multiple external data sources, including four moderately sized datasets (10 to 58M
samples) studied by Nguyen et&#x00A0;al.&#x00A0;[<a 
href="#Xnguyen2022quality">94</a>]&#8212;CC12M [<a 
href="#Xchangpinyo2021conceptual">20</a>], YFCC15M [<a 
href="#Xyfcc100m">131</a>,&#x00A0;<a 
href="#Xradford2021learning">104</a>], RedCaps [<a 
href="#Xdesai2021redcaps">34</a>] and
Shutterstock [<a 
href="#Xnguyen2022quality">94</a>]&#8212;and the larger LAION-2B&#x00A0;[<a 
href="#Xlaion5b">122</a>]. Additional experiments, along with more
details about the data sources are provided in Appendix <a 
href="#x1-105000O.2">O.2<!--tex4ht:ref: app:byod --></a>. We consider these data sources as
they are and do not perform additional preprocessing. We also present experiments combining
some of the data sources (using only the external datasets, or in addition to data from our
pool).
                                                                                         
                                                                                         
<!--l. 564--><p class="noindent" ><a 
 id="x1-28001r3"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-28002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;3: </span><span  
class="content">Zero-shot performance for select baselines in the <span 
class="ecti-1095">filtering </span>track. On all scales, various
filtering strategies lead to better performance than using the entire pool without filtering. The
intersection between imaged-based and CLIP score strategies performs well on most tasks and scales.
For all metrics, higher is better (see Appendix <a 
href="#x1-91000N">N<!--tex4ht:ref: sec:app-eval --></a> for details). <span 
class="cmsy-10x-x-109">&#x2229; </span>denotes the intersection between
filtering strategies. </span></div><!--tex4ht:label?: x1-28001r4 -->
<!--l. 572--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-4" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-4-1g"><col 
id="TBL-4-1"><col 
id="TBL-4-2"><col 
id="TBL-4-3"><col 
id="TBL-4-4"><col 
id="TBL-4-5"><col 
id="TBL-4-6"><col 
id="TBL-4-7"><col 
id="TBL-4-8"><col 
id="TBL-4-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-4-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-1-2"  
class="td11">                                  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-3"  
class="td11"> <span 
class="ecrm-1000">Dataset  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-4"  
class="td11"> <span 
class="ecrm-1000">Samples  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-5"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-6"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-7"  
class="td11">       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-8"  
class="td11">         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-9"  
class="td11"> <span 
class="ecrm-1000">Average over  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Scale</span></div>   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-2-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering strategy</span></div>                              </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-3"  
class="td11">   <span 
class="ecrm-1000">size    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-4"  
class="td11">   <span 
class="ecrm-1000">seen    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-6"  
class="td11"> <span 
class="ecrm-1000">dist. shifts  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-7"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-8"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-9"  
class="td11">  <span 
class="ecrm-1000">38 datasets  </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-4-3-2"  
class="td11"> <span 
class="ecrm-1000">No filtering </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-3"  
class="td11"> <span 
class="ecrm-1000">12.8M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-4"  
class="td11"> <span 
class="ecrm-1000">12.8M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-5"  
class="td11"> <span 
class="ecrm-1000">0.025 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-6"  
class="td11"> <span 
class="ecrm-1000">0.033 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-7"  
class="td11"> <span 
class="ecrm-1000">0.145 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-8"  
class="td11"> <span 
class="ecrm-1000">0.105 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-9"  
class="td11"> <span 
class="ecrm-1000">0.132</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-4-2"  
class="td11"> <span 
class="ecrm-1000">Basic filtering                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-3"  
class="td11">   <span 
class="ecrm-1000">3M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-5"  
class="td11">   <span 
class="ecrm-1000">0.030    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-6"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-7"  
class="td11"> <span 
class="ecrm-1000">0.149  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-8"  
class="td11">   <span 
class="ecrm-1000">0.111    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-9"  
class="td11">    <span 
class="ecrm-1000">0.137      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-5-2"  
class="td11"> <span 
class="ecrm-1000">Text-based                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-3"  
class="td11">  <span 
class="ecrm-1000">3.2M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-5"  
class="td11">   <span 
class="ecrm-1000">0.046    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-6"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-7"  
class="td11"> <span 
class="ecrm-1000">0.169  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-8"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.112</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-9"  
class="td11">    <span 
class="ecrm-1000">0.156      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-6-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-6-2"  
class="td11"> <span 
class="ecrm-1000">Image-based                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-3"  
class="td11">   <span 
class="ecrm-1000">3M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-5"  
class="td11">   <span 
class="ecrm-1000">0.043    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-6"  
class="td11">   <span 
class="ecrm-1000">0.047     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-7"  
class="td11"> <span 
class="ecrm-1000">0.178  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-8"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.112</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-9"  
class="td11">    <span 
class="ecrm-1000">0.158      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-7-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-7-2"  
class="td11"> <span 
class="ecrm-1000">LAION-2B filtering                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-3"  
class="td11">  <span 
class="ecrm-1000">1.3M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-5"  
class="td11">   <span 
class="ecrm-1000">0.031    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-6"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-7"  
class="td11"> <span 
class="ecrm-1000">0.136  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-8"  
class="td11">   <span 
class="ecrm-1000">0.085    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-7-9"  
class="td11">    <span 
class="ecrm-1000">0.133      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-8-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-8-2"  
class="td11"> <span 
class="ecrm-1000">CLIP score (L/14 30%)                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-3"  
class="td11">  <span 
class="ecrm-1000">3.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.051</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.055</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.190</span></span>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-8"  
class="td11">   <span 
class="ecrm-1000">0.108    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-8-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.172</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-9-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">small</span> </div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-9-2"  
class="td11"> <span 
class="ecrm-1000">Image-based </span><span 
class="cmsy-10">&#x2229; </span><span 
class="ecrm-1000">CLIP score (L/14 30%)  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-3"  
class="td11">  <span 
class="ecrm-1000">1.4M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-5"  
class="td11">   <span 
class="ecrm-1000">0.039    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-6"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-7"  
class="td11"> <span 
class="ecrm-1000">0.162  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-8"  
class="td11">   <span 
class="ecrm-1000">0.089    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-9-9"  
class="td11">    <span 
class="ecrm-1000">0.144      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-10-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-10-2"  
class="td11"> <span 
class="ecrm-1000">No filtering                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-3"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-5"  
class="td11">   <span 
class="ecrm-1000">0.176    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-6"  
class="td11">   <span 
class="ecrm-1000">0.152     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-7"  
class="td11"> <span 
class="ecrm-1000">0.259  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-8"  
class="td11">   <span 
class="ecrm-1000">0.174    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-10-9"  
class="td11">    <span 
class="ecrm-1000">0.254      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-11-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-11-2"  
class="td11"> <span 
class="ecrm-1000">Basic filtering                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-3"  
class="td11">  <span 
class="ecrm-1000">30M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-5"  
class="td11">   <span 
class="ecrm-1000">0.226    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-6"  
class="td11">   <span 
class="ecrm-1000">0.193     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-7"  
class="td11"> <span 
class="ecrm-1000">0.284  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-8"  
class="td11">   <span 
class="ecrm-1000">0.192    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-11-9"  
class="td11">    <span 
class="ecrm-1000">0.280      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-12-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-12-2"  
class="td11"> <span 
class="ecrm-1000">Text-based                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-3"  
class="td11">  <span 
class="ecrm-1000">31M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-5"  
class="td11">   <span 
class="ecrm-1000">0.255    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-6"  
class="td11">   <span 
class="ecrm-1000">0.215     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-7"  
class="td11"> <span 
class="ecrm-1000">0.328  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-8"  
class="td11">   <span 
class="ecrm-1000">0.183    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-12-9"  
class="td11">    <span 
class="ecrm-1000">0.301      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-13-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-4-13-2"  
class="td11"> <span 
class="ecrm-1000">Image-based </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-3"  
class="td11"> <span 
class="ecrm-1000">29M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-4"  
class="td11"> <span 
class="ecrm-1000">128M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-5"  
class="td11"> <span 
class="ecrm-1000">0.268 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-6"  
class="td11"> <span 
class="ecrm-1000">0.213 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-7"  
class="td11"> <span 
class="ecrm-1000">0.319 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-8"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.193</span></span> </td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-13-9"  
class="td11"> <span 
class="ecrm-1000">0.307</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-14-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-14-2"  
class="td11"> <span 
class="ecrm-1000">LAION-2B filtering                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-3"  
class="td11">  <span 
class="ecrm-1000">13M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-5"  
class="td11">   <span 
class="ecrm-1000">0.230    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-6"  
class="td11">   <span 
class="ecrm-1000">0.198     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-7"  
class="td11"> <span 
class="ecrm-1000">0.307  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-8"  
class="td11">   <span 
class="ecrm-1000">0.170    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-14-9"  
class="td11">    <span 
class="ecrm-1000">0.287      </span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-15-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-15-2"  
class="td11"> <span 
class="ecrm-1000">CLIP score (L/14 30%)                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-3"  
class="td11">  <span 
class="ecrm-1000">38M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-5"  
class="td11">   <span 
class="ecrm-1000">0.273    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-6"  
class="td11">   <span 
class="ecrm-1000">0.230     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-7"  
class="td11"> <span 
class="ecrm-1000">0.338  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-8"  
class="td11">   <span 
class="ecrm-1000">0.183    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-15-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.323</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-16-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">medium</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-16-2"  
class="td11"> <span 
class="ecrm-1000">Image-based </span><span 
class="cmsy-10">&#x2229; </span><span 
class="ecrm-1000">CLIP score (L/14 30%)  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-3"  
class="td11">  <span 
class="ecrm-1000">14M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.297</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.239</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.346</span></span>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-8"  
class="td11">   <span 
class="ecrm-1000">0.170    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-16-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.323</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-17-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-17-2"  
class="td11"> <span 
class="ecrm-1000">No filtering                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-3"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-5"  
class="td11">   <span 
class="ecrm-1000">0.459    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-6"  
class="td11">   <span 
class="ecrm-1000">0.378     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-7"  
class="td11"> <span 
class="ecrm-1000">0.426  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-8"  
class="td11">   <span 
class="ecrm-1000">0.305    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-17-9"  
class="td11">    <span 
class="ecrm-1000">0.428      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-18-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-18-2"  
class="td11"> <span 
class="ecrm-1000">Basic filtering                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-3"  
class="td11">  <span 
class="ecrm-1000">298M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-5"  
class="td11">   <span 
class="ecrm-1000">0.516    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-6"  
class="td11">   <span 
class="ecrm-1000">0.423     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-7"  
class="td11"> <span 
class="ecrm-1000">0.446  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-8"  
class="td11">   <span 
class="ecrm-1000">0.353    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-18-9"  
class="td11">    <span 
class="ecrm-1000">0.448      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-19-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-19-2"  
class="td11"> <span 
class="ecrm-1000">Text-based                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-3"  
class="td11">  <span 
class="ecrm-1000">317M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-5"  
class="td11">   <span 
class="ecrm-1000">0.561    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-6"  
class="td11">   <span 
class="ecrm-1000">0.465     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-7"  
class="td11"> <span 
class="ecrm-1000">0.465  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-8"  
class="td11">   <span 
class="ecrm-1000">0.352    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-19-9"  
class="td11">    <span 
class="ecrm-1000">0.466      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-20-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-4-20-2"  
class="td11"> <span 
class="ecrm-1000">Image-based </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-3"  
class="td11"> <span 
class="ecrm-1000">293M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-4"  
class="td11"> <span 
class="ecrm-1000">1.28B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-5"  
class="td11"> <span 
class="ecrm-1000">0.572 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-6"  
class="td11"> <span 
class="ecrm-1000">0.454 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-7"  
class="td11"> <span 
class="ecrm-1000">0.483 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-8"  
class="td11"> <span 
class="ecrm-1000">0.353 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-4-20-9"  
class="td11"> <span 
class="ecrm-1000">0.471</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-21-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-21-2"  
class="td11"> <span 
class="ecrm-1000">LAION-2B filtering                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-3"  
class="td11">  <span 
class="ecrm-1000">130M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-5"  
class="td11">   <span 
class="ecrm-1000">0.553    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-6"  
class="td11">   <span 
class="ecrm-1000">0.453     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-7"  
class="td11"> <span 
class="ecrm-1000">0.510  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-8"  
class="td11">   <span 
class="ecrm-1000">0.365    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-21-9"  
class="td11">    <span 
class="ecrm-1000">0.491      </span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-22-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-22-2"  
class="td11"> <span 
class="ecrm-1000">CLIP score (L/14 30%)                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-3"  
class="td11">  <span 
class="ecrm-1000">384M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-5"  
class="td11">   <span 
class="ecrm-1000">0.578    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-6"  
class="td11">   <span 
class="ecrm-1000">0.474     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-7"  
class="td11"> <span 
class="ecrm-1000">0.538  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-8"  
class="td11">   <span 
class="ecrm-1000">0.342    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-22-9"  
class="td11">    <span 
class="ecrm-1000">0.520      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-23-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">large</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-23-2"  
class="td11"> <span 
class="ecrm-1000">Image-based </span><span 
class="cmsy-10">&#x2229; </span><span 
class="ecrm-1000">CLIP score (L/14 30%)  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-3"  
class="td11">  <span 
class="ecrm-1000">140M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.631</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.508</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.546</span></span>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-8"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.369</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-23-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.527</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-24-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-24-2"  
class="td11"> <span 
class="ecrm-1000">No filtering                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-3"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-5"  
class="td11">   <span 
class="ecrm-1000">0.723    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-6"  
class="td11">   <span 
class="ecrm-1000">0.612     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-7"  
class="td11"> <span 
class="ecrm-1000">0.611  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-8"  
class="td11">   <span 
class="ecrm-1000">0.441    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-24-9"  
class="td11">    <span 
class="ecrm-1000">0.611      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-25-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-25-2"  
class="td11"> <span 
class="ecrm-1000">LAION-2B filtering                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-3"  
class="td11">  <span 
class="ecrm-1000">1.3B    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-5"  
class="td11">   <span 
class="ecrm-1000">0.755    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-6"  
class="td11">   <span 
class="ecrm-1000">0.637     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-7"  
class="td11"> <span 
class="ecrm-1000">0.624  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-8"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.503</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-25-9"  
class="td11">    <span 
class="ecrm-1000">0.627      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-26-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-26-2"  
class="td11"> <span 
class="ecrm-1000">CLIP score (L/14 30%)                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-3"  
class="td11">  <span 
class="ecrm-1000">3.8B    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-5"  
class="td11">   <span 
class="ecrm-1000">0.764    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-6"  
class="td11">   <span 
class="ecrm-1000">0.655     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-7"  
class="td11"> <span 
class="ecrm-1000">0.643  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-8"  
class="td11">   <span 
class="ecrm-1000">0.468    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-26-9"  
class="td11">    <span 
class="ecrm-1000">0.641      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-27-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">xlarge</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-27-2"  
class="td11"> <span 
class="ecrm-1000">Image-based </span><span 
class="cmsy-10">&#x2229; </span><span 
class="ecrm-1000">CLIP score (L/14 30%)  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-3"  
class="td11">  <span 
class="ecrm-1000">1.4B    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.792</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.679</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.652</span></span>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-8"  
class="td11">   <span 
class="ecrm-1000">0.489    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-27-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.653</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-28-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-28-1"  
class="td11">        </td></tr></table>                                                                                                                     </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h3 class="sectionHead"><span class="titlemark">5   </span> <a 
 id="x1-290005"></a>Results and discussion</h3>
<!--l. 609--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">5.1   </span> <a 
 id="x1-300005.1"></a>Building better datasets</h4>
<!--l. 611--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-310005.1"></a><span 
class="ecbx-1095">Main results.</span></span>
Our key results are in Table <a 
href="#x1-28001r3">3<!--tex4ht:ref: tab:main --></a>. Most notably, the intersection between image-based filtering and CLIP score
filtering taking the top 30% examples with highest scores using a ViT-L/14 model excels on most tasks.
The exception is for the <span 
class="ectt-1000">small </span>scale and the retrieval datasets, where other filtering approaches perform
better.<span class="footnote-mark"><a 
href="main6.html#fn5x0"><sup class="textsuperscript">5</sup></a></span><a 
 id="x1-31001f5"></a> 
Furthermore, other filtering strategies like basic, CLIP score, image-based, text-based filtering show better
downstream performance when compared to no filtering. While Table <a 
href="#x1-28001r3">3<!--tex4ht:ref: tab:main --></a> shows a summary of our key
results, we present a much larger suite of experiments in Appendix&#x00A0;<a 
href="#x1-110000Q">Q<!--tex4ht:ref: sec:app-more-plots --></a>.
<!--l. 615--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-320005.1"></a><span 
class="ecxc-1095">DataComp </span><span 
class="ecbx-1095">leads to better image-text datasets.</span></span>
We hope <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>catalyzes the search for the next generation of multimodal datasets. Towards this
end, we contribute <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B, which is a direct result of the <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>benchmark workflow.
<span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B is the output from the Image-based <span 
class="cmsy-10x-x-109">&#x2229; </span>CLIP score (L/14 30%) baseline filter at the
<span 
class="ectt-1000">xlarge </span>scale of the filtering track. Our dataset is comprised of 1.4B samples, which is <span 
class="ecti-1095">smaller</span>
than the LAION-2B dataset with 2.3B samples. Additionally, <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B is built from a
smaller pool than the one used to create LAION-2B, which means direct comparisons are
likely skewed in favor of LAION-2B. Nevertheless, a CLIP L/14 trained on <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B
outperforms the LAION-2B competitor by 6.1 percentage points on ImageNet as seen in Table <a 
href="#x1-1001r1">1<!--tex4ht:ref: tab:tab1 --></a>.
Moreover, training on <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>-1B improves ImageNet accuracy by 3.7 percentage points over
OpenAI&#8217;s ViT-L/14 trained with the same compute budget. These results underscore the impact
that <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>can make and provide a promising foundation upon which participants can
build.
                                                                                         
                                                                                         
<!--l. 623--><p class="noindent" ><a 
 id="x1-32001r4"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-32002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;4: </span><span  
class="content">Zero-shot performance for select baselines in the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track. External data sources
can be effective in isolation or in combination with CommonPool. Moreover, upsampling external
curated sources can improve performance. </span></div><!--tex4ht:label?: x1-32001r5 -->
<!--l. 630--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-5" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-5-1g"><col 
id="TBL-5-1"><col 
id="TBL-5-2"><col 
id="TBL-5-3"><col 
id="TBL-5-4"><col 
id="TBL-5-5"><col 
id="TBL-5-6"><col 
id="TBL-5-7"><col 
id="TBL-5-8"><col 
id="TBL-5-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-5-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Scale</span></div>    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-1-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Data source</span></div>                                     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-3"  
class="td11"> <span 
class="ecrm-1000">Dataset </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-4"  
class="td11"> <span 
class="ecrm-1000">Samples </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-6"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-7"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-8"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-9"  
class="td11"> <span 
class="ecrm-1000">Average over </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-2-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-2-2"  
class="td11">                                  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-3"  
class="td11">  <span 
class="ecrm-1000">size    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-4"  
class="td11">  <span 
class="ecrm-1000">seen    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-5"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-6"  
class="td11"> <span 
class="ecrm-1000">dist. shifts </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-7"  
class="td11">       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-8"  
class="td11">         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-2-9"  
class="td11"> <span 
class="ecrm-1000">38 datasets  </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-3-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-5-3-2"  
class="td11"> <span 
class="ecrm-1000">CC12M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-3"  
class="td11"> <span 
class="ecrm-1000">10M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-4"  
class="td11"> <span 
class="ecrm-1000">128M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-5"  
class="td11"> <span 
class="ecrm-1000">0.245 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-6"  
class="td11"> <span 
class="ecrm-1000">0.189 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-7"  
class="td11"> <span 
class="ecrm-1000">0.283 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-8"  
class="td11"> <span 
class="ecrm-1000">0.206 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-9"  
class="td11"> <span 
class="ecrm-1000">0.266</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-4-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-4-2"  
class="td11"> <span 
class="ecrm-1000">YFCC15M                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-3"  
class="td11">  <span 
class="ecrm-1000">15M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-5"  
class="td11">   <span 
class="ecrm-1000">0.232    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-6"  
class="td11">   <span 
class="ecrm-1000">0.137     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-7"  
class="td11"> <span 
class="ecrm-1000">0.263  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-8"  
class="td11">  <span 
class="ecrm-1000">0.174    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-9"  
class="td11">    <span 
class="ecrm-1000">0.251      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-5-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-5-5-2"  
class="td11"> <span 
class="ecrm-1000">RedCaps </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-3"  
class="td11"> <span 
class="ecrm-1000">11M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-4"  
class="td11"> <span 
class="ecrm-1000">128M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-5"  
class="td11"> <span 
class="ecrm-1000">0.237 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-6"  
class="td11"> <span 
class="ecrm-1000">0.166 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-7"  
class="td11"> <span 
class="ecrm-1000">0.271 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-8"  
class="td11"> <span 
class="ecrm-1000">0.150 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-5-9"  
class="td11"> <span 
class="ecrm-1000">0.261</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-6-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-6-2"  
class="td11"> <span 
class="ecrm-1000">Shutterstock                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-3"  
class="td11">  <span 
class="ecrm-1000">58M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-5"  
class="td11">   <span 
class="ecrm-1000">0.342    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-6"  
class="td11">   <span 
class="ecrm-1000">0.209     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-7"  
class="td11"> <span 
class="ecrm-1000">0.364  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-8"  
class="td11">  <span class="underline"><span 
class="ecrm-1000">0.248</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-6-9"  
class="td11">    <span 
class="ecrm-1000">0.323      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-7-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-7-2"  
class="td11"> <span 
class="ecrm-1000">4 external sources                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-3"  
class="td11">  <span 
class="ecrm-1000">109M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.378</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-6"  
class="td11">   <span 
class="ecrm-1000">0.262     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-7"  
class="td11"> <span 
class="ecrm-1000">0.392  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-8"  
class="td11">  <span 
class="ecrm-1000">0.210    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-7-9"  
class="td11">    <span 
class="ecrm-1000">0.348      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-8-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-5-8-2"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span><span 
class="ecrm-1000">, CLIP score filter </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-3"  
class="td11"> <span 
class="ecrm-1000">38M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-4"  
class="td11"> <span 
class="ecrm-1000">128M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-5"  
class="td11"> <span 
class="ecrm-1000">0.273 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-6"  
class="td11"> <span 
class="ecrm-1000">0.230 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-7"  
class="td11"> <span 
class="ecrm-1000">0.338 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-8"  
class="td11"> <span 
class="ecrm-1000">0.183 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-8-9"  
class="td11"> <span 
class="ecrm-1000">0.323</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-9-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">medium</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-9-2"  
class="td11">   <span 
class="ecrm-1000">+ 4 external sources                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-3"  
class="td11">  <span 
class="ecrm-1000">147M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-4"  
class="td11">  <span 
class="ecrm-1000">128M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-5"  
class="td11">   <span 
class="ecrm-1000">0.372    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.269</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.401</span></span>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-8"  
class="td11">  <span 
class="ecrm-1000">0.203    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-9-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.357</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-10-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-10-2"  
class="td11"> <span 
class="ecrm-1000">LAION-2B                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-3"  
class="td11">  <span 
class="ecrm-1000">2.3B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-5"  
class="td11">   <span 
class="ecrm-1000">0.585    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-6"  
class="td11">   <span 
class="ecrm-1000">0.472     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-7"  
class="td11"> <span 
class="ecrm-1000">0.504  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-8"  
class="td11">  <span class="underline"><span 
class="ecrm-1000">0.399</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-10-9"  
class="td11">    <span 
class="ecrm-1000">0.505      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-11-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-5-11-2"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span><span 
class="ecrm-1000">, CLIP score filter </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-3"  
class="td11"> <span 
class="ecrm-1000">0.4B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-4"  
class="td11"> <span 
class="ecrm-1000">1.28B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-5"  
class="td11"> <span 
class="ecrm-1000">0.578 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-6"  
class="td11"> <span 
class="ecrm-1000">0.474 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-7"  
class="td11"> <span 
class="ecrm-1000">0.538 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-8"  
class="td11"> <span 
class="ecrm-1000">0.342 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-11-9"  
class="td11"> <span 
class="ecrm-1000">0.520</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-12-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-12-2"  
class="td11">   <span 
class="ecrm-1000">+ 4 external sources                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-3"  
class="td11">  <span 
class="ecrm-1000">0.5B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-5"  
class="td11">   <span 
class="ecrm-1000">0.609    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-6"  
class="td11">   <span 
class="ecrm-1000">0.508     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-7"  
class="td11"> <span 
class="ecrm-1000">0.546  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-8"  
class="td11">  <span 
class="ecrm-1000">0.303    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-12-9"  
class="td11">    <span 
class="ecrm-1000">0.525      </span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-13-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">large</span></div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-13-2"  
class="td11">   <span 
class="ecrm-1000">+ 4 external sources (upsampled 2x) </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-3"  
class="td11">  <span 
class="ecrm-1000">0.5B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.621</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.509</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.547</span></span>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-8"  
class="td11">  <span 
class="ecrm-1000">0.315    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-13-9"  
class="td11">    <span class="underline"><span 
class="ecrm-1000">0.530</span></span>      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-14-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-14-2"  
class="td11"> <span 
class="ecrm-1000">LAION-2B                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-3"  
class="td11">  <span 
class="ecrm-1000">2.3B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-5"  
class="td11">   <span 
class="ecrm-1000">0.757    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-6"  
class="td11">   <span 
class="ecrm-1000">0.631     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-7"  
class="td11"> <span 
class="ecrm-1000">0.611  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-8"  
class="td11">  <span class="underline"><span 
class="ecrm-1000">0.502</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-14-9"  
class="td11">    <span 
class="ecrm-1000">0.612      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-15-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-5-15-2"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span><span 
class="ecrm-1000">, CLIP score filter </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-3"  
class="td11"> <span 
class="ecrm-1000">3.8B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-4"  
class="td11"> <span 
class="ecrm-1000">12.8B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-5"  
class="td11"> <span 
class="ecrm-1000">0.764 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-6"  
class="td11"> <span 
class="ecrm-1000">0.655 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-7"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.643</span></span> </td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-8"  
class="td11"> <span 
class="ecrm-1000">0.468 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-5-15-9"  
class="td11"> <span class="underline"><span 
class="ecrm-1000">0.641</span></span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-16-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">xlarge</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-5-16-2"  
class="td11">   <span 
class="ecrm-1000">+ 4 external sources (upsampled 6x) </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-3"  
class="td11">  <span 
class="ecrm-1000">3.9B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-5"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.776</span></span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-6"  
class="td11">   <span class="underline"><span 
class="ecrm-1000">0.671</span></span>     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-7"  
class="td11"> <span 
class="ecrm-1000">0.633  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-8"  
class="td11">  <span 
class="ecrm-1000">0.410    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-16-9"  
class="td11">    <span 
class="ecrm-1000">0.638      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-17-1"  
class="td11">        </td></tr></table>                                                                                                                  </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 661--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-330005.1"></a><span 
class="ecbx-1095">External data sources can improve performance.</span></span>
Table <a 
href="#x1-32001r4">4<!--tex4ht:ref: tab:byod --></a> shows results for several baselines in the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track. Compared to the best baselines in the
filtering track, training on each external data source separately for the <span 
class="ectt-1000">medium </span>scale performs worse, but
using all four sources together significantly improves accuracy, especially on ImageNet. At the <span 
class="ectt-1000">large </span>scale,
combining CLIP-filtered data from the filtering track with external data from the four sources further
boosts ImageNet accuracy by up to 4.3 percentage points. This approach also surpasses using
LAION-2B. In Appendix <a 
href="#x1-105000O.2">O.2<!--tex4ht:ref: app:byod --></a> we further examine the external data sources and show additional
experiments.
<!--l. 668--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-340005.1"></a><span 
class="ecbx-1095">English filtering is helpful but not necessary.</span></span>
Given that the prompts used in downstream tasks are in English, a natural question is how critical
is English filtering for achieving good performance. We try filtering our pool by removing
non-English captions, with both cld3 and fasttext as language detectors. Although the two vastly
differ in percentage of English captions detected (20% and 50% respectively), filtering with
both of them results in similar performances at all scales. For basic filtering, English filtering
is a key component in our best performing baselines (see Appendix <a 
href="#x1-110000Q">Q<!--tex4ht:ref: sec:app-more-plots --></a>). On the other hand,
English filtering is not necessary to achieve good performance. When using English filtering in
combination with CLIP score filtering, performance stays the same or decreases at all scales.
Figure&#x00A0;<a 
href="#x1-110007r24">24<!--tex4ht:ref: fig:clip_english --></a> in the appendix suggests that CLIP score filtering implicitly does some English
filtering, which may be a result of the CLIP models being trained on English filtered data
[<a 
href="#Xradford2021learning">104</a>].
<!--l. 674--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-34001r3"></a>
                                                                                         
                                                                                         
<!--l. 676--><p class="noindent" > <img 
src="figures/clip_threshold-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-34002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;3: </span><span  
class="content">Performance of random subsets (dotted line) and CLIP score filtering (solid line) when
varying the subset size. When taking random subsets larger subsets are always better, but other
filtering functions such as CLIP score perform best with subsets of intermediate size.</span></div><!--tex4ht:label?: x1-34001r5 -->
                                                                                         
                                                                                         
<!--l. 679--><p class="noindent" ></div><hr class="endfigure">
<!--l. 681--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-34003r4"></a>
                                                                                         
                                                                                         
<!--l. 683--><p class="noindent" > <img 
src="figures/train_samples_medium-.png" alt="PIC"  
width="446" height="446" >
<a 
 id="x1-34004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;4: </span><span  
class="content">Performance as a function of the number of training samples from the <span 
class="ectt-1000">medium </span>scale. There
is a significant variance in accuracy even when accounting for the size of the training set, suggesting
that size is not the only determining factor of the quality of a dataset. Results for additional scales
are shown in Appendix Figure <a 
href="#x1-110005r23">23<!--tex4ht:ref: fig:training-samples-extra --></a>.</span></div><!--tex4ht:label?: x1-34003r5 -->
                                                                                         
                                                                                         
<!--l. 686--><p class="noindent" ></div><hr class="endfigure">
<!--l. 689--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-350005.1"></a><span 
class="ecbx-1095">Trade-off between data diversity and repetition.</span></span>
When we have large pools of data, is it useful to see samples more than once during training? In Figure <a 
href="#x1-34001r3">3<!--tex4ht:ref: fig:clip-th --></a>,
we show that randomly selecting subsets of the pool typically has little effect or degrades performance;
when only small fractions are used, performance drops substantially. In contrast, when filtering with CLIP
scores, the optimal training set comes from selecting <span 
class="cmsy-10x-x-109">~</span>30% of the pool with the highest scores. The
difference in performance between filtering with CLIP scores and using random subsets while using the
same number of training samples again highlights the importance of different strategies for selecting
samples.
<!--l. 698--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">5.2   </span> <a 
 id="x1-360005.2"></a><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>design analyses</h4>
<!--l. 700--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-370005.2"></a><span 
class="ecxc-1095">CommonPool </span><span 
class="ecbx-1095">and LAION are comparable with the same filtering.</span></span>
To validate our pool construction, we show that we can build datasets comparable to LAION-2B by
employing their filtering technique on our pool. LAION-2B selects all samples where the caption
is in English and the cosine similarity score from a trained ViT-B/32 CLIP model is above
0.28. We compare this filtering approach on our pool using the same number samples, 130M
samples at the <span 
class="ectt-1000">large </span>scale. Our experiments show that the different data sources perform
comparably when using the same filtering strategy: 55.3% vs 55.7% accuracy on ImageNet, and
0.491 vs 0.479 average performance over our evaluation sets using our pool and LAION-2B,
respectively.
<!--l. 705--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-380005.2"></a><span 
class="ecbx-1095">Training set size alone does not explain performance.</span></span>
We find a significant variation in accuracy even when accounting for the size of the filtered training set at a
given scale. As shown in Figure <a 
href="#x1-34003r4">4<!--tex4ht:ref: fig:training-samples --></a>, different choices of filtering can substantially impact performance, even
when the size of the resulting dataset is comparable and the scale is fixed. For example, cld3 English
filtering and CLIP score top 20% are almost the same size, yet the CLIP score approach performs
substantially better at all scales.
<!--l. 710--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-390005.2"></a><span 
class="ecbx-1095">Consistency across scales.</span></span>
We find that the ranking between filtering strategies is typically consistent across different scales. This is
illustrated in Figure&#x00A0;<a 
href="#x1-39001r5">5<!--tex4ht:ref: fig:scaling-scatter --></a>, which shows that the baselines at <span 
class="ectt-1000">small </span>and <span 
class="ectt-1000">medium </span>scales are positively correlated.
Moreover, as shown in Table <a 
href="#x1-110003r20">20<!--tex4ht:ref: tab:correlation --></a> in the appendix, the rank correlations of performance is high, between 0.74
and 0.90 for different scale pairs.
<!--l. 712--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-39001r5"></a>
                                                                                         
                                                                                         
<!--l. 714--><p class="noindent" > <img 
src="figures/scaling_scatter_mini-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-39002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;5:  </span><span  
class="content">Correlation  between  performance  at  <span 
class="ectt-1000">small </span>and  <span 
class="ectt-1000">medium </span>scales  for  various  filtering
strategies. The trends suggest that experiments at smaller scales can serve as useful guides for larger
scales. Results for additional scales are shown in Appendix Figure <a 
href="#x1-110001r22">22<!--tex4ht:ref: fig:scaling-scatter-full --></a>. </span></div><!--tex4ht:label?: x1-39001r5 -->
                                                                                         
                                                                                         
<!--l. 718--><p class="noindent" ></div><hr class="endfigure">
<!--l. 720--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-400005.2"></a><span 
class="ecbx-1095">Consistency across training hyperparameters.</span></span>
One potential concern is that modifying training hyperparameters changes the relative ordering of different
data curation methods in terms of downstream performance. To test this, we examine the effect of
increasing the number of training steps in <span 
class="ectt-1000">small </span>filtering track baselines by 10<span 
class="cmsy-10x-x-109">&#x00D7;</span>. We find a rank correlation
of 0.71 on zero-shot average performance. Though varying training hyperparameters can change the
optimal filtering method, these initial experiments suggest that the ordering is relatively stable. For more
information see Appendix <a 
href="#x1-89000L">L<!--tex4ht:ref: app:steps --></a>.
<!--l. 726--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">5.3   </span> <a 
 id="x1-410005.3"></a>Evaluation trends</h4>
<!--l. 728--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-420005.3"></a><span 
class="ecbx-1095">ImageNet accuracy is indicative, but not the complete picture.</span></span>
Similarly to Kornblith et&#x00A0;al.&#x00A0;[<a 
href="#Xkornblith2019better">77</a>], in Appendix Figure&#x00A0;<a 
href="#x1-110009r25">25<!--tex4ht:ref: fig:imagenet-vs-all --></a> we find that ImageNet performance is highly correlated
with the average performance across all datasets we study, with an overall correlation of 0.99 using the full
evaluation suite.<span class="footnote-mark"><a 
href="main7.html#fn6x0"><sup class="textsuperscript">6</sup></a></span><a 
 id="x1-42001f6"></a> 
However, ImageNet performance is not representative of all evaluation tasks, as the correlation between
ImageNet accuracy and accuracy on other individual datasets varies substantially, in some cases even
exhibiting a negative correlation, as discussed in Appendix <a 
href="#x1-110000Q">Q<!--tex4ht:ref: sec:app-more-plots --></a>.
<!--l. 730--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-430005.3"></a><span 
class="ecbx-1095">Robustness and fairness.</span></span>
While typical models trained on a target task suffer large performance drops under data distribution shift,
zero-shot CLIP models exhibit consistently strong performance across a wide range of distributions [<a 
href="#Xradford2021learning">104</a>].
In Appendix Figure <a 
href="#x1-110011r26">26<!--tex4ht:ref: fig:robustness --></a>, we show that models trained with data from our pool are more robust to
distribution shift than ImageNet-trained models trained to the same ImageNet accuracy from Taori
et&#x00A0;al.&#x00A0;[<a 
href="#Xtaori2020measuring">130</a>]&#8217;s testbed. Examining geographic diversity, we find that our models are better than
ImageNet-trained models, but fall short of models fine-tuned on diverse curated datasets (see Appendix
Figure&#x00A0;<a 
href="#x1-108001r21">21<!--tex4ht:ref: fig:robustness_diversity --></a>). We also perform a face classification analysis and identify demographic biases
in our models: notably, introducing the BYOD datasets we consider can increase the risk of
misclassification. Full details of our fairness and diversity analyses are presented in Appendix
<a 
href="#x1-107000P">P<!--tex4ht:ref: app:fairness --></a>.
                                                                                         
                                                                                         
<!--l. 737--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">6   </span> <a 
 id="x1-440006"></a>Conclusion and future work</h3>
<!--l. 740--><p class="noindent" >We introduce <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>, a new benchmark for curating image-text datasets. <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>allows for
controlled experiments in dataset creation, enabling a similar paradigm as that seen in model
development. Our benchmark supports experiments both augmenting our candidate pool with
examples from new data sources, or coming up with new filtering approaches. In either case, our
infrastructure makes experimenting with data curation ideas far simpler than creating an entire large
dataset from scratch, and also provides a controlled environment that allows rigorous empirical
experimentation. We believe that such an approach to dataset development will accelerate progress in
machine learning because key datasets such as ImageNet or LAION-2B are currently rarely
updated (if at all), while researchers develop many generations of new models on the same
dataset.
<!--l. 746--><p class="noindent" >In its current form, <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>is a first step towards improving training datasets. We see several
interesting directions for future work, including:
<!--l. 748--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-450006"></a><span 
class="ecbx-1095">Curating more data sources.</span></span>
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>and LAION-2B only draw text annotations from <span 
class="ectt-1095">alt</span>-text in the HTML <span 
class="ectt-1095">img </span>tags. Parsing
websites more intelligently will likely unlock higher quality text annotations. In addition, identifying
further data repositories and conducting broader or more targeted web crawls will hopefully yield better
training data. Beyond real data, synthetic data from generative models or physics-based rendering are also
promising directions.
<!--l. 753--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-460006"></a><span 
class="ecbx-1095">Improved data filtering.</span></span>
So far we only experimented with basic filtering techniques in our baselines. We expect that better text
processing, using alternative multimodal models as features, or other clustering approaches will result in
better filtering methods for multimodal dataset design.
<!--l. 756--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-470006"></a><span 
class="ecbx-1095">Further supervision signals.</span></span>
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>relies entirely on the original captions from Common Crawl. Running image captioning
models on the collected images may offer an alternative supervision signal and make it possible to train on
images that do not come with a text annotation. In addition, bounding boxes for object detection
or segmentation masks could be further useful information to incorporate into the training
set.
<!--l. 760--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-480006"></a><span 
class="ecbx-1095">More modalities.</span></span>
Beyond image-text pairs, contemporary machine learning relies on many additional forms of large
pre-training datasets. Natural candidates for benchmarks similar to <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>are text, video, structured
documents, 3D objects, or graph-structured data. Moreover, as researchers build foundation models for
                                                                                         
                                                                                         
specific scientific domains such as remote sensing, understanding data curation in specialized domains is
also an important direction for future work.
<!--l. 764--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-490006"></a><span 
class="ecbx-1095">Broader evaluations.</span></span>
Beyond our evaluation suite, researchers could investigate additional domains and tasks such as image
generation, visual question answering, captioning and embodied tasks such as vision-and-language
navigation. Moreover, our evaluation suite could be expanded beyond English to include multilingual
tasks.
<!--l. 767--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-500006"></a><span 
class="ecbx-1095">Extended scaling trends.</span></span>
While medium-scale experiments in <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>usually predict performance at larger scales well, there are
also phenomena that still appear puzzling. For instance, the 12.8M scale does not always predict the larger
scales accurately, and the gains from our current BYOD experiments shrink with increased scale. Reliably
extrapolating these performance changes across compute and data scales would assist future dataset
design. And ideally, experiments on ever smaller scales than 12.8M would yield useful signal. Finally, it
would be important to better characterize how data curation methods compare under different choices for
model size and compute budget.
<!--l. 773--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-510006"></a><span 
class="ecbx-1095">Combining data sources.</span></span>
While combining different data sources often leads to better performance than any individual source, in
many cases the combination is worse than simply using the best source. Even when combining multiple
data sources is productive, there is still the question of whether and by how much to upsample each source,
which has a direct impact on performance. While we present related initial experiments in the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>
track, a more complete understanding of the optimal way to combine data sources is an exciting research
direction for future work.
<!--l. 790--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-520006"></a>Acknowledgements</h3>
<!--l. 791--><p class="noindent" >SYG and JH are supported by NSF Graduate Research Fellowships. GS is supported by the Onassis
Foundation - Scholarship ID: F ZS 056-1/2022-2023. GD has been supported by the Onassis
Fellowship (Scholarship ID: F ZS 012-1/2022-2023), the Bodossaki Fellowship and the Leventis
Fellowship. This research has been supported by NSF Grants AF 1901292, CNS 2148141,
DMS 2134012, TRIPODS II-DMS 2023166, Tripods CCF 1934932, IFML CCF 2019844 and
research gifts by Western Digital, WNCG IAP, UT Austin Machine Learning Lab (MLL),
Cisco, the Len Blavatnik and the Blavatnik Family Foundation, the Stanly P. Finch Centennial
Professorship in Engineering, Open Philanthropy, Google, Microsoft, and the Allen Institute for
AI.
                                                                                         
                                                                                         
<!--l. 793--><p class="noindent" >We thank Stability AI and the Gauss Centre for Supercomputing
e.V.<span class="footnote-mark"><a 
href="main8.html#fn7x0"><sup class="textsuperscript">7</sup></a></span><a 
 id="x1-52001f7"></a> 
for providing us with compute resources to train models. We are thankful for the compute time provided
through the John von Neumann Institute for Computing (NIC) on the GCS Supercomputer JUWELS
Booster [<a 
href="#XJUWELSBooster2020">70</a>] at Jlich Supercomputing Centre (JSC), and for storage resources on JUST [<a 
href="#Xgraf2021just">46</a>] granted and
operated by JSC, as well as computing and storage resources from the Helmholtz Data Federation
(HDF).
<!--l. 795--><p class="noindent" >We would like to thank Amro Abbas, Danny Bickson, Alper Canberk, Jessie Chapman, Brian Cheung,
Tim Dettmers, Joshua Gardner, Nancy Garland, Sachin Goyal, Huy Ha, Zaid Harchaoui, Ari
Holtzman, Andrew Hundt, Andy Jones, Adam Klivans, Ronak Mehta, Sachit Menon, Ari
Morcos, Raviteja Mullapudi, Jonathon Shlens, Brandon McKinzie, Alexander Toshev, David
Grangier, Navdeep Jaitly, Kentrell Owens, Marco Tulio Ribeiro, Shiori Sagawa, Christoph
Schuhmann, Matthew Wallingford, and Ross Wightman for helpful feedback at various stages of the
project.
<!--l. 797--><p class="noindent" >We are particularly grateful to Daniel Levy and Alec Radford for early encouragement to pursue this
project and feedback on the experimental design.
                                                                                         
                                                                                         
<h3 class="likesectionHead"><a 
 id="x1-530006"></a>References</h3>
<!--l. 1--><p class="noindent" >
     <div class="thebibliography">
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xcld3"></a>[1] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>CLD3. <a 
href="https://github.com/google/cld3" class="url" ><span 
class="ectt-1095">https://github.com/google/cld3</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xabbas2023semdedup"></a>[2] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Amro  Abbas,  Kushal  Tirumala,  Dniel  Simig,  Surya  Ganguli,  and  Ari&#x00A0;S  Morcos.
     Semdedup:  Data-efficient  learning  at  web-scale  through  semantic  deduplication,  2023.
     <a 
href="https://arxiv.org/abs/2303.09540" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2303.09540</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xagarwal2004approximating"></a>[3] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Pankaj&#x00A0;K.          Agarwal,          Sariel          Har-Peled,          and          Kasturi&#x00A0;R.
     Varadarajan. Approximating extent measures of points. <span 
class="ecti-1095">Journal of the ACM (JACM)</span>, 2004.
     <a 
href="https://doi.org/10.1145/1008731.1008736" class="url" ><span 
class="ectt-1095">https://doi.org/10.1145/1008731.1008736</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xalayrac2022flamingo"></a>[4] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson,
     Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds, et&#x00A0;al.  Flamingo: a visual
     language model for few-shot learning. In <span 
class="ecti-1095">Advances in Neural Information Processing Systems</span>
     <span 
class="ecti-1095">(NeurIPS)</span>, 2022. <a 
href="https://openreview.net/forum?id=EbMuimAbPbs" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=EbMuimAbPbs</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="XAwasthi2020Learning"></a>[5] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal, and Sunita Sarawagi.  Learning from
     rules generalizing labeled exemplars. In <span 
class="ecti-1095">International Conference on Learning Representations</span>
     <span 
class="ecti-1095">(ICLR)</span>, 2020. <a 
href="https://openreview.net/forum?id=SkeuexBtDr" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=SkeuexBtDr</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xbach2019snorkel"></a>[6] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Stephen&#x00A0;H Bach, Daniel Rodriguez, Yintao Liu, Chong Luo, Haidong Shao, Cassandra
     Xia, Souvik Sen, Alex Ratner, Braden Hancock, Houman Alborzi, Rahul Kuchhal, Christopher
     R,  and  Rob  Malkin.   Snorkel  drybell:  A  case  study  in  deploying  weak  supervision  at
     industrial  scale.    In  <span 
class="ecti-1095">Special  Interest  Group  on  Management  of  Data  (SIGMOD)</span>,  2019.
     <a 
href="https://arxiv.org/abs/1812.00417" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1812.00417</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xpmlr-v37-bachem15"></a>[7] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Olivier Bachem, Mario Lucic, and Andreas Krause. Coresets for nonparametric estimation
     - the case of dp-means.  In <span 
class="ecti-1095">International Conference on Machine Learning (ICML)</span>, 2015.
     <a 
href="https://proceedings.mlr.press/v37/bachem15.html" class="url" ><span 
class="ectt-1095">https://proceedings.mlr.press/v37/bachem15.html</span></a>.
     </p>
                                                                                         
                                                                                         
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xbandi2018detection"></a>[8] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Peter Bandi, Oscar Geessink, Quirine Manson, Marcory Van&#x00A0;Dijk, Maschenka Balkenhol,
     Meyke  Hermsen,  Babak&#x00A0;Ehteshami  Bejnordi,  Byungjae  Lee,  Kyunghyun  Paeng,  Aoxiao
     Zhong, et&#x00A0;al. From detection of individual metastases to classification of lymph node status
     at the patient level: the camelyon17 challenge. <span 
class="ecti-1095">IEEE Transactions on Medical Imaging</span>, 2018.
     <a 
href="https://pubmed.ncbi.nlm.nih.gov/30716025/" class="url" ><span 
class="ectt-1095">https://pubmed.ncbi.nlm.nih.gov/30716025/</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
  <a 
 id="Xobjectnet"></a>[9] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Andrei  Barbu,  David  Mayo,  Julian  Alverio,  William  Luo,  Christopher  Wang,  Dan
     Gutfreund,  Josh  Tenenbaum,  and  Boris  Katz.    Objectnet:  A  large-scale  bias-controlled
     dataset for pushing the limits of object recognition models.  In H.&#x00A0;Wallach, H.&#x00A0;Larochelle,
     A.&#x00A0;Beygelzimer,  F.&#x00A0;d<span 
class="tcrm-1095">'</span>Alch-Buc,  E.&#x00A0;Fox,  and  R.&#x00A0;Garnett  (eds.),  <span 
class="ecti-1095">Advances  in  Neural</span>
     <span 
class="ecti-1095">Information  Processing  Systems  (NeurIPS)</span>,  volume&#x00A0;32.  Curran  Associates,  Inc.,  2019.
     <a 
href="https://proceedings.neurips.cc/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf" class="url" ><span 
class="ectt-1095">https://proceedings.neurips.cc/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xbeery2020iwildcam"></a>[10] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Sara Beery, Elijah Cole, and Arvi Gjoka.  The iwildcam 2020 competition dataset, 2020.
     <a 
href="https://arxiv.org/abs/2004.10340" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2004.10340</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="XBirhane2021MultimodalDM"></a>[11] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Abeba          Birhane,          Vinay&#x00A0;Uday          Prabhu,          and          Emmanuel
     Kahembwe.  Multimodal datasets: misogyny, pornography, and malignant stereotypes.  2021.
     <a 
href="https://arxiv.org/abs/2110.01963" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2110.01963</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xbirodkar2019semantic"></a>[12] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Vighnesh  Birodkar,  Hossein  Mobahi,  and  Samy  Bengio.    Semantic  redundancies  in
     image-classification datasets: The 10% you don&#8217;t need. <span 
class="ecti-1095">arXiv preprint arXiv:1901.11409</span>, 2019.
     <a 
href="https://arxiv.org/abs/1901.11409" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1901.11409</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xbitton2022winogavil"></a>[13] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Yonatan Bitton, Nitzan&#x00A0;Bitton Guetta, Ron Yosef, Yuval Elovici, Mohit Bansal, Gabriel
     Stanovsky, and Roy Schwartz.  WinoGAViL: Gamified association benchmark to challenge
     vision-and-language models, 2022. <a 
href="https://arxiv.org/abs/2207.12576" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2207.12576</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xfood101"></a>[14] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Lukas Bossard, Matthieu Guillaumin, and Luc Van&#x00A0;Gool. Food-101&#8211;mining discriminative
     components with random forests. In <span 
class="ecti-1095">European Conference on Computer Vision (ECCV)</span>, 2014.
     <a 
href="https://link.springer.com/chapter/10.1007/978-3-319-10599-4_29" class="url" ><span 
class="ectt-1095">https://link.springer.com/chapter/10.1007/978-3-319-10599-4_29</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xgpt3"></a>[15] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&#x00A0;D Kaplan, Prafulla
     Dhariwal,  Arvind  Neelakantan,  Pranav  Shyam,  Girish  Sastry,  Amanda  Askell,  Sandhini
                                                                                         
                                                                                         
     Agarwal,  Ariel  Herbert-Voss,  Gretchen  Krueger,  Tom  Henighan,  Rewon  Child,  Aditya
     Ramesh,  Daniel  Ziegler,  Jeffrey  Wu,  Clemens  Winter,  Chris  Hesse,  Mark  Chen,  Eric
     Sigler,  Mateusz  Litwin,  Scott  Gray,  Benjamin  Chess,  Jack  Clark,  Christopher  Berner,
     Sam  McCandlish,  Alec  Radford,  Ilya  Sutskever,  and  Dario  Amodei.    Language  models
     are  few-shot  learners.     In  H.&#x00A0;Larochelle,  M.&#x00A0;Ranzato,  R.&#x00A0;Hadsell,  M.F.  Balcan,  and
     H.&#x00A0;Lin  (eds.),  <span 
class="ecti-1095">Advances  in  Neural  Information  Processing  Systems  (NeurIPS)</span>,  2020.
     <a 
href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" class="url" ><span 
class="ectt-1095">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcoyo700m"></a>[16] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Minwoo                 Byeon,                 Beomhee                 Park,                 Haecheon
     Kim, Sungjun Lee, Woonhyuk Baek, and Saehoon Kim. Coyo-700m: Image-text pair dataset.
     <a 
href="https://github.com/kakaobrain/coyo-dataset" class="url" ><span 
class="ectt-1095">https://github.com/kakaobrain/coyo-dataset</span></a>, 2022.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcaballero2022broken"></a>[17] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ethan  Caballero,  Kshitij  Gupta,  Irina  Rish,  and  David  Krueger.     Broken  neural
     scaling  laws.      <span 
class="ecti-1095">International  Conference  on  Learning  Representations  (ICLR)</span>,  2023.
     <a 
href="https://arxiv.org/abs/2210.14891" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2210.14891</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcarlini2023poisoning"></a>[18] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Nicholas Carlini, Matthew Jagielski, Christopher&#x00A0;A Choquette-Choo, Daniel Paleka, Will
     Pearce, Hyrum Anderson, Andreas Terzis, Kurt Thomas, and Florian Tramr.   Poisoning
     web-scale training datasets is practical, 2023. <a 
href="https://arxiv.org/abs/2302.10149" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2302.10149</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xchan2022data"></a>[19] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Stephanie C.&#x00A0;Y. Chan, Adam Santoro, Andrew&#x00A0;K. Lampinen, Jane&#x00A0;X. Wang, Aaditya
     Singh, Pierre&#x00A0;H. Richemond, Jay McClelland, and Felix Hill.  Data distributional properties
     drive  emergent  in-context  learning  in  transformers.   In  <span 
class="ecti-1095">Advances  in  Neural  Information</span>
     <span 
class="ecti-1095">Processing Systems (NeurIPS)</span>, 2022. <a 
href="https://arxiv.org/abs/2205.05055" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2205.05055</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xchangpinyo2021conceptual"></a>[20] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Soravit                                                                                           Changpinyo,
     Piyush Sharma, Nan Ding, and Radu Soricut. Conceptual 12m: Pushing web-scale image-text
     pre-training to recognize long-tail visual concepts.  In <span 
class="ecti-1095">Conference on Computer Vision and</span>
     <span 
class="ecti-1095">Pattern Recognition (CVPR)</span>, 2021. <a 
href="https://arxiv.org/abs/2102.08981" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2102.08981</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xchen2022pali"></a>[21] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Xi&#x00A0;Chen,  Xiao  Wang,  Soravit  Changpinyo,  AJ&#x00A0;Piergiovanni,  Piotr  Padlewski,  Daniel
     Salz,   Sebastian   Goodman,   Adam   Grycner,   Basil   Mustafa,   Lucas   Beyer,   Alexander
     Kolesnikov,  Joan  Puigcerver,  Nan  Ding,  Keran  Rong,  Hassan  Akbari,  Gaurav  Mishra,
     Linting  Xue,  Ashish  Thapliyal,  James  Bradbury,  Weicheng  Kuo,  Mojtaba  Seyedhosseini,
     Chao  Jia,  Burcu&#x00A0;Karagol  Ayan,  Carlos  Riquelme,  Andreas  Steiner,  Anelia  Angelova,
     Xiaohua  Zhai,  Neil  Houlsby,  and  Radu  Soricut.     Pali:  A  jointly-scaled  multilingual
                                                                                         
                                                                                         
     language-image model.   In <span 
class="ecti-1095">International Conference on Learning Representations (ICLR)</span>,
     2022. <a 
href="https://arxiv.org/abs/2209.06794" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2209.06794</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xmscoco"></a>[22] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
     Dollr, and C&#x00A0;Lawrence Zitnick.  Microsoft COCO captions: Data collection and evaluation
     server, 2015. <a 
href="https://arxiv.org/abs/1504.00325" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1504.00325</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xresisc45"></a>[23] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Gong Cheng, Junwei Han, and Xiaoqiang Lu. Remote sensing image scene classification:
     Benchmark and state of the art.  <span 
class="ecti-1095">Proceedings of the Institute of Electrical and Electronics</span>
     <span 
class="ecti-1095">Engineers (IEEE)</span>, 2017. <a 
href="https://ieeexplore.ieee.org/abstract/document/7891544" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/abstract/document/7891544</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcherti2022reproducible"></a>[24] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mehdi Cherti, Romain Beaumont, Ross Wightman, Mitchell Wortsman, Gabriel Ilharco,
     Cade Gordon, Christoph Schuhmann, Ludwig Schmidt, and Jenia Jitsev. Reproducible scaling
     laws for contrastive language-image learning, 2022. <a 
href="https://arxiv.org/abs/2212.07143" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2212.07143</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xchristie2018functional"></a>[25] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Gordon Christie, Neil Fendley, James Wilson, and Ryan Mukherjee.   Functional map
     of the world.  In <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2018.
     <a 
href="https://arxiv.org/abs/1711.07846" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1711.07846</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdtd"></a>[26] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mircea    Cimpoi,    Subhransu    Maji,    Iasonas    Kokkinos,    Sammy    Mohamed,
     and     Andrea     Vedaldi.             Describing     textures     in     the     wild.             In
     <span 
class="ecti-1095">Conference    on    Computer    Vision    and    Pattern    Recognition    (CVPR)</span>,    2014.
     <a 
href="https://openaccess.thecvf.com/content_cvpr_2014/html/Cimpoi_Describing_Textures_in_2014_CVPR_paper.html" class="url" ><span 
class="ectt-1095">https://openaccess.thecvf.com/content_cvpr_2014/html/Cimpoi_Describing_Textures_in_2014_CVPR_paper.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xstl10"></a>[27] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Adam Coates, Andrew Ng, and Honglak Lee.   An analysis of single-layer networks in
     unsupervised  feature  learning.   In  <span 
class="ecti-1095">International Conference on Artificial Intelligence and</span>
     <span 
class="ecti-1095">Statistics (AISTATS)</span>, 2011. <a 
href="https://proceedings.mlr.press/v15/coates11a.html" class="url" ><span 
class="ectt-1095">https://proceedings.mlr.press/v15/coates11a.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcohen2017input"></a>[28] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Michael&#x00A0;B. Cohen, Cameron Musco, and Christopher Musco. Input sparsity time low-rank
     approximation via ridge leverage score sampling.   In <span 
class="ecti-1095">ACM-SIAM Symposium on Discrete</span>
     <span 
class="ecti-1095">Algorithms</span>, 2017. <a 
href="https://dl.acm.org/doi/10.5555/3039686.3039801" class="url" ><span 
class="ectt-1095">https://dl.acm.org/doi/10.5555/3039686.3039801</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcoleman2020selection"></a>[29] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>C&#x00A0;Coleman,                                                                                           C&#x00A0;Yeh,
                                                                                         
                                                                                         
     S&#x00A0;Mussmann, B&#x00A0;Mirzasoleiman, P&#x00A0;Bailis, P&#x00A0;Liang, J&#x00A0;Leskovec, and M&#x00A0;Zaharia.  Selection
     via proxy: Efficient data selection for deep learning. In <span 
class="ecti-1095">International Conference on Learning</span>
     <span 
class="ecti-1095">Representations (ICLR)</span>, 2020. <a 
href="https://arxiv.org/abs/1906.11829" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1906.11829</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="XConneau2019UnsupervisedCR"></a>[30] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alexis                       Conneau,                       Kartikay                       Khandelwal,
     Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmn, Edouard Grave,
     Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. Unsupervised cross-lingual representation
     learning at scale. In <span 
class="ecti-1095">Annual Meeting of the Association for Computational Linguistics (ACL)</span>,
     2019. <a 
href="https://arxiv.org/abs/1911.02116" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1911.02116</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcook1977detection"></a>[31] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>R&#x00A0;Dennis Cook. Detection of influential observation in linear. <span 
class="ecti-1095">Technometrics</span>, 19(1):15&#8211;18,
     1977.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdave2020tao"></a>[32] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, and Deva Ramanan.
     Tao: A large-scale benchmark for tracking any object. In <span 
class="ecti-1095">European Conference on Computer</span>
     <span 
class="ecti-1095">Vision (ECCV)</span>, 2020. <a 
href="https://arxiv.org/abs/2005.10356" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2005.10356</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdeng2009imagenet"></a>[33] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li&#x00A0;Fei-Fei.   Imagenet: A
     large-scale  hierarchical  image  database.   In  <span 
class="ecti-1095">Conference on Computer Vision and Pattern</span>
     <span 
class="ecti-1095">Recognition (CVPR)</span>, 2009. <a 
href="https://ieeexplore.ieee.org/abstract/document/5206848" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/abstract/document/5206848</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdesai2021redcaps"></a>[34] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Karan        Desai,        Gaurav        Kaul,        Zubin        Aysola,        and        Justin
     Johnson. Redcaps: Web-curated image-text data created by the people, for the people, 2021.
     <a 
href="https://arxiv.org/abs/2111.11431" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2111.11431</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdosovitskiy2021an"></a>[35] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
     Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
     Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image
     recognition at scale. In <span 
class="ecti-1095">International Conference on Learning Representations (ICLR)</span>, 2021.
     <a 
href="https://openreview.net/forum?id=YicbFdNTTy" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=YicbFdNTTy</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdouze2021isc"></a>[36] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Matthijs  Douze,  Giorgos  Tolias,  Ed&#x00A0;Pizzi,  Zo  Papakipos,  Lowik  Chanussot,  Filip
     Radenovic, Tomas Jenicek, Maxim Maximov, Laura Leal-Taix, Ismail Elezi, Ondrej Chum,
     and  Cristian  Canton-Ferrer.    The  2021  image  similarity  dataset  and  challenge,  2021.
     <a 
href="https://arxiv.org/abs/2106.09672" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2106.09672</span></a>.
                                                                                         
                                                                                         
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xethayarajh2022understanding"></a>[37] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kawin  Ethayarajh,  Yejin  Choi,  and  Swabha  Swayamdipta.    Understanding  dataset
     difficulty  with  v-usable  information.    In  <span 
class="ecti-1095">International  Conference  on  Machine  Learning</span>
     <span 
class="ecti-1095">(ICML)</span>, 2022. <a 
href="https://arxiv.org/abs/2110.08420" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2110.08420</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xpascal-voc-2007"></a>[38] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>M.&#x00A0;Everingham,   L.&#x00A0;Van&#x00A0;Gool,   C.&#x00A0;K.&#x00A0;I.   Williams,   J.&#x00A0;Winn,   and   A.&#x00A0;Zisserman.
     The   PASCAL   Visual   Object   Classes   Challenge   2007   (VOC2007)   Results,   2007.
     <a 
href="http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html" class="url" ><span 
class="ectt-1095">http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdcbench"></a>[39] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Sabri Eyuboglu, Bojan Karla&#353;, Christopher R, Ce&#x00A0;Zhang, and James Zou.  dcbench: a
     benchmark           for           data-centric           ai           systems.                              In
     <span 
class="ecti-1095">Proceedings of the Sixth Workshop on Data Management for End-To-End Machine Learning</span>,
     2022. <a 
href="https://dl.acm.org/doi/abs/10.1145/3533028.3533310" class="url" ><span 
class="ectt-1095">https://dl.acm.org/doi/abs/10.1145/3533028.3533310</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xfang2022data"></a>[40] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alex Fang, Gabriel Ilharco, Mitchell Wortsman, Yuhao Wan, Vaishaal Shankar, Achal
     Dave, and Ludwig Schmidt. Data determines distributional robustness in contrastive language
     image pre-training (clip).  In <span 
class="ecti-1095">International Conference on Machine Learning (ICML)</span>, 2022.
     <a 
href="https://arxiv.org/abs/2205.01397" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2205.01397</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcaltech101"></a>[41] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Li&#x00A0;Fei-Fei,  Rob  Fergus,  and  Pietro  Perona.     Learning  generative  visual  models
     from  few  training  examples:  An  incremental  Bayesian  approach  tested  on  101  object
     categories. <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition (CVPR) Workshop</span>, 2004.
     <a 
href="https://ieeexplore.ieee.org/document/1384978" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/document/1384978</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="XFeldman2011Scalable"></a>[42] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Dan Feldman, Matthew Faulkner, and Andreas Krause.   Scalable training of mixture
     models via coresets. In <span 
class="ecti-1095">Advances in Neural Information Processing Systems (NeuIPS)</span>, 2011.
     <a 
href="https://proceedings.neurips.cc/paper\_files/paper/2011/file/2b6d65b9a9445c4271ab9076ead5605a-Paper.pdf" class="url" ><span 
class="ectt-1095">https://proceedings.neurips.cc/paper\_files/paper/2011/file/2b6d65b9a9445c4271ab9076ead5605a-Paper.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xfu2020fast"></a>[43] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Daniel&#x00A0;Y.  Fu,  Mayee&#x00A0;F.  Chen,  Frederic  Sala,  Sarah&#x00A0;M.  Hooper,  Kayvon  Fatahalian,
     and   Christopher   R.      Fast   and   three-rious:   Speeding   up   weak   supervision   with
     triplet  methods.     In  <span 
class="ecti-1095">International  Conference  on  Machine  Learning  (ICML)</span>,  2020.
     <a 
href="https://arxiv.org/abs/2002.11955" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2002.11955</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkitti"></a>[44] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving?
                                                                                         
                                                                                         
     the kitti vision benchmark suite. In <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition</span>
     <span 
class="ecti-1095">(CVPR)</span>, 2012. <a 
href="https://ieeexplore.ieee.org/abstract/document/6248074" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/abstract/document/6248074</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xghorbani2019data"></a>[45] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Amirata Ghorbani and James Zou. Data shapley: Equitable valuation of data for machine
     learning. In <span 
class="ecti-1095">International Conference on Machine Learning</span>, pp.&#x00A0;2242&#8211;2251. PMLR, 2019.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xgraf2021just"></a>[46] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Stephan Graf and Olaf Mextorf. Just: Large-scale multi-tier storage infrastructure at the
     jlich supercomputing centre. <span 
class="ecti-1095">Journal of large-scale research facilities JLSRF</span>, 7:180, 2021.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xguo2022deepcore"></a>[47] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Chengcheng Guo, Bo&#x00A0;Zhao, and Yanbing Bai.  Deepcore: A comprehensive library for
     coreset selection in deep learning, 2022. <a 
href="https://arxiv.org/abs/2204.08499" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2204.08499</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xguo2020fastif"></a>[48] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Han Guo, Nazneen&#x00A0;Fatema Rajani, Peter Hase, Mohit Bansal, and Caiming Xiong. Fastif:
     Scalable influence functions for efficient model interpretation and debugging.  <span 
class="ecti-1095">arXiv preprint</span>
     <span 
class="ecti-1095">arXiv:2012.15781</span>, 2020.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xguo2021sample"></a>[49] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jia  Guo,  Jiankang  Deng,  Alexandros  Lattas,  and  Stefanos  Zafeiriou.    Sample  and
     computation  redistribution  for  efficient  face  detection.    In  <span 
class="ecti-1095">International  Conference  on</span>
     <span 
class="ecti-1095">Learning Representations (ICLR)</span>, 2021. <a 
href="https://arxiv.org/abs/2105.04714" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2105.04714</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xgururangan-etal-2018-annotation"></a>[50] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman,
     and Noah&#x00A0;A. Smith. Annotation artifacts in natural language inference data. In <span 
class="ecti-1095">Conference</span>
     <span 
class="ecti-1095">of the North American Chapter of the Association for Computational Linguistics (NAACL)</span>,
     2018. <a 
href="https://aclanthology.org/N18-2017" class="url" ><span 
class="ectt-1095">https://aclanthology.org/N18-2017</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xguu2023simfluence"></a>[51] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kelvin Guu, Albert Webson, Ellie Pavlick, Lucas Dixon, Ian Tenney, and Tolga Bolukbasi.
     Simfluence: Modeling the influence of individual training examples by simulating training
     runs. <span 
class="ecti-1095">arXiv preprint arXiv:2303.08114</span>, 2023.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xhampel1974influence"></a>[52] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Frank&#x00A0;R Hampel.  The influence curve and its role in robust estimation.  <span 
class="ecti-1095">Journal of the</span>
     <span 
class="ecti-1095">american statistical association</span>, 69(346):383&#8211;393, 1974.
     </p>
                                                                                         
                                                                                         
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xhan2020explaining"></a>[53] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Xiaochuang Han, Byron&#x00A0;C Wallace, and Yulia Tsvetkov. Explaining black box predictions
     and unveiling data artifacts through influence functions.  <span 
class="ecti-1095">arXiv preprint arXiv:2005.06676</span>,
     2020.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="XDetoxify"></a>[54] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Laura        Hanu        and        Unitary        team.                      Detoxify,        2020.
     <a 
href="https://github.com/unitaryai/detoxify" class="url" ><span 
class="ectt-1095">https://github.com/unitaryai/detoxify</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xharpeled2004coresets"></a>[55] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Sariel       Har-Peled       and       Soham       Mazumdar.                   On       coresets
     for k-means and k-median clustering. In <span 
class="ecti-1095">Symposium on Theory of Computing (STOC)</span>, 2004.
     <a 
href="https://doi.org/10.1145/1007352.1007400" class="url" ><span 
class="ectt-1095">https://doi.org/10.1145/1007352.1007400</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xhe2016deep"></a>[56] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.  Deep residual learning for
     image recognition.   In <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
     2016. <a 
href="https://arxiv.org/abs/1512.03385" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1512.03385</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xeurosat"></a>[57] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Patrick  Helber,  Benjamin  Bischke,  Andreas  Dengel,  and  Damian  Borth.   Eurosat:  A
     novel  dataset  and  deep  learning  benchmark  for  land  use  and  land  cover  classification.
     <span 
class="ecti-1095">Journal  of  Selected  Topics  in  Applied  Earth  Observations  and  Remote  Sensing</span>,  2019.
     <a 
href="https://arxiv.org/abs/1709.00029" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1709.00029</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Ximagenetr"></a>[58] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Dan  Hendrycks,  Steven  Basart,  Norman  Mu,  Saurav  Kadavath,  Frank  Wang,  Evan
     Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt,
     and Justin Gilmer.  The many faces of robustness: A critical analysis of out-of-distribution
     generalization. <span 
class="ecti-1095">ICCV</span>, 2021. <a 
href="https://arxiv.org/abs/2006.16241" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2006.16241</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Ximageneta_and_imageneto"></a>[59] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural
     adversarial examples.  In <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
     2021. <a 
href="https://arxiv.org/abs/1907.07174" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1907.07174</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xchinchilla"></a>[60] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai,
     Eliza        Rutherford,        Diego        de&#x00A0;Las        Casas,        Lisa&#x00A0;Anne        Hendricks,
     Johannes Welbl, Aidan Clark, et&#x00A0;al. Training compute-optimal large language models, 2022.
     <a 
href="https://arxiv.org/abs/2203.15556" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2203.15556</span></a>.
                                                                                         
                                                                                         
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xhoffmann2011knowledge"></a>[61] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Raphael  Hoffmann,  Congle  Zhang,  Xiao  Ling,  Luke  Zettlemoyer,  and  Daniel&#x00A0;S Weld.
     Knowledge-based  weak  supervision  for  information  extraction  of  overlapping  relations.
     In   <span 
class="ecti-1095">Annual  Meeting  of  the  Association  for  Computational  Linguistics  (ACL)</span>,   2011.
     <a 
href="https://aclanthology.org/P11-1055/" class="url" ><span 
class="ectt-1095">https://aclanthology.org/P11-1055/</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xilharco2021openclip"></a>[62] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas Carlini,
     Rohan   Taori,   Achal   Dave,   Vaishaal   Shankar,   Hongseok   Namkoong,   John   Miller,
     Hannaneh   Hajishirzi,   Ali   Farhadi,   and   Ludwig   Schmidt.      OpenCLIP,   July   2021.
     <a 
href="https://doi.org/10.5281/zenodo.5143773" class="url" ><span 
class="ectt-1095">https://doi.org/10.5281/zenodo.5143773</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xilyas2022datamodels"></a>[63] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Andrew            Ilyas,            Sung&#x00A0;Min            Park,            Logan            Engstrom,
     Guillaume Leclerc, and Aleksander Madry. Datamodels: Predicting predictions from training
     data, 2022. <a 
href="https://arxiv.org/abs/2202.00622" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2202.00622</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xidealods2019imagededup"></a>[64] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Tanuj  Jain,  Christopher  Lennan,  Zubin  John,  and  Dat  Tran.    Imagededup,  2019.
     <a 
href="https://github.com/idealo/imagededup" class="url" ><span 
class="ectt-1095">https://github.com/idealo/imagededup</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xjia2021scaling"></a>[65] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Chao  Jia,  Yinfei  Yang,  Ye&#x00A0;Xia,  Yi-Ting  Chen,  Zarana  Parekh,  Hieu  Pham,  Quoc&#x00A0;V
     Le,  Yunhsuan  Sung,  Zhen  Li,  and  Tom  Duerig.   Scaling  up  visual  and  vision-language
     representation learning with noisy text supervision. In <span 
class="ecti-1095">International Conference on Machine</span>
     <span 
class="ecti-1095">Learning (ICML)</span>, 2021. <a 
href="https://arxiv.org/abs/2102.05918" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2102.05918</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xjiang2001two"></a>[66] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mon-Fong Jiang, Shian-Shyong Tseng, and Chih-Ming Su.  Two-phase clustering process
     for       outliers       detection.                    <span 
class="ecti-1095">Pattern      recognition      letters</span>,       2001.
     <a 
href="https://www.sciencedirect.com/science/article/abs/pii/S0167865500001318" class="url" ><span 
class="ectt-1095">https://www.sciencedirect.com/science/article/abs/pii/S0167865500001318</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xjohnson2019billion"></a>[67] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jeff Johnson, Matthijs Douze, and Herv Jgou. Billion-scale similarity search with GPUs.
     <span 
class="ecti-1095">IEEE Transactions on Big Data</span>, 2019. <a 
href="https://arxiv.org/abs/1702.08734" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1702.08734</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xclevr"></a>[68] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Justin Johnson, Bharath Hariharan, Laurens van&#x00A0;der Maaten, Li&#x00A0;Fei-Fei, C.&#x00A0;Lawrence
     Zitnick, and Ross&#x00A0;B. Girshick.   CLEVR: A diagnostic dataset for compositional language
     and elementary visual reasoning.  <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition</span>
     <span 
class="ecti-1095">(CVPR)</span>, 2017. <a 
href="https://arxiv.org/abs/1612.06890" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1612.06890</span></a>.
                                                                                         
                                                                                         
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xjoulin2017bag"></a>[69] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov.  Bag of tricks
     for efficient text classification. In <span 
class="ecti-1095">Conference of the European Chapter of the Association for</span>
     <span 
class="ecti-1095">Computational Linguistics (EACL)</span>, 2017. <a 
href="https://arxiv.org/abs/1607.01759" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1607.01759</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="XJUWELSBooster2020"></a>[70] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Juelich    Supercomputing    Center.         JUWELS    Booster    Supercomputer,    2020.
     <a 
href="https://apps.fz-juelich.de/jsc/hps/juwels/configuration.html\#hardware-configuration-of-the-system-name-booster-module" class="url" ><span 
class="ectt-1095">https://apps.fz-juelich.de/jsc/hps/juwels/configuration.html\#hardware-configuration-of-the-system-name-booster-module</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkaplan2020scaling"></a>[71] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jared Kaplan, Sam McCandlish, Tom Henighan, Tom&#x00A0;B Brown, Benjamin Chess, Rewon
     Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.  Scaling laws for neural
     language models, 2020. <a 
href="https://arxiv.org/abs/2001.08361" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2001.08361</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkarkkainen2021fairface"></a>[72] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kimmo Karkkainen and Jungseock Joo. Fairface: Face attribute dataset for balanced race,
     gender, and age for bias measurement and mitigation. In <span 
class="ecti-1095">IEEE/CVF Winter Conference on</span>
     <span 
class="ecti-1095">Applications of Computer Vision</span>, 2021. <a 
href="https://arxiv.org/abs/1908.04913" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1908.04913</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkingma2014adam"></a>[73] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Diederik&#x00A0;P                          Kingma                          and                          Jimmy
     Ba.  Adam: A method for stochastic optimization.  In <span 
class="ecti-1095">International Conference on Learning</span>
     <span 
class="ecti-1095">Representations (ICLR)</span>, 2014. <a 
href="https://arxiv.org/abs/1412.6980" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1412.6980</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkoh2017understanding"></a>[74] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Pang&#x00A0;Wei  Koh  and  Percy  Liang.   Understanding  black-box  predictions  via  influence
     functions. In <span 
class="ecti-1095">International Conference on Machine Learning (ICML)</span>, 2017.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkoh2019accuracy"></a>[75] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Pang&#x00A0;Wei Koh, Kai-Siang Ang, Hubert Teo, and Percy&#x00A0;S Liang.   On the accuracy of
     influence functions for measuring group effects.  <span 
class="ecti-1095">Advances in Neural Information Processing</span>
     <span 
class="ecti-1095">Systems (NeurIPS)</span>, 2019.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xwilds2021"></a>[76] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Pang&#x00A0;Wei  Koh,  Shiori  Sagawa,  Henrik  Marklund,  Sang&#x00A0;Michael  Xie,  Marvin  Zhang,
     Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard&#x00A0;Lanas Phillips, Irena Gao,
     Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton&#x00A0;A. Earnshaw, Imran&#x00A0;S. Haque,
     Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn,
     and Percy Liang.  WILDS: A benchmark of in-the-wild distribution shifts.  In <span 
class="ecti-1095">International</span>
     <span 
class="ecti-1095">Conference on Machine Learning (ICML)</span>, 2021. <a 
href="https://arxiv.org/abs/2012.07421" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2012.07421</span></a>.
                                                                                         
                                                                                         
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkornblith2019better"></a>[77] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Simon  Kornblith,  Jonathon  Shlens,  and  Quoc&#x00A0;V  Le.    Do  better  imagenet  models
     transfer better? In <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2019.
     <a 
href="https://arxiv.org/abs/1805.08974" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1805.08974</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcars"></a>[78] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jonathan       Krause,       Michael       Stark,       Jia       Deng,       and       Li&#x00A0;Fei-Fei.
     3d      object      representations      for      fine-grained      categorization.                  In
     <span 
class="ecti-1095">International    Conference    on    Computer    Vision    Workshops    (ICML)</span>,     2013.
     <a 
href="https://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W19/html/Krause_3D_Object_Representations_2013_ICCV_paper.html" class="url" ><span 
class="ectt-1095">https://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W19/html/Krause_3D_Object_Representations_2013_ICCV_paper.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcifar10andcifar100"></a>[79] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alex Krizhevsky, Geoffrey Hinton, et&#x00A0;al.  Learning multiple layers of features from tiny
     images, 2009. <a 
href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" class="url" ><span 
class="ectt-1095">https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xkrizhevsky2012imagenet"></a>[80] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alex Krizhevsky, Ilya Sutskever, and Geoffrey&#x00A0;E Hinton.   Imagenet classification with
     deep convolutional neural networks.  In <span 
class="ecti-1095">Advances in Neural Information Processing Systems</span>
     <span 
class="ecti-1095">(NeurIPS)</span>, 2012.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xle2020adversarial"></a>[81] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ronan Le&#x00A0;Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew
     Peters, Ashish Sabharwal, and Yejin Choi. Adversarial filters of dataset biases. In <span 
class="ecti-1095">International</span>
     <span 
class="ecti-1095">Conference on Machine Learning (ICML)</span>, 2020. <a 
href="https://arxiv.org/abs/2002.04108" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2002.04108</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xlecun1998mnist"></a>[82] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Yann    LeCun.           The    MNIST    database    of    handwritten    digits,    1998.
     <a 
href="http://yann.lecun.com/exdb/mnist/" class="url" ><span 
class="ectt-1095">http://yann.lecun.com/exdb/mnist/</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="XLee2021DeduplicatingTD"></a>[83] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris
     Callison-Burch, and Nicholas Carlini.  Deduplicating training data makes language models
     better.  In <span 
class="ecti-1095">Annual Meeting of the Association for Computational Linguistics (ACL)</span>, 2021.
     <a 
href="https://arxiv.org/abs/2107.06499" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2107.06499</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xli2019repair"></a>[84] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Yi&#x00A0;Li  and  Nuno  Vasconcelos.     Repair:  Removing  representation  bias  by  dataset
     resampling.   In  <span 
class="ecti-1095">Conference on Computer Vision and Pattern Recognition (CVPR)</span>,  2019.
     <a 
href="https://arxiv.org/abs/1904.07911" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1904.07911</span></a>.
     </p>
                                                                                         
                                                                                         
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xloshchilov2016sgdr"></a>[85] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ilya  Loshchilov  and  Frank  Hutter.    Sgdr:  Stochastic  gradient  descent  with  warm
     restarts.      In   <span 
class="ecti-1095">International  Conference  on  Learning  Representations  (ICLR)</span>,   2016.
     <a 
href="https://arxiv.org/abs/1608.03983" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1608.03983</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xloshchilov2018decoupled"></a>[86] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ilya       Loshchilov       and       Frank       Hutter.                   Decoupled       weight
     decay regularization. In <span 
class="ecti-1095">International Conference on Learning Representations (ICLR)</span>, 2019.
     <a 
href="https://openreview.net/forum?id=Bkg6RiCqY7" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=Bkg6RiCqY7</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xlucic2018gaussian"></a>[87] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mario Lucic, Matthew Faulkner, Andreas Krause, and Dan Feldman.  Training gaussian
     mixture models at scale via coresets.  <span 
class="ecti-1095">Journal of Machine Learning Research (JMLR)</span>, 2018.
     <a 
href="http://jmlr.org/papers/v18/15-506.html" class="url" ><span 
class="ectt-1095">http://jmlr.org/papers/v18/15-506.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xfgvc_aicraft"></a>[88] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>S.&#x00A0;Maji,  J.&#x00A0;Kannala,  E.&#x00A0;Rahtu,  M.&#x00A0;Blaschko,  and  A.&#x00A0;Vedaldi.    Fine-grained  visual
     classification of aircraft, 2013. <a 
href="https://arxiv.org/abs/1306.5151" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1306.5151</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xmann2010generalized"></a>[89] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Gideon&#x00A0;S   Mann   and   Andrew   McCallum.      Generalized   expectation   criteria   for
     semi-supervised learning with weakly labeled data.  <span 
class="ecti-1095">Journal of Machine Learning Research</span>
     <span 
class="ecti-1095">(JMLR)</span>, 2010. <a 
href="https://www.jmlr.org/papers/v11/mann10a.html" class="url" ><span 
class="ectt-1095">https://www.jmlr.org/papers/v11/mann10a.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdataperf"></a>[90] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karla&#353;, William&#x00A0;Gaviria Rojas,
     Sudnya Diamos, Greg Diamos, Lynn He, Douwe Kiela, David Jurado, David Kanter, Rafael
     Mosquera, Juan Ciro, Lora Aroyo, Bilge Acun, Sabri Eyuboglu, Amirata Ghorbani, Emmett
     Goodman, Tariq Kane, Christine&#x00A0;R. Kirkpatrick, Tzu-Sheng Kuo, Jonas Mueller, Tristan
     Thrush,  Joaquin  Vanschoren,  Margaret  Warren,  Adina  Williams,  Serena  Yeung,  Newsha
     Ardalani, Praveen Paritosh, Ce&#x00A0;Zhang, James Zou, Carole-Jean Wu, Cody Coleman, Andrew
     Ng,  Peter  Mattson,  and  Vijay&#x00A0;Janapa  Reddi.   Dataperf:  Benchmarks  for  data-centric  ai
     development, 2022. <a 
href="https://arxiv.org/abs/2207.10062" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2207.10062</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xcraig"></a>[91] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Baharan Mirzasoleiman, Jeff Bilmes, and Jure Leskovec. Coresets for data-efficient training
     of machine learning models. In <span 
class="ecti-1095">International Conference on Machine Learning (ICML)</span>, 2020.
     <a 
href="https://arxiv.org/abs/1906.01827" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1906.01827</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xsvhn"></a>[92] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Yuval   Netzer,   Tao   Wang,   Adam   Coates,   Alessandro   Bissacco,   Bo&#x00A0;Wu,   and
     Andrew&#x00A0;Y  Ng.    Reading  digits  in  natural  images  with  unsupervised  feature  learning.
                                                                                         
                                                                                         
     In  <span 
class="ecti-1095">Advances  in  Neural  Information  Processing  Systems  (NeurIPS)  Workshops</span>,  2011.
     <a 
href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37648.pdf" class="url" ><span 
class="ectt-1095">https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37648.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdatacentric"></a>[93] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Andrew   Ng,   Dillon   Laird,   and   Lynn   He.      Data-centric   ai   competition,   2021.
     <a 
href="https://https-deeplearning-ai. github. io/data-centric-comp/" class="url" ><span 
class="ectt-1095">https://https-deeplearning-ai.github.io/data-centric-comp/</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xnguyen2022quality"></a>[94] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Thao Nguyen, Gabriel Ilharco, Mitchell Wortsman, Sewoong Oh, and Ludwig Schmidt.
     Quality   not   quantity:   On   the   interaction   between   dataset   design   and   robustness
     of  clip.     In  <span 
class="ecti-1095">Advances  in  Neural  Information  Processing  Systems  (NeurIPS)</span>,  2022.
     <a 
href="https://openreview.net/forum?id=LTCBavFWp5C" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=LTCBavFWp5C</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xflowers102"></a>[95] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Maria-Elena Nilsback and Andrew Zisserman. Automated flower classification over a large
     number of classes. In <span 
class="ecti-1095">Indian Conference on Computer Vision, Graphics and Image Processing</span>,
     2008. <a 
href="https://ieeexplore.ieee.org/document/4756141" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/document/4756141</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xgpt4"></a>[96] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>OpenAI. Gpt-4 technical report, 2023. <a 
href="https://arxiv.org/abs/2303.08774" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2303.08774</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xsbu"></a>[97] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Vicente    Ordonez,    Girish    Kulkarni,    and    Tamara&#x00A0;L.    Berg.           Im2text:
     Describing      images      using      1      million      captioned      photographs.               In
     <span 
class="ecti-1095">Advances     in     Neural     Information     Processing     Systems     (NeurIPS)</span>,      2011.
     <a 
href="https://papers.nips.cc/paper_files/paper/2011/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf" class="url" ><span 
class="ectt-1095">https://papers.nips.cc/paper_files/paper/2011/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xpets"></a>[98] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Omkar&#x00A0;M.  Parkhi,  Andrea  Vedaldi,  Andrew  Zisserman,  and  C.&#x00A0;V.  Jawahar.    Cats
     and  dogs.   In  <span 
class="ecti-1095">Conference  on  Computer  Vision  and  Pattern  Recognition  (CVPR)</span>,  2012.
     <a 
href="https://ieeexplore.ieee.org/document/6248092" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/document/6248092</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
 <a 
 id="Xdatadiet"></a>[99] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mansheej  Paul,  Surya  Ganguli,  and  Gintare&#x00A0;Karolina  Dziugaite.   Deep  learning  on  a
     data diet: Finding important examples early in training. In <span 
class="ecti-1095">Advances in Neural Information</span>
     <span 
class="ecti-1095">Processing Systems (NeurIPS)</span>, 2021. <a 
href="https://arxiv.org/abs/2107.07075" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2107.07075</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xpham2021scaling"></a>[100] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Hieu Pham, Zihang Dai, Golnaz Ghiasi, Hanxiao Liu, Adams&#x00A0;Wei Yu, Minh-Thang Luong,
     Mingxing Tan, and Quoc&#x00A0;V. Le.   Combined scaling for zero-shot transfer learning, 2021.
     <a 
href="https://arxiv.org/abs/2111.10050" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2111.10050</span></a>.
                                                                                         
                                                                                         
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XPrabhu2020LargeID"></a>[101] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Vinay&#x00A0;Uday  Prabhu  and  Abeba  Birhane.   Large  image  datasets:  A  pyrrhic  win  for
     computer vision? In <span 
class="ecti-1095">Winter Conference on Applications of Computer Vision (WACV)</span>, 2020.
     <a 
href="https://arxiv.org/abs/2006.16923" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2006.16923</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xpruthi2020estimating"></a>[102] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Garima  Pruthi,  Frederick  Liu,  Satyen  Kale,  and  Mukund  Sundararajan.   Estimating
     training data influence by tracing gradient descent. <span 
class="ecti-1095">Advances in Neural Information Processing</span>
     <span 
class="ecti-1095">Systems (NeurIPS)</span>, 2020. <a 
href="https://arxiv.org/abs/2002.08484" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2002.08484</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrdk+23"></a>[103] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Filip   Radenovic,   Abhimanyu   Dubey,   Abhishek   Kadian,   Todor   Mihaylov,   Simon
     Vandenhende, Yash Patel, Yi&#x00A0;Wen, Vignesh Ramanathan, and Dhruv Mahajan.  Filtering,
     distillation, and hard negatives for vision-language pre-training. In <span 
class="ecti-1095">Conference on Computer</span>
     <span 
class="ecti-1095">Vision and Pattern Recognition (CVPR)</span>, 2023. <a 
href="https://arxiv.org/abs/2301.02280" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2301.02280</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xradford2021learning"></a>[104] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alec   Radford,   Jong&#x00A0;Wook   Kim,   Chris   Hallacy,   Aditya   Ramesh,   Gabriel   Goh,
     Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen
     Krueger,   and   Ilya   Sutskever.      Learning   transferable   visual   models   from   natural
     language  supervision.   In  <span 
class="ecti-1095">International  Conference  on  Machine  Learning  (ICML)</span>,  2021.
     <a 
href="https://arxiv.org/abs/2103.00020" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2103.00020</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xradford2022robust"></a>[105] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alec Radford, Jong&#x00A0;Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya
     Sutskever.   Robust  speech  recognition  via  large-scale  weak  supervision.   <span 
class="ecti-1095">arXiv  preprint</span>
     <span 
class="ecti-1095">arXiv:2212.04356</span>, 2022.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xraffel2020exploring"></a>[106] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Colin  Raffel,  Noam  Shazeer,  Adam  Roberts,  Katherine  Lee,  Sharan  Narang,  Michael
     Matena, Yanqi Zhou, Wei Li, and Peter&#x00A0;J Liu. Exploring the limits of transfer learning with
     a unified text-to-text transformer. <span 
class="ecti-1095">The Journal of Machine Learning Research (JMLR)</span>, 2020.
     <a 
href="https://arxiv.org/abs/1910.10683" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1910.10683</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xramaswamy2022geode"></a>[107] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Vikram&#x00A0;V. Ramaswamy, Sing&#x00A0;Yu Lin, Dora Zhao, Aaron&#x00A0;B. Adcock, Laurens van&#x00A0;der
     Maaten, Deepti Ghadiyaram, and Olga Russakovsky.  Beyond web-scraping: Crowd-sourcing
     a geodiverse datase, 2023. <a 
href="https://arxiv.org/abs/2301.02560" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2301.02560</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xramesh2021zero"></a>[108] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford,
                                                                                         
                                                                                         
     Mark  Chen,  and  Ilya  Sutskever.    Zero-shot  text-to-image  generation.    In  <span 
class="ecti-1095">International</span>
     <span 
class="ecti-1095">Conference on Machine Learning (ICML)</span>, 2021. <a 
href="https://arxiv.org/abs/2102.12092" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2102.12092</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xramesh2022hierarchical"></a>[109] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Aditya        Ramesh,        Prafulla        Dhariwal,        Alex        Nichol,        Casey
     Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents, 2022.
     <a 
href="https://arxiv.org/abs/2204.06125" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2204.06125</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XRatner19"></a>[110] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>A.&#x00A0;J.  Ratner,  B.&#x00A0;Hancock,  J.&#x00A0;Dunnmon,  F.&#x00A0;Sala,  S.&#x00A0;Pandey,  and  C.&#x00A0;R.   Training
     complex models with multi-task weak supervision.  In <span 
class="ecti-1095">Association for the Advancement of</span>
     <span 
class="ecti-1095">Artificial Intelligence (AAAI)</span>, 2019. <a 
href="https://arxiv.org/abs/1810.02840" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1810.02840</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XRatner16"></a>[111] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alexander&#x00A0;J Ratner, Christopher&#x00A0;M De&#x00A0;Sa, Sen Wu, Daniel Selsam, and Christopher R.
     Data programming: Creating large training sets, quickly. In <span 
class="ecti-1095">Advances in Neural Information</span>
     <span 
class="ecti-1095">Processing Systems (NeurIPS)</span>, 2016. <a 
href="https://arxiv.org/abs/1605.07723" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1605.07723</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xratner2017snorkel"></a>[112] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Alexander&#x00A0;J  Ratner,  Stephen&#x00A0;H  Bach,  Henry  Ehrenberg,  Jason  Fries,  Sen  Wu,  and
     Christopher R. Snorkel: Rapid training data creation with weak supervision. In <span 
class="ecti-1095">Very Large</span>
     <span 
class="ecti-1095">Data Bases Conference (VLDB)</span>, 2017. <a 
href=" https://arxiv.org/abs/1711.10160" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1711.10160</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XOverton"></a>[113] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Christopher R.  Overton: A data system for monitoring and improving machine-learned
     products. In <span 
class="ecti-1095">10th Conference on Innovative Data Systems Research, CIDR 2020, Amsterdam,</span>
     <span 
class="ecti-1095">The Netherlands, January 12-15, 2020, Online Proceedings</span>.  www.cidrdb.org,  2020.   URL
     <a 
href="http://cidrdb.org/cidr2020/papers/p33-re-cidr20.pdf" class="url" ><span 
class="ectt-1095">http://cidrdb.org/cidr2020/papers/p33-re-cidr20.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Ximagenetv2"></a>[114] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do ImageNet
     classifiers generalize to ImageNet? In <span 
class="ecti-1095">International Conference on Machine Learning (ICML)</span>,
     2019. <a 
href="http://proceedings.mlr.press/v97/recht19a.html" class="url" ><span 
class="ectt-1095">http://proceedings.mlr.press/v97/recht19a.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrojas2022dollar"></a>[115] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>William  A&#x00A0;Gaviria  Rojas,  Sudnya  Diamos,  Keertan&#x00A0;Ranjan  Kini,  David  Kanter,
     Vijay&#x00A0;Janapa Reddi, and Cody Coleman.   The dollar street dataset: Images representing
     the  geographic  and  socioeconomic  diversity  of  the  world.     In  <span 
class="ecti-1095">Advances  in  Neural</span>
     <span 
class="ecti-1095">Information   Processing   Systems   (NeurIPS)   Datasets   and   Benchmarks   Track</span>,   2022.
     <a 
href="https://openreview.net/forum?id=qnfYsave0U4" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=qnfYsave0U4</span></a>.
     </p>
                                                                                         
                                                                                         
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrombach2022high"></a>[116] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjrn Ommer.
     High-resolution image synthesis with latent diffusion models.  In <span 
class="ecti-1095">Conference on Computer</span>
     <span 
class="ecti-1095">Vision and Pattern Recognition (CVPR)</span>, 2022. <a 
href="https://arxiv.org/abs/2112.10752" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2112.10752</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrousseeuw2011robust"></a>[117] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Peter&#x00A0;J       Rousseeuw       and       Mia       Hubert.                  Robust       statistics
     for outlier detection.  <span 
class="ecti-1095">Wiley interdisciplinary reviews: Data mining and knowledge discovery</span>,
     2011. <a 
href="http://i2pc.es/coss/Docencia/SignalProcessingReviews/Rousseeuw2011.pdf" class="url" ><span 
class="ectt-1095">http://i2pc.es/coss/Docencia/SignalProcessingReviews/Rousseeuw2011.pdf</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrousseeuw2018anomaly"></a>[118] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Peter&#x00A0;J      Rousseeuw      and      Mia      Hubert.                 Anomaly      detection
     by robust statistics.  <span 
class="ecti-1095">Wiley interdisciplinary reviews: Data mining and knowledge discovery</span>,
     2018. <a 
href="https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1236" class="url" ><span 
class="ectt-1095">https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1236</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XILSVRC15"></a>[119] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Olga  Russakovsky,  Jia  Deng,  Hao  Su,  Jonathan  Krause,  Sanjeev  Satheesh,  Sean  Ma,
     Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander&#x00A0;C. Berg, and
     Li&#x00A0;Fei-Fei.  ImageNet Large Scale Visual Recognition Challenge.  <span 
class="ecti-1095">International Journal of</span>
     <span 
class="ecti-1095">Computer Vision (IJCV)</span>, 2015. <a 
href="https://arxiv.org/abs/1409.0575" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1409.0575</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xsagawa2022extending"></a>[120] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Shiori  Sagawa,  Pang&#x00A0;Wei  Koh,  Tony  Lee,  Irena  Gao,  Sang&#x00A0;Michael  Xie,  Kendrick
     Shen,  Ananya  Kumar,  Weihua  Hu,  Michihiro  Yasunaga,  Henrik  Marklund,  Sara  Beery,
     Etienne David, Ian Stavness, Wei Guo, Jure Leskovec, Kate Saenko, Tatsunori Hashimoto,
     Sergey  Levine,  Chelsea  Finn,  and  Percy  Liang.    Extending  the  wilds  benchmark  for
     unsupervised adaptation.  In <span 
class="ecti-1095">International Conference on Learning Representations (ICLR)</span>,
     2022. <a 
href="https://arxiv.org/abs/2112.05090" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2112.05090</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xlaion400m"></a>[121] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Christoph  Schuhmann,  Richard  Vencu,  Romain  Beaumont,  Robert  Kaczmarczyk,
     Clayton  Mullis,  Aarush  Katta,  Theo  Coombes,  Jenia  Jitsev,  and  Aran  Komatsuzaki.
     LAION-400M:   Open   dataset   of   clip-filtered   400   million   image-text   pairs,   2021.
     <a 
href="https://arxiv.org/abs/2111.02114" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2111.02114</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xlaion5b"></a>[122] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Christoph  Schuhmann,  Romain  Beaumont,  Richard  Vencu,  Cade&#x00A0;W  Gordon,  Ross
     Wightman,  Mehdi  Cherti,  Theo  Coombes,  Aarush  Katta,  Clayton  Mullis,  Mitchell
     Wortsman,  Patrick  Schramowski,  Srivatsa&#x00A0;R  Kundurthy,  Katherine  Crowson,  Ludwig
     Schmidt,  Robert  Kaczmarczyk,  and  Jenia  Jitsev.     LAION-5B:  An  open  large-scale
     dataset  for  training  next  generation  image-text  models.    In  <span 
class="ecti-1095">Thirty-sixth  Conference  on</span>
                                                                                         
                                                                                         
     <span 
class="ecti-1095">Neural Information Processing Systems (NeurIPS), Datasets and Benchmarks Track</span>, 2022.
     <a 
href="https://openreview.net/forum?id=M3Y74vmsMcY" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=M3Y74vmsMcY</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xsener2018active"></a>[123] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ozan Sener and Silvio Savarese.  Active learning for convolutional neural networks: A
     core-set approach.  In <span 
class="ecti-1095">International Conference on Learning Representations (ICLR)</span>, 2018.
     <a 
href="https://openreview.net/forum?id=H1aIuk-RW" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=H1aIuk-RW</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xsharma2018conceptual"></a>[124] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Piyush  Sharma,  Nan  Ding,  Sebastian  Goodman,  and  Radu  Soricut.     Conceptual
     captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning.
     In   <span 
class="ecti-1095">Annual  Meeting  of  the  Association  for  Computational  Linguistics  (ACL)</span>,   2018.
     <a 
href="https://aclanthology.org/P18-1238/" class="url" ><span 
class="ectt-1095">https://aclanthology.org/P18-1238/</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xshin2021universalizing"></a>[125] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Changho  Shin,  Winfred  Li,  Harit  Vishwakarma,  Nicholas  Roberts,  and  Frederic  Sala.
     Universalizing weak supervision.  In <span 
class="ecti-1095">International Conference on Learning Representations</span>
     <span 
class="ecti-1095">(ICLR)</span>, 2022. <a 
href="https://openreview.net/forum?id=YpPiNigTzMT" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=YpPiNigTzMT</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xsorscher2022beyond"></a>[126] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ben                 Sorscher,                 Robert                 Geirhos,                 Shashank
     Shekhar, Surya Ganguli, and Ari&#x00A0;S. Morcos. Beyond neural scaling laws: beating power law
     scaling via data pruning. In <span 
class="ecti-1095">Advances in Neural Information Processing Systems (NeurIPS)</span>,
     2022. <a 
href="https://openreview.net/forum?id=UmvSlP-PyV" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=UmvSlP-PyV</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xsrinivasan2021wit"></a>[127] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Krishna Srinivasan, Karthik Raman, Jiecao Chen, Michael Bendersky, and Marc Najork.
     Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning.  In
     <span 
class="ecti-1095">44th International ACM SIGIR Conference on Research and Development in Information</span>
     <span 
class="ecti-1095">Retrieval</span>, 2021. <a 
href="https://arxiv.org/abs/2103.01913" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2103.01913</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xgtsrb"></a>[128] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Johannes                                          Stallkamp,                                          Marc
     Schlipsing, Jan Salmen, and Christian Igel. The german traffic sign recognition benchmark: a
     multi-class classification competition. In <span 
class="ecti-1095">International Joint Conference on Neural Networks</span>
     <span 
class="ecti-1095">(IJCNN)</span>, 2011. <a 
href="https://ieeexplore.ieee.org/document/6033395" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/document/6033395</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xdataset-cartography"></a>[129] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Swabha  Swayamdipta,  Roy  Schwartz,  Nicholas  Lourie,  Yizhong  Wang,  Hannaneh
     Hajishirzi, Noah&#x00A0;A. Smith, and Yejin Choi.  Dataset cartography: Mapping and diagnosing
     datasets with training dynamics.  In <span 
class="ecti-1095">Conference on Empirical Methods in Natural Language</span>
     <span 
class="ecti-1095">Processing (EMNLP)</span>, 2020. <a 
href="https://aclanthology.org/2020.emnlp-main.746" class="url" ><span 
class="ectt-1095">https://aclanthology.org/2020.emnlp-main.746</span></a>.
                                                                                         
                                                                                         
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xtaori2020measuring"></a>[130] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Rohan  Taori,  Achal  Dave,  Vaishaal  Shankar,  Nicholas  Carlini,  Benjamin  Recht,
     and  Ludwig  Schmidt.     Measuring  robustness  to  natural  distribution  shifts  in  image
     classification.   In  <span 
class="ecti-1095">Advances  in  Neural  Information  Processing  Systems  (NeurIPS)</span>,  2020.
     <a 
href="https://dl.acm.org/doi/abs/10.5555/3495724.3497285" class="url" ><span 
class="ectt-1095">https://dl.acm.org/doi/abs/10.5555/3495724.3497285</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xyfcc100m"></a>[131] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Bart Thomee, David&#x00A0;A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas
     Poland, Damian Borth, and Li-Jia Li.  YFCC100M: The new data in multimedia research.
     <span 
class="ecti-1095">Communications of the ACM</span>, 2016. <a 
href="https://arxiv.org/abs/1503.01817" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1503.01817</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xtoneva2018empirical"></a>[132] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Mariya Toneva, Alessandro Sordoni, Remi&#x00A0;Tachet des Combes, Adam Trischler, Yoshua
     Bengio, and Geoffrey&#x00A0;J Gordon. An empirical study of example forgetting during deep neural
     network learning.  In <span 
class="ecti-1095">International Conference on Learning Representations (ICLR)</span>, 2018.
     <a 
href="https://arxiv.org/abs/1812.05159" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1812.05159</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xpatchcamelyon"></a>[133] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Bastiaan&#x00A0;S  Veeling,  Jasper  Linmans,  Jim  Winkens,  Taco  Cohen,  and  Max  Welling.
     Rotation equivariant CNNs for digital pathology, 2018. <a 
href="https://arxiv.org/abs/1806.03962" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1806.03962</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Ximagenetsketch"></a>[134] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Haohan Wang, Songwei Ge, Zachary Lipton, and Eric&#x00A0;P Xing.  Learning robust global
     representations  by  penalizing  local  predictive  power.   In  <span 
class="ecti-1095">Advances in Neural Information</span>
     <span 
class="ecti-1095">Processing Systems (NeurIPS)</span>, 2019. <a 
href="https://arxiv.org/abs/1905.13549" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1905.13549</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xwebster2023deduplication"></a>[135] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Ryan Webster, Julien Rabin, Loic Simon, and Frederic Jurie.  On the de-duplication of
     laion-2b, 2023. <a 
href="https://arxiv.org/abs/2303.12733" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2303.12733</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xpmlr-v37-wei15"></a>[136] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kai  Wei,  Rishabh  Iyer,  and  Jeff  Bilmes.    Submodularity  in  data  subset  selection
     and  active  learning.    In  <span 
class="ecti-1095">International  Conference  on  Machine  Learning  (ICML)</span>,  2015.
     <a 
href="https://proceedings.mlr.press/v37/wei15.html" class="url" ><span 
class="ectt-1095">https://proceedings.mlr.press/v37/wei15.html</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xsun397"></a>[137] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jianxiong Xiao, Krista&#x00A0;A Ehinger, James Hays, Antonio Torralba, and Aude Oliva. Sun
     database: Exploring a large collection of scene categories. <span 
class="ecti-1095">International Journal of Computer</span>
     <span 
class="ecti-1095">Vision (IJCV)</span>, 2016. <a 
href="https://link.springer.com/article/10.1007/s11263-014-0748-y" class="url" ><span 
class="ectt-1095">https://link.springer.com/article/10.1007/s11263-014-0748-y</span></a>.
     </p>
                                                                                         
                                                                                         
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XYang2019TowardsFD"></a>[138] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kaiyu Yang, Klint Qinami, Li&#x00A0;Fei-Fei, Jia Deng, and Olga Russakovsky.  Towards fairer
     datasets:  filtering  and  balancing  the  distribution  of  the  people  subtree  in  the  imagenet
     hierarchy.   In  <span 
class="ecti-1095">Conference  on  Fairness,  Accountability,  and  Transparency  (FAccT)</span>,  2020.
     <a 
href="https://arxiv.org/abs/1912.07726" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1912.07726</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xyang2022study"></a>[139] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Kaiyu Yang, Jacqueline&#x00A0;H Yau, Li&#x00A0;Fei-Fei, Jia Deng, and Olga Russakovsky.  A study
     of face obfuscation in ImageNet. In <span 
class="ecti-1095">International Conference on Machine Learning (ICML)</span>,
     2022. <a 
href="https://arxiv.org/abs/2103.06191" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2103.06191</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xfilip"></a>[140] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Lewei Yao, Runhui Huang, Lu&#x00A0;Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiaodan Liang,
     Zhenguo Li, Xin Jiang, and Chunjing Xu.   Filip: Fine-grained interactive language-image
     pre-training.    In  <span 
class="ecti-1095">International  Conference  on  Learning  Representations  (ICLR)</span>,  2022.
     <a 
href="https://arxiv.org/abs/2111.07783" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2111.07783</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="XYokoo2021Dedup"></a>[141] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Shuhei Yokoo.  Contrastive learning with large memory bank and negative embedding
     subtraction for accurate copy detection, 2021. <a 
href="https://arxiv.org/abs/2112.04323" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2112.04323</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xflickr30k"></a>[142] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Peter  Young,  Alice  Lai,  Micah  Hodosh,  and  Julia  Hockenmaier.     From  image
     descriptions  to  visual  denotations:  New  similarity  metrics  for  semantic  inference  over
     event  descriptions.   <span 
class="ecti-1095">Transactions of the Association for Computational Linguistics</span>,  2014.
     <a 
href="https://aclanthology.org/Q14-1006/" class="url" ><span 
class="ectt-1095">https://aclanthology.org/Q14-1006/</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xyu2002findout"></a>[143] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Dantong       Yu,       Gholamhosein       Sheikholeslami,       and       Aidong       Zhang.
     Findout: Finding outliers in very large datasets.  <span 
class="ecti-1095">Knowledge and information Systems</span>, 2002.
     <a 
href="https://link.springer.com/article/10.1007/s101150200013" class="url" ><span 
class="ectt-1095">https://link.springer.com/article/10.1007/s101150200013</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xyuan2021florence"></a>[144] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Lu&#x00A0;Yuan,  Dongdong  Chen,  Yi-Ling  Chen,  Noel  Codella,  Xiyang  Dai,  Jianfeng  Gao,
     Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, et&#x00A0;al.  Florence: A new foundation
     model for computer vision, 2021. <a 
href="https://arxiv.org/abs/2111.11432" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2111.11432</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xyuen2011survey"></a>[145] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Man-Ching Yuen, Irwin King, and Kwong-Sak Leung. A survey of crowdsourcing systems.
     In <span 
class="ecti-1095">SocialCom</span>. IEEE, 2011. <a 
href="https://ieeexplore.ieee.org/document/6113213" class="url" ><span 
class="ectt-1095">https://ieeexplore.ieee.org/document/6113213</span></a>.
     </p>
                                                                                         
                                                                                         
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xzaharia2016apache"></a>[146] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Matei  Zaharia,  Reynold&#x00A0;S  Xin,  Patrick  Wendell,  Tathagata  Das,  Michael  Armbrust,
     Ankur Dave, Xiangrui Meng, Josh Rosen, Shivaram Venkataraman, Michael&#x00A0;J Franklin, et&#x00A0;al.
     Apache spark: a unified engine for big data processing.  <span 
class="ecti-1095">Communications of the ACM</span>, 2016.
     <a 
href="https://dl.acm.org/doi/10.1145/2934664" class="url" ><span 
class="ectt-1095">https://dl.acm.org/doi/10.1145/2934664</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xvtab"></a>[147] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Xiaohua Zhai, Joan Puigcerver, Alexander Kolesnikov, Pierre Ruyssen, Carlos Riquelme,
     Mario Lucic, Josip Djolonga, Andr&#x00A0;Susano Pinto, Maxim Neumann, Alexey Dosovitskiy,
     Lucas  Beyer,  Olivier  Bachem,  Michael  Tschannen,  Marcin  Michalski,  Olivier  Bousquet,
     Sylvain   Gelly,   and   Neil   Houlsby.      The   visual   task   adaptation   benchmark,   2019.
     <a 
href="http://arxiv.org/abs/1910.04867" class="url" ><span 
class="ectt-1095">http://arxiv.org/abs/1910.04867</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xzhang2021wrench"></a>[148] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jieyu Zhang, Yue Yu, Yinghao Li, Yujing Wang, Yaming Yang, Mao Yang, and Alexander
     Ratner.  WRENCH: A comprehensive benchmark for weak supervision.  In <span 
class="ecti-1095">NeurIPS</span>, 2021.
     URL <a 
href="https://openreview.net/forum?id=Q9SKS5k8io" class="url" ><span 
class="ectt-1095">https://openreview.net/forum?id=Q9SKS5k8io</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xzhang2022survey"></a>[149] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Jieyu Zhang, Cheng-Yu Hsieh, Yue Yu, Chao Zhang, and Alexander Ratner. A survey on
     programmatic weak supervision, 2022. <a 
href="https://arxiv.org/abs/2202.05433" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/2202.05433</span></a>.
     </p>
     <p class="bibitem" ><span class="biblabel">
<a 
 id="Xutkface"></a>[150] <span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Zhifei Zhang, Yang Song, and Hairong Qi.   Age progression/regression by conditional
     adversarial autoencoder.  In <span 
class="ecti-1095">IEEE Conference on Computer Vision and Pattern Recognition</span>
     <span 
class="ecti-1095">(CVPR)</span>, 2017. <a 
href="https://arxiv.org/abs/1702.08423" class="url" ><span 
class="ectt-1095">https://arxiv.org/abs/1702.08423</span></a>.
</p>
     </div>
<!--l. 803--><p class="noindent" >
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<h1 class="likepartHead"><a 
 id="x1-540006"></a>Appendix</h1>
<h3 class="likesectionHead"><a 
 id="x1-550006"></a>Contents</h3>
<div class="tableofcontents">
<span class="sectionToc" >1 <a 
href="#x1-10001" id="QQ2-1-1">Introduction</a></span>
<br /><span class="sectionToc" >2 <a 
href="#x1-20002" id="QQ2-1-2">Related Work</a></span>
<br /><span class="sectionToc" >3 <a 
href="#x1-50003" id="QQ2-1-5"><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span></a></span>
<br />&#x00A0;<span class="subsectionToc" >3.1 <a 
href="#x1-60003.1" id="QQ2-1-6">Competition design</a></span>
<br />&#x00A0;<span class="subsectionToc" >3.2 <a 
href="#x1-110003.2" id="QQ2-1-11"><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>generation</a></span>
<br />&#x00A0;<span class="subsectionToc" >3.3 <a 
href="#x1-170003.3" id="QQ2-1-17">Bring your own data (<span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>)</a></span>
<br />&#x00A0;<span class="subsectionToc" >3.4 <a 
href="#x1-180003.4" id="QQ2-1-18">Training</a></span>
<br />&#x00A0;<span class="subsectionToc" >3.5 <a 
href="#x1-190003.5" id="QQ2-1-19">Evaluation</a></span>
<br /><span class="sectionToc" >4 <a 
href="#x1-200004" id="QQ2-1-20">Baselines</a></span>
<br />&#x00A0;<span class="subsectionToc" >4.1 <a 
href="#x1-210004.1" id="QQ2-1-21">Filtering baselines</a></span>
<br />&#x00A0;<span class="subsectionToc" >4.2 <a 
href="#x1-280004.2" id="QQ2-1-28"><span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>baselines</a></span>
<br /><span class="sectionToc" >5 <a 
href="#x1-290005" id="QQ2-1-29">Results and discussion</a></span>
<br />&#x00A0;<span class="subsectionToc" >5.1 <a 
href="#x1-300005.1" id="QQ2-1-30">Building better datasets</a></span>
<br />&#x00A0;<span class="subsectionToc" >5.2 <a 
href="#x1-360005.2" id="QQ2-1-36"><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>design analyses</a></span>
<br />&#x00A0;<span class="subsectionToc" >5.3 <a 
href="#x1-410005.3" id="QQ2-1-41">Evaluation trends</a></span>
<br /><span class="sectionToc" >6 <a 
href="#x1-440006" id="QQ2-1-44">Conclusion and future work</a></span>
<br /><span class="sectionToc" >A <a 
href="#x1-56000A" id="QQ2-1-56">Benchmark rules</a></span>
<br />&#x00A0;<span class="subsectionToc" >A.1 <a 
href="#x1-57000A.1" id="QQ2-1-57">Filtering track rules</a></span>
<br />&#x00A0;<span class="subsectionToc" >A.2 <a 
href="#x1-58000A.2" id="QQ2-1-58">Bring your own data track: amendments</a></span>
<br /><span class="sectionToc" >B <a 
href="#x1-60000B" id="QQ2-1-60">Contributions</a></span>
<br />&#x00A0;<span class="subsectionToc" >B.1 <a 
href="#x1-61000B.1" id="QQ2-1-61">Candidate pool</a></span>
<br />&#x00A0;<span class="subsectionToc" >B.2 <a 
href="#x1-65000B.2" id="QQ2-1-65">Participant tooling</a></span>
<br />&#x00A0;<span class="subsectionToc" >B.3 <a 
href="#x1-71000B.3" id="QQ2-1-71">Baselines</a></span>
<br />&#x00A0;<span class="subsectionToc" >B.4 <a 
href="#x1-76000B.4" id="QQ2-1-76">Leadership and Advising</a></span>
<br /><span class="sectionToc" >C <a 
href="#x1-80000C" id="QQ2-1-80">Additional related work</a></span>
<br /><span class="sectionToc" >D <a 
href="#x1-81000D" id="QQ2-1-81">Parsing Common Crawl</a></span>
                                                                                         
                                                                                         
<br /><span class="sectionToc" >E <a 
href="#x1-82000E" id="QQ2-1-82">Not safe for work (NSFW) filtering</a></span>
<br /><span class="sectionToc" >F <a 
href="#x1-83000F" id="QQ2-1-83">Deduplication against evaluation sets</a></span>
<br /><span class="sectionToc" >G <a 
href="#x1-84000G" id="QQ2-1-84">Face blurring</a></span>
<br /><span class="sectionToc" >H <a 
href="#x1-85000H" id="QQ2-1-85"><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> <span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>creation pipeline</a></span>
<br /><span class="sectionToc" >I <a 
href="#x1-86000I" id="QQ2-1-86"><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>statistics</a></span>
<br /><span class="sectionToc" >J <a 
href="#x1-87000J" id="QQ2-1-87">Efficient training on data subsets</a></span>
<br /><span class="sectionToc" >K <a 
href="#x1-88000K" id="QQ2-1-88">Effect of duplicates in the training data</a></span>
</div>
<!--l. 4--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">A   </span> <a 
 id="x1-56000A"></a>Benchmark rules</h3>
<!--l. 7--><p class="noindent" >We provide concrete rules below for the two competition tracks that comprise <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>: filtering and
<span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>. Additionally, we provide a checklist, which encourages participants to specify design decisions,
hence allowing for more granular comparison between submissions.
<!--l. 10--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">A.1   </span> <a 
 id="x1-57000A.1"></a>Filtering track rules</h4>
     <ul class="itemize1">
     <li class="itemize">Participants can enter submissions for one or many different scales: <span 
class="ectt-1095">small</span>, <span 
class="ectt-1095">medium</span>, <span 
class="ectt-1095">large </span>or
     <span 
class="ectt-1095">xlarge</span>, which represent the raw number of image-text pairs in CommonPool that should be
     filtered.
     </li>
     <li class="itemize">After  choosing  a  scale,  participants  generate  a  list  of  uids,  where  each  uid  refers  to  a
     <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>sample. The list of uids is used to recover image-text pairs from the pool,
     which is used for downstream CLIP training.
     </li>
     <li class="itemize">Duplicate uids are allowed.
     </li>
     <li class="itemize">Participants   are   <span 
class="ecti-1095">not   </span>allowed   to   modify   the   training   procedure.   Hence,   changing
     hyperparameters, model architecture, optimizer, compute budget, or number of training steps
     is not allowed. Changing any other training details is also not allowed.
                                                                                         
                                                                                         
     </li>
     <li class="itemize">Participants are strongly encouraged to submit and open-source both the list of uids and the
     code used to generate this list; however, this is not required.
     </li>
     <li class="itemize">To avoid overfitting, we do not permit running any code or algorithmic dependence on the
     test images of the evaluation tasks. However, use of other images associated with these tasks
     (e.g., supervised training sets) is permitted.
     </li>
     <li class="itemize">Participants can use templates or class labels from the downstream tasks in their filtering
     algorithms.</li></ul>
<!--l. 23--><p class="noindent" >For clarity, we include some examples of permitted and forbidden uses:
     <ul class="itemize1">
     <li class="itemize">We <span 
class="ecbx-1095">permit </span>using the ImageNet class label &#8220;triceratops&#8221; in a filtering algorithm.
     </li>
     <li class="itemize">We <span 
class="ecbx-1095">forbid </span>examining individual or aggregate predictions on the test sets of the evaluation
     tasks.</li></ul>
<!--l. 30--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">A.2   </span> <a 
 id="x1-58000A.2"></a>Bring your own data track: amendments</h4>
<!--l. 31--><p class="noindent" >To facilitate more open-ended exploration, we provide amendments to the Track 1 competition to allow for
more diverse submissions in Track 2.
     <ul class="itemize1">
     <li class="itemize">Participants are allowed to augment <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>data with existing datasets, so long as
     these data sources do not contain test images from the evaluation tasks. Participants can use
     data from any <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>; however, they are not required to do so.
     </li>
     <li class="itemize">Assembling one&#8217;s own dataset is allowed; however, test images from the evaluation tasks can
     neither be contained nor otherwise used to construct said dataset. We encourage releasing the
     image urls or the images themselves in addition to the text for each image. We also encourage
     rigorous documentation of face-blurring and other data safety checks (see Section&#x00A0;<a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a> for more
     details). We reserve the right to run our own safety code on participant provided data and
     disqualify entries that do not meet adequate safety standards.</li></ul>
<!--l. 39--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-59000A.2"></a><span 
class="ecbx-1095">Checklist.</span></span>
The following checklist provides the basis for more fine-grained comparison between submissions.
     <ul class="itemize1">
     <li class="itemize">Images from the evaluation tasks are included in my submission. If yes, please specify which
                                                                                         
                                                                                         
     datasets.
     </li>
     <li class="itemize">I used an existing datasets (e.g., YFCC100M&#x00A0;[<a 
href="#Xyfcc100m">131</a>]) in my submission. If yes, please specify
     which datasets. (Note: applies to <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>only)
     </li>
     <li class="itemize">I curated my own data. If yes, please provide (1) image data or urls, (2) text for each image,
     (3) list of safety steps taken including but not limited to face blurring, explicit content image
     and text filtering. (Note: applies to <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>only)</li></ul>
<!--l. 47--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">B   </span> <a 
 id="x1-60000B"></a>Contributions</h3>
<!--l. 48--><p class="noindent" >For this section, contributors are ordered alphabetically.
<!--l. 50--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">B.1   </span> <a 
 id="x1-61000B.1"></a>Candidate pool</h4>
<!--l. 52--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-62000B.1"></a><span 
class="ecbx-1095">Candidate pool lead.</span></span>
Vaishaal Shankar
<!--l. 54--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-63000B.1"></a><span 
class="ecbx-1095">Data collection.</span></span>
Romain Beaumont, Vaishaal Shankar
<!--l. 56--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-64000B.1"></a><span 
class="ecbx-1095">Pre-processing and metadata.</span></span>
Giannis Daras, Alex Fang (content filtering lead), Samir Yitzhak Gadre (metadata lead), Ryan
Marten (deduplication lead), Vivek Ramanujan, Vaishaal Shankar, George Smyrnis (face blurring
lead)
<!--l. 58--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">B.2   </span> <a 
 id="x1-65000B.2"></a>Participant tooling</h4>
                                                                                         
                                                                                         
<!--l. 60--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-66000B.2"></a><span 
class="ecbx-1095">Participant tooling lead.</span></span>
Gabriel Ilharco
<!--l. 62--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-67000B.2"></a><span 
class="ecbx-1095">Resharder.</span></span>
Romain Beaumont, Yair Carmon, Alex Fang, Jonathan Hayase (lead), Gabriel Ilharco, Vivek Ramanujan,
Vaishaal Shankar, Georgios Smyrnis
<!--l. 64--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-68000B.2"></a><span 
class="ecbx-1095">Training.</span></span>
Mehdi Cherti, Gabriel Ilharco, Jenia Jitsev, Vivek Ramanujan, Georgios Smyrnis, Mitchell Wortsman
(lead)
<!--l. 66--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-69000B.2"></a><span 
class="ecbx-1095">Evaluation.</span></span>
Romain Beaumont, Yonatan Bitton, Mehdi Cherti, Dhruba Ghosh (lead), Gabriel Ilharco
<!--l. 68--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-70000B.2"></a><span 
class="ecbx-1095">Additional infrastructure.</span></span>
Stephen Mussmann, Sarah Pratt
<!--l. 70--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">B.3   </span> <a 
 id="x1-71000B.3"></a>Baselines</h4>
<!--l. 72--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-72000B.3"></a><span 
class="ecbx-1095">Baselines lead.</span></span>
Yair Carmon
<!--l. 74--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-73000B.3"></a><span 
class="ecbx-1095">Filtering track.</span></span>
Yair Carmon, Rahim Enterazi, Alex Fang, Samir Yitzhak Gadre, Gabriel Ilharco, Kalyani
Marathe, Thao Nguyen, Eyal Orgad (co-lead), Georgios Smyrnis, Mitchell Wortsman, Jieyu Zhang
(co-lead)
<!--l. 76--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-74000B.3"></a><span 
class="ecbx-1095">BYOD track.</span></span>
Gabriel Ilharco, Thao Nguyen
                                                                                         
                                                                                         
<!--l. 78--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-75000B.3"></a><span 
class="ecbx-1095">Experiment babysitting.</span></span>
Alex Fang, Gabriel Ilharco, Samir Yitzhak Gadre
<!--l. 80--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">B.4   </span> <a 
 id="x1-76000B.4"></a>Leadership and Advising</h4>
<!--l. 82--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-77000B.4"></a><span 
class="ecbx-1095">Advising.</span></span>
Romain Beaumont, Yair Carmon, Alexandros G.&#x00A0;Dimakis, Ali Farhadi, Hannaneh Hajishirzi, Jenia Jitsev,
Pang Wei Koh, Ranjay Krishna, Stephen Mussmann, Sewoong Oh, Alexander Ratner, Olga Saukh, Ludwig
Schmidt, Vaishaal Shankar, Shuran Song, Richard Vencu
<!--l. 85--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-78000B.4"></a><span 
class="ecbx-1095">Leadership.</span></span>
Yair Carmon, Alexandros G.&#x00A0;Dimakis, Jenia Jitsev, Sewoong Oh, Ludwig Schmidt, Vaishaal
Shankar
<!--l. 88--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-79000B.4"></a><span 
class="ecbx-1095">Overall project lead.</span></span>
Ludwig Schmidt
<!--l. 91--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">C   </span> <a 
 id="x1-80000C"></a>Additional related work</h3>
<!--l. 94--><p class="noindent" >Here we expand on Section&#x00A0;<a 
href="#x1-20002">2<!--tex4ht:ref: sec:relatedwork --></a>.
<!--l. 96--><p class="noindent" >Image dataset safety is an active area of research, especially in the context of large-scale dataset
construction. In addition to Birhane et&#x00A0;al.&#x00A0;[<a 
href="#XBirhane2021MultimodalDM">11</a>], who study problematic content in LAION-400M, Yang
et&#x00A0;al.&#x00A0;[<a 
href="#XYang2019TowardsFD">138</a>] study the ImageNet dataset and reveal limitations associated with the ImageNet curation
strategy&#8212;with negative implications for downstream model fairness. Prabhu &amp; Birhane&#x00A0;[<a 
href="#XPrabhu2020LargeID">101</a>]
also study the ImageNet dataset and find pornographic content. Both Birhane et&#x00A0;al.&#x00A0;[<a 
href="#XBirhane2021MultimodalDM">11</a>] and
Prabhu &amp; Birhane&#x00A0;[<a 
href="#XPrabhu2020LargeID">101</a>] survey ethical conundrums and harms that are borne out of improper
dataset curation. In an effort to combat dataset toxicity, we conduct NSFW preprocessing
(Section&#x00A0;<a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a>, Appendix&#x00A0;<a 
href="#x1-82000E">E<!--tex4ht:ref: app:nsfw --></a>) and blur detected faces (Section&#x00A0;<a 
href="#x1-110003.2">3.2<!--tex4ht:ref: sec:pool --></a>, Appendix&#x00A0;<a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a>) during pool
construction. We also conduct fairness evaluations (Section&#x00A0;<a 
href="#x1-410005.3">5.3<!--tex4ht:ref: sec:eval-trends --></a>, Appendix&#x00A0;<a 
href="#x1-107000P">P<!--tex4ht:ref: app:fairness --></a>) for models trained
on our data. We hope <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>will be a resource for future work examining dataset
safety.
<!--l. 98--><p class="noindent" >Beyond data selection, Chan et&#x00A0;al.&#x00A0;[<a 
href="#Xchan2022data">19</a>] investigate the effects of dataset distribution on emergent
properties of transformers, while Fang et&#x00A0;al.&#x00A0;[<a 
href="#Xfang2022data">40</a>] look at the relationship between data and
                                                                                         
                                                                                         
model robustness to distribution shifts. We hope our extensive evaluation suite comprised
of 38 diverse tasks will facilitate similar studies when training multimodal models at large
scale.
<!--l. 100--><p class="noindent" >Others study how to reduce the burdens of training data annotation in the curation process. Classic
approaches include distant supervision&#x00A0;[<a 
href="#Xhoffmann2011knowledge">61</a>], crowd-sourced labels&#x00A0;[<a 
href="#Xyuen2011survey">145</a>], heuristic rules&#x00A0;[<a 
href="#XAwasthi2020Learning">5</a>] and feature
annotation&#x00A0;[<a 
href="#Xmann2010generalized">89</a>], among others. A recent line of work known as data programming or programmatic weak
supervision&#x00A0;[<a 
href="#XRatner16">111</a>,&#x00A0;<a 
href="#Xratner2017snorkel">112</a>,&#x00A0;<a 
href="#Xzhang2021wrench">148</a>,&#x00A0;<a 
href="#Xzhang2022survey">149</a>] attempts to reduce annotation cost and is found in many industry
applications&#x00A0;[<a 
href="#Xbach2019snorkel">6</a>,&#x00A0;<a 
href="#XOverton">113</a>]. In data programming, developers write programmatic labeling functions to
automatically label a large amount of unlabeled data. The labeling functions could produce noisy and
conflicting labels, so researchers have developed methods to aggregate noisy votes to produce the final
training labels&#x00A0;[<a 
href="#XRatner19">110</a>,&#x00A0;<a 
href="#Xfu2020fast">43</a>,&#x00A0;<a 
href="#Xshin2021universalizing">125</a>].
<!--l. 102--><p class="noindent" >Previous literature also studies methods for training data attribution, which seek to link a model&#8217;s
behavior (e.g., its accuracy on a particular task or subset of data) to particular subsets of its training data.
Such methods include influence functions, a classic technique from robust statistics [<a 
href="#Xhampel1974influence">52</a>,&#x00A0;<a 
href="#Xcook1977detection">31</a>] that uses a
second-order Taylor expansion to approximate the effect of removing a training point on the learned model
parameters [<a 
href="#Xkoh2017understanding">74</a>,&#x00A0;<a 
href="#Xkoh2019accuracy">75</a>,&#x00A0;<a 
href="#Xhan2020explaining">53</a>,&#x00A0;<a 
href="#Xguo2020fastif">48</a>], as well as methods that fit attribution functions directly to the dynamics of
repeated training runs [<a 
href="#Xghorbani2019data">45</a>,&#x00A0;<a 
href="#Xpruthi2020estimating">102</a>,&#x00A0;<a 
href="#Xilyas2022datamodels">63</a>,&#x00A0;<a 
href="#Xguu2023simfluence">51</a>]. Training data attribution methods assume that we have already
trained a model, though they can be subsequently used to refine the training data (e.g., by identifying
potentially mislabeled training points [<a 
href="#Xkoh2017understanding">74</a>]). Our focus in this paper is instead on data curation
methods&#8212;that is, methods for selecting a subset of the training data to train a model in the first
place.
<!--l. 108--><p class="noindent" >In the context of natural language processing, Swayamdipta et&#x00A0;al.&#x00A0;[<a 
href="#Xdataset-cartography">129</a>] proposes a tool for
characterizing samples in a dataset based on training dynamics, labelling instances as ambiguous,
easy to learn or hard to learn. Previous literature such as work by Le&#x00A0;Bras et&#x00A0;al.&#x00A0;[<a 
href="#Xle2020adversarial">81</a>],&#x00A0;Li &amp;
Vasconcelos&#x00A0;[<a 
href="#Xli2019repair">84</a>],&#x00A0;Gururangan et&#x00A0;al.&#x00A0;[<a 
href="#Xgururangan-etal-2018-annotation">50</a>] advocate for removing easy instances from the training data.
Ethayarajh et&#x00A0;al.&#x00A0;[<a 
href="#Xethayarajh2022understanding">37</a>] propose a measure of how difficult a dataset is to learn, <span 
class="cmsy-10x-x-109"><img 
src="cmsy10-56.png" alt="V" class="10-109x-x-56" /></span>-usable information.
Such techniques could be promising directions of further exploration in the context of our
benchmark.
<!--l. 111--><p class="noindent" >Finally, another related line of work is studying scaling trends. In addition to Sorscher et&#x00A0;al.&#x00A0;[<a 
href="#Xsorscher2022beyond">126</a>],
researchers have investigated how model performance changes as a function of compute budget, model size,
and number of training samples [<a 
href="#Xkaplan2020scaling">71</a>,&#x00A0;<a 
href="#Xchinchilla">60</a>,&#x00A0;<a 
href="#Xcaballero2022broken">17</a>,&#x00A0;<a 
href="#Xcherti2022reproducible">24</a>]. However, this line of work does not consider how dataset
design may affects scaling trends. Beyond dataset size, we measure the effects of different dataset sources
and filtering strategies. While scaling trends are central to our investigations, the purpose of our
benchmark is to search for the next generation of large multimodal datasets to facilitate more accurate and
reliable models.
<!--l. 116--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">D   </span> <a 
 id="x1-81000D"></a>Parsing Common Crawl</h3>
<!--l. 118--><p class="noindent" >Common Crawl releases metadata files for the websites that they index (i.e., WAT files). They release
these files approximately once a month. We consider all files available from 2014 through November of
                                                                                         
                                                                                         
2022. We first parse these files, utilizing Apache Spark&#x00A0;[<a 
href="#Xzaharia2016apache">146</a>] to extract image urls and corresponding
alt-text. We map each url, text pair to a uid hash and remove duplicates. This results in 88 billion url, text
pairs, which are randomized via a distributed shuffle. Note, we do not consider image content when
running uid deduplication at this step. Hence, two identical images with different urls and the same
caption would both be retained.
<!--l. 120--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">E   </span> <a 
 id="x1-82000E"></a>Not safe for work (NSFW) filtering</h3>
<!--l. 122--><p class="noindent" >Our data is sourced from Common Crawl, which contains snapshots of the web. Therefore, we apply
multiple layers of NSFW content filtering to remove problematic images and captions from
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.
<!--l. 124--><p class="noindent" >First, we filter our captions with Detoxify [<a 
href="#XDetoxify">54</a>], a language model for toxic comment classification.
Specifically, we use the multilingual XLM-RoBERTa&#x00A0;[<a 
href="#XConneau2019UnsupervisedCR">30</a>] variant. The model outputs scores between zero
and one for the following categories: toxicity, severe toxicity, obscene, identity attack, insult, threat, and
sexually explicit. As we had no ground truth for our data, we manually inspected a 1 million random
subset of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>at varying thresholds. We found that a threshold of 0.1 provided good coverage
of filtering out NSFW text. If any of the detoxify category scores exceeds the threshold, the sample is
discarded. Qualitatively, we found that the model struggled with multilingual content, acronyms, and
innuendo. Even at 0.1, we noticed there are some captions that are NSFW. However, lowering the
threshold further heavily affected false positives. We therefore use a 0.1 threshold for all NSFW
categories, which on a random subset of one million captions achieves positive rates shown in
Table&#x00A0;<a 
href="#x1-82001r5">5<!--tex4ht:ref: tab:detoxify --></a>.
                                                                                         
                                                                                         
<!--l. 131--><p class="noindent" ><a 
 id="x1-82001r5"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-82002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;5: </span><span  
class="content">Detoxify positive rates by threshold on 1 million caption subset of Common Crawl.</span></div><!--tex4ht:label?: x1-82001rE -->
<!--l. 136--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-6" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-6-1g"><col 
id="TBL-6-1"><col 
id="TBL-6-2"><col 
id="TBL-6-3"><col 
id="TBL-6-4"><col 
id="TBL-6-5"><col 
id="TBL-6-6"><col 
id="TBL-6-7"><col 
id="TBL-6-8"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-6-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-1"  
class="td11"> Threshold  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-2"  
class="td11"> Toxicity  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-3"  
class="td11"> Severe Toxicity  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-4"  
class="td11"> Obscene  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-5"  
class="td11"> Identity Attack  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-6"  
class="td11"> Insult  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-7"  
class="td11"> Threat  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-1-8"  
class="td11"> Sexual Explicit  </td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-6-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-1"  
class="td11">    0.01      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-2"  
class="td11">  9.5%    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-3"  
class="td11">     1.0%        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-4"  
class="td11">  33.4%   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-5"  
class="td11">     1.8%         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-6"  
class="td11"> 35.0%  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-7"  
class="td11">  1.3%   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-2-8"  
class="td11">     2.0%        </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-6-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-1"  
class="td11">    0.1       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-2"  
class="td11">  3.6%    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-3"  
class="td11">     0.1%        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-4"  
class="td11">   0.8%    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-5"  
class="td11">     0.3%         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-6"  
class="td11">  1.4%  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-7"  
class="td11">  0.1%   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-6-3-8"  
class="td11">     1.0%        </td></tr><tr  
 style="vertical-align:baseline;" id="TBL-6-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-6-4-1"  
class="td11"> </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 149--><p class="noindent" >Second, on the vision side, we use a modified version of LAION-5B&#8217;s [<a 
href="#Xlaion5b">122</a>] CLIP-based binary classification
NSFW model, which takes CLIP ViT-L/14 visual embeddings as input. We remove the initial
multi-category encoder from the model, and retrain on the same data with an initial normalization layer
followed by a 4-layer multilayer perceptron. Our retrained model matches the performance of the original
model on their manually annotated testset. Specifically, we achieve 97.4% classification accuracy on a held
out test set compared to 96.1% for the original LAION NSFW image filtering model. Additional details
about the training data can be found in Appendix C.5 of the LAION-5B paper. In brief, the training data
contains 682K images that is roughly balanced with images from safe for work and NSFW
categories.
                                                                                         
                                                                                         
<!--l. 152--><p class="noindent" ><a 
 id="x1-82003r6"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-82004"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;6: </span><span  
class="content">Comparing LAION-2B CLIP based NSFW filtering model to Google Vision API Safe
Search adult category on a 40,000 random subset of Common Crawl.</span></div><!--tex4ht:label?: x1-82003rE -->
<!--l. 157--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-7" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-7-1g"><col 
id="TBL-7-1"><col 
id="TBL-7-2"><col 
id="TBL-7-3"><col 
id="TBL-7-4"><col 
id="TBL-7-5"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-7-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-7-1-1"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-1-2"  
class="td11">  False Positive Rate   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-1-3"  
class="td11">  True Positives    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-1-4"  
class="td11">                   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-1-5"  
class="td11">                        </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-7-2-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
Threshold</div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-2-2"  
class="td11"> (Relative to Google)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-2-3"  
class="td11"> (Manual Review)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-2-4"  
class="td11"> <div class="multirow"><!-- rows=0 -->
Model Positive Rate</div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-2-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
Google API Positive Rate</div>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-7-3-1"  
class="td11">    0.1      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-3-2"  
class="td11">        3.6%            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-3-3"  
class="td11">        2            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-3-4"  
class="td11">       14.4%           </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-3-5"  
class="td11">          3.5%               </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-7-4-1"  
class="td11">    0.2      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-4-2"  
class="td11">        0.6%            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-4-3"  
class="td11">        2            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-4-4"  
class="td11">        9.1%            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-4-5"  
class="td11">          3.5%               </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-7-5-1"  
class="td11">    0.3      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-5-2"  
class="td11">        0.3%            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-5-3"  
class="td11">        3            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-5-4"  
class="td11">        7.2%            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-7-5-5"  
class="td11">          3.5%               </td></tr><tr  
 style="vertical-align:baseline;" id="TBL-7-6-"><td  style="white-space:nowrap; text-align:center;" id="TBL-7-6-1"  
class="td11"> </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 171--><p class="noindent" >To evaluate our model and determine a threshold, we used Google Vision API&#8217;s SafeSearch explicit content
detector to generate labels for an 40,000 random subset of our candidate pool. Specifically, an
image is NSFW if SafeSearch classifies it as likely or very likely adult (i.e., sexually explicit).
As shown in Table&#x00A0;<a 
href="#x1-82003r6">6<!--tex4ht:ref: tab:nsfw --></a>, we found that by thresholding at 0.1 we achieve high recall relative to
SafeSearch and very few true positives after manual review. We also manually reviewed images
classified by SafeSearch as likely or very likely racy and found that the images were either
benign, subjectively suggestive but not explicit, or already found in the set of images labeled as
adult.
<h3 class="sectionHead"><span class="titlemark">F   </span> <a 
 id="x1-83000F"></a>Deduplication against evaluation sets</h3>
                                                                                         
                                                                                         
<!--l. 177--><p class="noindent" ><a 
 id="x1-83001r6"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 178--><p class="noindent" > <img 
src="figures/dedups-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-83002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;6: </span><span  
class="content">Candidate images (top) that are detected as duplicates against images in the evaluation
sets (bottom) are removed from the pool. In addition to exact duplicate images, near-duplicates
with variable aspect ratios, JPEG compression, overlays, color adjustment, and artistic rendering
are also detected. </span></div><!--tex4ht:label?: x1-83001rF -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 183--><p class="noindent" >To prevent data leakage, we filter <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>by removing duplicate and near-duplicate matches of
evaluation set images. See Figure <a 
href="#x1-83001r6">6<!--tex4ht:ref: fig:dedups --></a> for example query images from Common Crawl and corresponding
near-duplicates in our evaluations sets. We consider images as duplicates when the cosine similarity
between a query (Common Crawl image) feature and a reference (evaluation image) feature is higher
than a fixed threshold. We employ the deduplication model proposed by Yokoo&#x00A0;[<a 
href="#XYokoo2021Dedup">141</a>], which
earned 1st place in the Facebook AI Image Similarity Challenge (ISC) [<a 
href="#Xdouze2021isc">36</a>]. We choose a cosine
similarity threshold of 0.604169 to maximize the true duplicates detected, without removing
too many false duplicates from the pool. We compare against OpenAI&#8217;s CLIP ViT-B/32 as a
baseline on ISC. We find that for our threshold, the ISC model achieves precision 0.9 and
recall 0.8. At a threshold of 0.96, CLIP achieves the same precision 0.9, but a significantly
worse recall of 0.02. Approximately 2.8% of downloaded samples are flagged as evaluation set
near-duplicates.
<!--l. 185--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-83003r7"></a>
                                                                                         
                                                                                         
<!--l. 187--><p class="noindent" > <img 
src="figures/pr_curve_all_-.png" alt="PIC"  
width="225" height="225" >  <img 
src="figures/pr_curve_all_clip-.png" alt="PIC"  
width="225" height="225" >
<a 
 id="x1-83004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;7: </span><span  
class="content">Analysis of different de-duplication strategies across a variety of image transformations.
We see that the model introduced by Yokoo&#x00A0;[<a 
href="#XYokoo2021Dedup">141</a>] is better in almost every transformation, with
the exception of very aggressive aspect ratio modification.</span></div><!--tex4ht:label?: x1-83003rF -->
                                                                                         
                                                                                         
<!--l. 191--><p class="noindent" ></div><hr class="endfigure">
<!--l. 193--><p class="noindent" >To verify the performance of our de-duplication models with greater granularity, we modify the evaluation
procedure in Douze et&#x00A0;al.&#x00A0;[<a 
href="#Xdouze2021isc">36</a>] to include transformations which are representative of naturally-occurring
duplications on the Internet. Specifically, we study: 1) jpeg compression (encoding), 2) image flips, 3)
image rotations, 4) aspect ratio modifications, and 5) grayscaling. To do this, we sample 20% of the images
from each of our evaluation datasets uniformly at random to serve as a reference set of about 140,000
images. Next we sample 560,000 images uniformly at random from LAION-2B to serve as
distractors, for a 4-to-1 distractor to reference ratio. Finally, we apply each of the augmentations
above and use threshold filtering to determine duplicates. Figure&#x00A0;<a 
href="#x1-83003r7">7<!--tex4ht:ref: fig:dedup-analysis --></a> shows the results from the
deduplication model [<a 
href="#XYokoo2021Dedup">141</a>] compared with OpenAI&#8217;s CLIP ViT-L/14. At high recall values, we see that
CLIP filtering results in removing over 2<span 
class="cmsy-10x-x-109">&#x00D7; </span>the data as that of the deduplication model from
Yokoo&#x00A0;[<a 
href="#XYokoo2021Dedup">141</a>].
<h3 class="sectionHead"><span class="titlemark">G   </span> <a 
 id="x1-84000G"></a>Face blurring</h3>
<!--l. 198--><p class="noindent" >As an extra step to safeguard against issues of privacy that may arise from the use of data scraped from
the web, we include face blurring as part of our pool creation. To create face metadata, we use the SCRFD
face detector [<a 
href="#Xguo2021sample">49</a>] to extract bounding boxes for the faces in our images. These bounding boxes are
included as part of the image metadata in our pool. We make use of the pretrained SCRFD-10G model.
We use the same preprocessing as the one described in the official repository of the paper, with the
exception of providing <span 
class="cmr-10x-x-109">224 </span><span 
class="cmsy-10x-x-109">&#x00D7; </span><span 
class="cmr-10x-x-109">224 </span>input images (by padding each image to square and then
resizing) to limit computation costs. Invoking this model provides us with bounding boxes along
with an associated score, which we then compare against a threshold of <span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">3 </span>to keep or discard
this bounding box. This threshold is the default one used in the repository of SCRFD for the
visualization of bounding boxes, and we found it to perform well on our data as discussed
next.
<!--l. 200--><p class="noindent" >In Table <a 
href="#x1-84001r7">7<!--tex4ht:ref: tab:face_detection --></a> we can see the result of face detection on a set of 3293 images from <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. We
evaluate the detection on whether the image has visible faces or not (where images such as cartoon
drawings of non-real human faces are not considered as positives), and whether the detector has detected
these visible faces. We considered an image as a true positive if all the clearly visible faces in the image
were detected, based on the above thresholding process. We did not do extensive box labeling.
True positives are instead determined by human inspection. We compare the quality of these
detections with the Amazon Rekognition system, which is the one upon which the face detections
on ImageNet were based [<a 
href="#Xyang2022study">139</a>]. Note that in this scenario, the recall of the detectors is more
important than precision (as detecting a few more bounding boxes across our pool does not affect
privacy).
                                                                                         
                                                                                         
<!--l. 205--><p class="noindent" ><a 
 id="x1-84001r7"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-84002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;7: </span><span  
class="content">Face detection performance on a set of 3293 random images from <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</span></div><!--tex4ht:label?: x1-84001rG -->
<div class="tabular"> <table id="TBL-8" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-8-1g"><col 
id="TBL-8-1"><col 
id="TBL-8-2"><col 
id="TBL-8-3"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-8-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-8-1-1"  
class="td11"> &#x00A0;           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-1-2"  
class="td11"> SCRFD-10G  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-1-3"  
class="td11"> Amazon Rekognition  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-8-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-8-2-1"  
class="td11"> Accuracy  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-2-2"  
class="td11">       93.87  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-2-3"  
class="td11">              96.57  </td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-8-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-8-3-1"  
class="td11"> Precision  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-3-2"  
class="td11">       75.87  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-3-3"  
class="td11">              86.09  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-8-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-8-4-1"  
class="td11"> Recall      </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-4-2"  
class="td11">       90.53  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-8-4-3"  
class="td11">              93.75  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-8-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-8-5-1"  
class="td11">          </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 219--><p class="noindent" >To utilize these bounding boxes on our data, we apply a standard blurring pipeline, as proposed
by Yang et&#x00A0;al.&#x00A0;[<a 
href="#Xyang2022study">139</a>]. The result of this process is an image where the faces is blurred and
there is a smooth transition from blurred to clean parts of the image. In Figure <a 
href="#x1-84003r8">8<!--tex4ht:ref: fig:faces --></a> we see the
distribution of faces for the <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. Note that the majority of images do not contain
faces.
                                                                                         
                                                                                         
<!--l. 223--><p class="noindent" ><a 
 id="x1-84003r8"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 224--><p class="noindent" > <img 
src="figures/appx-faces-.png" alt="PIC"  
width="281" height="281" >
<a 
 id="x1-84004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;8: </span><span  
class="content">Frequency of predicted number of faces in the <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</span></div><!--tex4ht:label?: x1-84003rG -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 230--><p class="noindent" >As part of our competition pipeline, images are by default blurred during the download process. In Table <a 
href="#x1-84005r8">8<!--tex4ht:ref: tab:face_blur_test --></a>
we can see the results of training on 100M images with and without the application of face blurring, as
provided by our detector. We can see that the difference in performance is small, which suggests that the
application of face blurring does not significantly affect the performance on our downstream
tasks.
<!--l. 232--><p class="noindent" >Finally, we evaluated the detector we used for potential biases. More specifically, we used the detector on
the validation set of the FairFace dataset [<a 
href="#Xkarkkainen2021fairface">72</a>]. We found that the central face of the image was detected in
all the images of the validation set, regardless of subgroup.
                                                                                         
                                                                                         
<!--l. 235--><p class="noindent" ><a 
 id="x1-84005r8"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-84006"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;8: </span><span  
class="content">Effect of face blurring on zero-shot performance. Face blurring improves the privacy
preservation of our dataset, while affecting model performance negligibly. Results shown for the
<span 
class="ectt-1000">medium </span>scale.</span></div><!--tex4ht:label?: x1-84005rG -->
<!--l. 240--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-9" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-9-1g"><col 
id="TBL-9-1"><col 
id="TBL-9-2"><col 
id="TBL-9-3"><col 
id="TBL-9-4"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-9-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-9-1-1"  
class="td11"> Filtering                                                       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-1-2"  
class="td11"> Face blurring  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-1-3"  
class="td11"> ImageNet acc.  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-1-4"  
class="td11"> Avg. performance  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-9-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-9-2-1"  
class="td11">                                            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-2-2"  
class="td11">      <span 
class="cmsy-10x-x-109">&#x00D7;    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-2-3"  
class="td11">     0.209        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-2-4"  
class="td11">      0.246          </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-9-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-9-3-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
CLIP score (B/32, thresh. 0.3) + English filtering</div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-3-2"  
class="td11">      <span 
class="msam-10x-x-109">&#x2713;</span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-3-3"  
class="td11">     0.196        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-3-4"  
class="td11">      0.243          </td></tr><tr  
 style="vertical-align:baseline;" id="TBL-9-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-9-4-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:center;" id="TBL-9-4-2"  
class="td11"> <span 
class="cmsy-10x-x-109">&#x00D7; </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-9-4-3"  
class="td11"> 0.287 </td> <td  style="white-space:nowrap; text-align:center;" id="TBL-9-4-4"  
class="td11"> 0.301</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-9-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-9-5-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
CLIP score (B/32, 30%)</div>                                  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-5-2"  
class="td11">      <span 
class="msam-10x-x-109">&#x2713;</span>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-5-3"  
class="td11">     0.282        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-9-5-4"  
class="td11">      0.298          </td></tr><tr  
 style="vertical-align:baseline;" id="TBL-9-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-9-6-1"  
class="td11"> </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h3 class="sectionHead"><span class="titlemark">H   </span> <a 
 id="x1-85000H"></a><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> <span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>creation pipeline</h3>
                                                                                         
                                                                                         
<!--l. 256--><p class="noindent" ><a 
 id="x1-85001r9"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-85002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;9: </span><span  
class="content">Provided metadata for <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</span></div><!--tex4ht:label?: x1-85001rH -->
<div class="tabular"> <table id="TBL-10" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-10-1g"><col 
id="TBL-10-1"><col 
id="TBL-10-2"><col 
id="TBL-10-3"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-10-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-1-1"  
class="td11"> <span 
class="ecrm-1000">Generation Time                  </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-1-2"  
class="td11"> <span 
class="ecrm-1000">Label                              </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-1-3"  
class="td11">            <span 
class="ecrm-1000">Additional notes  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-2-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-2-2"  
class="td11"> <span 
class="ecrm-1000">uid                                 </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-2-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-10-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-3-1"  
class="td11">  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-3-2"  
class="td11"> <span 
class="ecrm-1000">url </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-3-3"  
class="td11"> <span 
class="ecrm-1000">Link to the image.</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-4-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-4-2"  
class="td11"> <span 
class="ecrm-1000">text                                </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-4-3"  
class="td11">             <span 
class="ecrm-1000">Image caption.  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-5-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-5-2"  
class="td11"> <span 
class="ecrm-1000">original_width                 </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-5-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-6-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-6-2"  
class="td11"> <span 
class="ecrm-1000">original_height                 </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-6-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-7-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Step 2</span></div>                                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-7-2"  
class="td11"> <span 
class="ecrm-1000">sha256                            </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-7-3"  
class="td11"> <span 
class="ecrm-1000">Safeguard for data poisoning.  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-8-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-8-2"  
class="td11"> <span 
class="ecrm-1000">clip_b32_similarity_score  </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-8-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-9-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-9-2"  
class="td11"> <span 
class="ecrm-1000">clip_b32_image_features   </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-9-3"  
class="td11">             <span 
class="ecrm-1000">In separate file.  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-10-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-10-2"  
class="td11"> <span 
class="ecrm-1000">clip_b32_text_features     </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-10-3"  
class="td11">             <span 
class="ecrm-1000">In separate file.  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-11-1"  
class="td11"> <span 
class="ecrm-1000">&#x00A0;                                        </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-11-2"  
class="td11"> <span 
class="ecrm-1000">clip_l14_similarity_score   </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-11-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-12-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-12-2"  
class="td11"> <span 
class="ecrm-1000">clip_l14_image_features    </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-12-3"  
class="td11">             <span 
class="ecrm-1000">In separate file.  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-13-1"  
class="td11"> <span 
class="ecrm-1000">&#x00A0;                                        </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-13-2"  
class="td11"> <span 
class="ecrm-1000">clip_l14_text_features      </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-13-3"  
class="td11">             <span 
class="ecrm-1000">In separate file.  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-14-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Step 1</span></div>                                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-14-2"  
class="td11"> <span 
class="ecrm-1000">face_bboxes                     </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-14-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-15-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-15-2"  
class="td11"> <span 
class="ecrm-1000">nsfw_image_score            </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-15-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-16-1"  
class="td11">                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-16-2"  
class="td11"> <span 
class="ecrm-1000">nsfw_text_score               </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-16-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-17-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Step 2, dropped during Step 3</span></div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-10-17-2"  
class="td11"> <span 
class="ecrm-1000">dedup_score                    </span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-10-17-3"  
class="td11">                         <span 
class="ecrm-1000">&#x00A0;  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-10-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-10-18-1"  
class="td11">                            </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 287--><p class="noindent" >Creating <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>was a multistep process, which involved (1) parsing image urls and alt-text from
Common Crawl dumps and downloading these images, (2) tagging images with metadata and (3)
conducting safety content filtering and evaluation set duplication. In this section we provide an overview of
the data pipeline used to create <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. For an overview of our &#8220;data funnel&#8221; see Figure
<a 
href="#x1-11002r2">2<!--tex4ht:ref: fig:data_pipeline --></a>.
     <dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   1. </dt><dd 
class="enumerate-enumitem">For the first step, we use parse Common Crawl metadata files to harvest image-text pairs
     (Section <a 
href="#x1-81000D">D<!--tex4ht:ref: app:parse-cc --></a>). We use <span 
class="ectt-1095">img2dataset</span><span class="footnote-mark"><a 
href="main9.html#fn8x0"><sup class="textsuperscript">8</sup></a></span><a 
 id="x1-85004f8"></a> 
     to obtain <span 
class="cmsy-10x-x-109">~</span>16.8B downloaded samples. This is the first, unfiltered version of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>,
     and contains only basic information for our images (i.e., the original image height, width, and
     alt-text caption). During this step we also resize images such that their largest dimension does
     not exceed 512px. This eases storage requirements for large images, but is still larger than the
     224px resolution used for later training stages.
     </dd><dt class="enumerate-enumitem">
   2. </dt><dd 
class="enumerate-enumitem">For the second step, we process our unfiltered pool and create richer metadata for each image-text
     pair. We generate the following for each sample:
          <ul class="itemize1">
          <li class="itemize">CLIP ViT-B/32 and CLIP ViT-L/14 image and text features, with their associated
          similarities.
          </li>
          <li class="itemize">NSFW scores for the image and the text, using the analysis described in Appendix <a 
href="#x1-82000E">E<!--tex4ht:ref: app:nsfw --></a>.
          </li>
          <li class="itemize">Deduplication score for the image, as described in Appendix <a 
href="#x1-83000F">F<!--tex4ht:ref: app:dedup --></a>.
          </li>
          <li class="itemize">Bounding boxes for faces detected in the image, using the method described in Appendix
          <a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
   3. </dt><dd 
class="enumerate-enumitem">For the third and final step, we filter our image-text pairs based on the metadata generated during
     the second stage. We filter out image-text pairs where the NSFW and deduplication scores exceed
     the respective thresholds (Section <a 
href="#x1-82000E">E<!--tex4ht:ref: app:nsfw --></a>). From the images that pass through this filtering, we keep only
     the desired amount (e.g., 12.8B images from the <span 
class="ectt-1000">xlarge </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>). Smaller pools are
     telescoping subsets of larger pools. We package the metadata and image urls, which is made publicly
     available to the participants. Note, we do not release raw image data but rather image urls pointing
     to images.</dd></dl>
<!--l. 307--><p class="noindent" >A summary of the metadata for each sample is found in Table <a 
href="#x1-85001r9">9<!--tex4ht:ref: tab:app_metadata --></a>. To validate our pipeline for duplication
and CLIP feature correctness, we also take ImageNet train though metadata generation as a unit test.
Using the deduplication features, we detect that 100% of the images are in fact duplicates. Additionally
using the CLIP ViT-B/32 and CLIP ViT-L/14 image features and corresponding text features from
                                                                                         
                                                                                         
OpenAI&#8217;s 80-prompt ensemble, we achieve 63.36% and 75.54% top-1 accuracies, which match the
performance reported in the CLIP paper&#x00A0;[<a 
href="#Xradford2021learning">104</a>].
<!--l. 310--><p class="noindent" >When creating pools of different scale (i.e., number of samples), we ensure that smaller pools
are subsets of larger pools. For instance, the <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is a subset of the <span 
class="ectt-1000">xlarge</span>
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.
<!--l. 312--><p class="noindent" >After <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is created, the participants can then download the final image-text pairs using the
provided files via <span 
class="ectt-1095">img2dataset</span>. To further ease the computational burden on participants, we additionally
provide metadata for each sample in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. Note that when downloading, our <span 
class="ectt-1095">img2dataset</span>
configuration automatically blurs faces. Hence this is an automatic step on not something participants
must do ad hoc.
<h3 class="sectionHead"><span class="titlemark">I   </span> <a 
 id="x1-86000I"></a><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>statistics</h3>
<!--l. 317--><p class="noindent" >To provide more information about the kinds of samples in our <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, we conduct additional
analysis on the <span 
class="ectt-1000">small </span>pool, which is an i.i.d. sample of downloaded data and a subset of the larger
pools.
<!--l. 319--><p class="noindent" >In Figure <a 
href="#x1-86001r9">9<!--tex4ht:ref: fig:clip_sim --></a> we show CLIP similarity similarity scores between images and their corresponding text. We
notice a flatter distribution of CLIP ViT-L/14 scores than corresponding B/32 scores.
<!--l. 321--><p class="noindent" >Turning our attention to images in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, in Figure <a 
href="#x1-86003r10">10<!--tex4ht:ref: fig:image_stats --></a>, we visualize the aspect ratios and sizes of
original images (i.e., before they are downloaded and resized). In Figure <a 
href="#x1-86005r11">11<!--tex4ht:ref: fig:resize_distrib --></a>, we display a distribution of
image height and width after <span 
class="ecti-1095">download </span>resizing. Notice that the majority of images are around
<span 
class="cmr-10x-x-109">224 </span><span 
class="cmsy-10x-x-109">&#x00D7; </span><span 
class="cmr-10x-x-109">224</span>px, which is the final resized resolution used for training.
<!--l. 324--><p class="noindent" >Analysing the textual component of each sample, we visualize frequency of the number of CLIP BPE
tokens in the captions (Figure <a 
href="#x1-86007r12">12<!--tex4ht:ref: fig:tokens --></a>) and most common languages (Figure <a 
href="#x1-86009r13">13<!--tex4ht:ref: fig:langdet_language --></a>). Token counts follow a
long-tailed distribution with much more mass in the short sequence range, while English is the
predominant language in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>according to fasttext and cld3.
<!--l. 327--><p class="noindent" >We also look at url statistics. In Figure <a 
href="#x1-86011r14">14<!--tex4ht:ref: fig:domain --></a> we see common domain names in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>(e.g.,
wordpress domains) and common suffixes (e.g., .com or .net).
                                                                                         
                                                                                         
<!--l. 330--><p class="noindent" ><a 
 id="x1-86001r9"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 331--><p class="noindent" > <img 
src="figures/appx-clip_sim-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-86002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;9:  </span><span  
class="content">Image-text  similarity  score  distributions  using  CLIP  ViT-B/32  <span 
class="ecti-1095">(left)  </span>and  ViT-L/14
<span 
class="ecti-1095">(right) </span>models. We plot samples from the <span 
class="ectt-1095">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, which are an i.i.d. sample of the
<span 
class="ectt-1095">xlarge </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</span></div><!--tex4ht:label?: x1-86001rI -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 337--><p class="noindent" ><a 
 id="x1-86003r10"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 338--><p class="noindent" > <img 
src="figures/appx-image_statistics-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-86004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;10: </span><span  
class="content">Statistics for images in the <span 
class="ectt-1095">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, before applying resizing.</span></div><!--tex4ht:label?: x1-86003rI -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 345--><p class="noindent" ><a 
 id="x1-86005r11"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 346--><p class="noindent" > <img 
src="figures/appx-img_distrib-.png" alt="PIC"  
width="187" height="187" >
<a 
 id="x1-86006"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;11: </span><span  
class="content"><span 
class="ecbx-1095">Image pixel heatmap. </span>Each entry in the above heatmap represents the estimated
probability that a pixel is occupied. The center entry has a value of 1.0 as every image has a
center pixel. We compute the heatmap over the <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. Note that image sizes are
bounded as we resize all images such that their max dimension does not exceed 512px during dataset
download.</span></div><!--tex4ht:label?: x1-86005rI -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 353--><p class="noindent" ><a 
 id="x1-86007r12"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 354--><p class="noindent" > <img 
src="figures/appx-tokens-.png" alt="PIC"  
width="328" height="328" >
<a 
 id="x1-86008"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;12: </span><span  
class="content">Distribution of token length for alt-text in the <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. The CLIP BPE
tokenizer is used for tokenization.</span></div><!--tex4ht:label?: x1-86007rI -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 362--><p class="noindent" ><a 
 id="x1-86009r13"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 363--><p class="noindent" > <img 
src="figures/appx-langdet-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-86010"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;13: </span><span  
class="content">Counts for the top 25 most frequent languages in the <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, as predicted
by fasttext <span 
class="ecti-1095">(left) </span>and cld3 (<span 
class="ecti-1095">right</span>).</span></div><!--tex4ht:label?: x1-86009rI -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 370--><p class="noindent" ><a 
 id="x1-86011r14"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 371--><p class="noindent" > <img 
src="figures/appx-domain-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-86012"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;14: </span><span  
class="content">Counts for the top 25 most frequent domains <span 
class="ecti-1095">(left) </span>and suffixes (<span 
class="ecti-1095">right</span>) in the <span 
class="ectt-1000">small</span>
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</span></div><!--tex4ht:label?: x1-86011rI -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h3 class="sectionHead"><span class="titlemark">J   </span> <a 
 id="x1-87000J"></a>Efficient training on data subsets</h3>
<!--l. 384--><p class="noindent" >When training at large scale, it is important to use efficient access patterns to load training
data. This typically means that data must be loaded using large sequential reads instead of
random reads in order to maximize throughput. In <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>, this is facilitated by the
WebDataset<span class="footnote-mark"><a 
href="main10.html#fn9x0"><sup class="textsuperscript">9</sup></a></span><a 
 id="x1-87001f9"></a> 
format which stores the training examples in tar files (called &#8220;shards&#8221;) and WebDataLoader which makes it
easy to load data stored in this format.
<!--l. 388--><p class="noindent" >Given an arbitrary subset of a pool, we would like to efficiently train on that subset. Because WebDataset
format does not permit efficient random access (a feature inherited from tar), we must read
through the entire pool to select the required images. There are two ways to implement this
filtering:
     <dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   1. </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Filter during training: </span>we apply a predicate during training data loading that discards data
     not present in the subset.<a 
 id="x1-870021"></a>
     </dd><dt class="enumerate-enumitem">
   2. </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Filter before training: </span>we iterate over the pool, selecting the images in the subset, and
     write them to a new WebDataset.<a 
 id="x1-870032"></a></dd></dl>
<!--l. 395--><p class="noindent" >After some profiling, we concluded that option&#x00A0;<a 
href="#x1-870021">1<!--tex4ht:ref: app:resharder:enum-train --></a> had too much overhead in the case where the subset is
much smaller than the pool. To see why, note that if the subset is an <img 
src="main4x.png" alt="p  "  class="math" >-fraction of the pool size, then we
would end up reading a <img 
src="main5x.png" alt="1&#x2215;p  "  class="math" > factor more data than needed for training. Instead, we give
an implementation of option&#x00A0;<a 
href="#x1-870032">2<!--tex4ht:ref: app:resharder:enum-reshard --></a>, which performs at most twice as many reads as needed for
training.<span class="footnote-mark"><a 
href="main11.html#fn10x0"><sup class="textsuperscript">10</sup></a></span><a 
 id="x1-87004f10"></a> 
<!--l. 398--><p class="noindent" >Our tool, called the <span 
class="ecti-1095">resharder</span>, reads a set of uids in NumPy array format, scans through the
pool, selecting those examples, and writes them to a new WebDataset. The resharder uses
multiprocessing to make good use of hardware and can be distributed over many computers to
further increase throughput. The resharder also supports streaming data to and from cloud
storage such as Amazon S3. The resharder is provided to participants as part of the competition
tooling.
                                                                                         
                                                                                         
<h3 class="sectionHead"><span class="titlemark">K   </span> <a 
 id="x1-88000K"></a>Effect of duplicates in the training data</h3>
<!--l. 406--><p class="noindent" >Given that <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>was constructed by scraping the web for image and text pairs, there is a
likelihood that some of our images are duplicates of each other, even if they originated from different web
sources and have different captions. Here we examine the effect of removing such duplicates. We
used the technique proposed by Webster et&#x00A0;al.&#x00A0;[<a 
href="#Xwebster2023deduplication">135</a>], where CLIP image features are first
compressed and then used to do an approximate nearest neighbor search. After this process, two
images <span 
class="cmmi-10x-x-109">x </span>and <span 
class="cmmi-10x-x-109">y </span>are considered duplicates if <img 
src="main6x.png" alt="|dADC(xd,xA)D-Cd(AxD,xC)-(x,y)|"  class="frac" align="middle"> <span 
class="cmmi-10x-x-109">&#x003C; T</span><sub><span 
class="cmmi-8">ADC</span></sub>, where <span 
class="cmmi-10x-x-109">T</span><sub><span 
class="cmmi-8">ADC</span></sub> is
some threshold and <span 
class="cmmi-10x-x-109">d</span><sub><span 
class="cmmi-8">ADC</span></sub><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">x,x</span><span 
class="cmr-10x-x-109">) </span>is the distance of a vector with its quantized version used for
approximate nearest neighbor search. For each image, we search duplicates across its <span 
class="cmr-10x-x-109">1000 </span>nearest
neighbors, and keep it if it&#8217;s the one with the highest CLIP ViT-L/14 similarity score across its
duplicates. Results can be seen in Table <a 
href="#x1-88001r10">10<!--tex4ht:ref: tab:app_dedup_training --></a>, both when this technique is used by itself and
in conjunction with ViT-B/32 filtering. We can see that the there are small improvements
over using CLIP filtering by itself with respect to the average performance across evaluation
datasets.
                                                                                         
                                                                                         
<!--l. 409--><p class="noindent" ><a 
 id="x1-88001r10"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-88002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;10: </span><span  
class="content">Effect of deduplication of training set for the medium size <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. The filtering
performed here is CLIP B32 score top 30% (see Table <a 
href="#x1-110017r22">22<!--tex4ht:ref: tab:full-medium --></a>). Higher threshold values lead to more
samples being labeled as duplicates.</span></div><!--tex4ht:label?: x1-88001rK -->
<div class="tabular"> <table id="TBL-11" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-11-1g"><col 
id="TBL-11-1"><col 
id="TBL-11-2"><col 
id="TBL-11-3"><col 
id="TBL-11-4"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-11-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-1-1"  
class="td11"> <span 
class="ecrm-1000">Subset                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-1-2"  
class="td11"> <span 
class="ecrm-1000">Training dataset size </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-1-3"  
class="td11"> <span 
class="ecrm-1000">ImageNet accuracy </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-1-4"  
class="td11"> <span 
class="ecrm-1000">Average performance </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-2-1"  
class="td11"> <span 
class="cmmi-10">T</span><sub>
<span 
class="cmmi-7">ADC</span></sub> <span 
class="cmr-10">= 0</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1</span><span 
class="ecrm-1000">, without filtering </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-2-2"  
class="td11">       <span 
class="ecrm-1000">99.8M           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-2-3"  
class="td11">       <span 
class="ecrm-1000">0.195          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-2-4"  
class="td11">       <span 
class="ecrm-1000">0.272            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-3-1"  
class="td11"> <span 
class="cmmi-10">T</span><sub><span 
class="cmmi-7">ADC</span></sub> <span 
class="cmr-10">= 0</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">2</span><span 
class="ecrm-1000">, without filtering </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-3-2"  
class="td11">       <span 
class="ecrm-1000">85.9M           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-3-3"  
class="td11">       <span 
class="ecrm-1000">0.200          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-3-4"  
class="td11">       <span 
class="ecrm-1000">0.274            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-4-1"  
class="td11"> <span 
class="cmmi-10">T</span><sub><span 
class="cmmi-7">ADC</span></sub> <span 
class="cmr-10">= 0</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5</span><span 
class="ecrm-1000">, without filtering </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-4-2"  
class="td11">       <span 
class="ecrm-1000">29.6M           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-4-3"  
class="td11">       <span 
class="ecrm-1000">0.227          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-4-4"  
class="td11">       <span 
class="ecrm-1000">0.292            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-5-1"  
class="td11"> <span 
class="cmmi-10">T</span><sub><span 
class="cmmi-7">ADC</span></sub> <span 
class="cmr-10">= 0</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1</span><span 
class="ecrm-1000">, with filtering      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-5-2"  
class="td11">       <span 
class="ecrm-1000">33.5M           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-5-3"  
class="td11">       <span 
class="ecrm-1000">0.288          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-5-4"  
class="td11">       <span 
class="ecrm-1000">0.333            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-6-1"  
class="td11"> <span 
class="cmmi-10">T</span><sub><span 
class="cmmi-7">ADC</span></sub> <span 
class="cmr-10">= 0</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">2</span><span 
class="ecrm-1000">, with filtering      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-6-2"  
class="td11">       <span 
class="ecrm-1000">30.6M           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-6-3"  
class="td11">       <span 
class="ecrm-1000">0.289          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-6-4"  
class="td11">       <span 
class="ecrm-1000">0.333            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-7-1"  
class="td11"> <span 
class="cmmi-10">T</span><sub><span 
class="cmmi-7">ADC</span></sub> <span 
class="cmr-10">= 0</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5</span><span 
class="ecrm-1000">, with filtering      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-7-2"  
class="td11">       <span 
class="ecrm-1000">15.5M           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-7-3"  
class="td11">       <span 
class="ecrm-1000">0.252          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-11-7-4"  
class="td11">       <span 
class="ecrm-1000">0.307            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-11-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-11-8-1"  
class="td11">                          </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h3 class="sectionHead"><span class="titlemark">L   </span> <a 
 id="x1-89000L"></a>Training with additional steps</h3>
<!--l. 432--><p class="noindent" >Recall that one of our major design decisions for <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>is to fix the hyperparameters associated with
model training, following closely hyperparameters from prior work [<a 
href="#Xradford2021learning">104</a>]. We choose to fix hyperparameters
to place emphasis on data curation and remove confounders arising from hyperparameter differences
between participants. Here we ablate our hyperparameter configuration by training <span 
class="ectt-1000">small </span>baselines for 10<span 
class="cmsy-10x-x-109">&#x00D7;</span>
more steps. In Figure <a 
href="#x1-89001r15">15<!--tex4ht:ref: fig:steps --></a> we see positive correlation for ImageNet accuracy for the ablated and original
hyperparameter configurations. We see similar correlation for average performance. See Table <a 
href="#x1-89003r11">11<!--tex4ht:ref: tab:app_steps --></a> for
specific values.
                                                                                         
                                                                                         
<!--l. 435--><p class="noindent" ><a 
 id="x1-89001r15"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 436--><p class="noindent" > <img 
src="figures/appx-steps-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-89002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;15: </span><span  
class="content"><span 
class="ecti-1095">(left) </span>The effect of training for 10<span 
class="cmsy-10x-x-109">&#x00D7; </span>steps for for <span 
class="ectt-1000">small </span>filtering track baselines on
ImageNet. <span 
class="ecti-1095">(right) </span>Similar plot but for Avg. performance. While the ordering of some methods
changes quite drastically, we, in general, see a positive correlation.</span></div><!--tex4ht:label?: x1-89001rL -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 443--><p class="noindent" ><a 
 id="x1-89003r11"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-89004"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;11: </span><span  
class="content">Experiment details when extending the number of steps by 10 times the standard amount
for that scale.</span></div><!--tex4ht:label?: x1-89003rL -->
<!--l. 450--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-12" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-12-1g"><col 
id="TBL-12-1"><col 
id="TBL-12-2"><col 
id="TBL-12-3"><col 
id="TBL-12-4"><col 
id="TBL-12-5"><col 
id="TBL-12-6"><col 
id="TBL-12-7"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-12-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Scale</span></div>    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-1-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div>                                                                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-1-3"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-1-4"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-1-7"  
class="td11"> <span 
class="ecrm-1000">Average over </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-2-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-2-2"  
class="td11">                                                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-2-3"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-2-4"  
class="td11"> <span 
class="ecrm-1000">dist. shifts </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-2-5"  
class="td11">       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-2-6"  
class="td11">         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-2-7"  
class="td11"> <span 
class="ecrm-1000">38 datasets  </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-12-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-3-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-12-3-2"  
class="td11"> <span 
class="ecrm-1000">No filtering </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-12-3-3"  
class="td11"> <span 
class="ecrm-1000">0.102 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-12-3-4"  
class="td11"> <span 
class="ecrm-1000">0.093 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-12-3-5"  
class="td11"> <span 
class="ecrm-1000">0.204 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-12-3-6"  
class="td11"> <span 
class="ecrm-1000">0.125 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-12-3-7"  
class="td11"> <span 
class="ecrm-1000">0.194</span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-4-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-4-2"  
class="td11"> <span 
class="ecrm-1000">Random subset(75%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-4-3"  
class="td11">   <span 
class="ecrm-1000">0.078    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-4-4"  
class="td11">   <span 
class="ecrm-1000">0.072     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-4-5"  
class="td11"> <span 
class="ecrm-1000">0.182  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-4-6"  
class="td11">  <span 
class="ecrm-1000">0.109    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-4-7"  
class="td11">    <span 
class="ecrm-1000">0.177      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-5-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-5-2"  
class="td11"> <span 
class="ecrm-1000">Random subset(50%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-5-3"  
class="td11">   <span 
class="ecrm-1000">0.045    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-5-4"  
class="td11">   <span 
class="ecrm-1000">0.049     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-5-5"  
class="td11"> <span 
class="ecrm-1000">0.161  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-5-6"  
class="td11">  <span 
class="ecrm-1000">0.096    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-5-7"  
class="td11">    <span 
class="ecrm-1000">0.149      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-6-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-6-2"  
class="td11"> <span 
class="ecrm-1000">Random subset(25%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-6-3"  
class="td11">   <span 
class="ecrm-1000">0.023    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-6-4"  
class="td11">   <span 
class="ecrm-1000">0.029     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-6-5"  
class="td11"> <span 
class="ecrm-1000">0.134  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-6-6"  
class="td11">  <span 
class="ecrm-1000">0.071    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-6-7"  
class="td11">    <span 
class="ecrm-1000">0.119      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-7-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-7-2"  
class="td11"> <span 
class="ecrm-1000">Random subset(10%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-7-3"  
class="td11">   <span 
class="ecrm-1000">0.010    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-7-4"  
class="td11">   <span 
class="ecrm-1000">0.018     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-7-5"  
class="td11"> <span 
class="ecrm-1000">0.119  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-7-6"  
class="td11">  <span 
class="ecrm-1000">0.067    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-7-7"  
class="td11">    <span 
class="ecrm-1000">0.101      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-8-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-8-2"  
class="td11"> <span 
class="ecrm-1000">Random subset(1%)                                                         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-8-3"  
class="td11">   <span 
class="ecrm-1000">0.002    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-8-4"  
class="td11">   <span 
class="ecrm-1000">0.006     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-8-5"  
class="td11"> <span 
class="ecrm-1000">0.097  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-8-6"  
class="td11">  <span 
class="ecrm-1000">0.055    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-8-7"  
class="td11">    <span 
class="ecrm-1000">0.082      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-9-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-9-2"  
class="td11"> <span 
class="ecrm-1000">Caption length                                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-9-3"  
class="td11">   <span 
class="ecrm-1000">0.085    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-9-4"  
class="td11">   <span 
class="ecrm-1000">0.080     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-9-5"  
class="td11"> <span 
class="ecrm-1000">0.198  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-9-6"  
class="td11">  <span 
class="ecrm-1000">0.116    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-9-7"  
class="td11">    <span 
class="ecrm-1000">0.183      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-10-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-10-2"  
class="td11"> <span 
class="ecrm-1000">Image size                                                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-10-3"  
class="td11">   <span 
class="ecrm-1000">0.066    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-10-4"  
class="td11">   <span 
class="ecrm-1000">0.064     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-10-5"  
class="td11"> <span 
class="ecrm-1000">0.153  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-10-6"  
class="td11">  <span 
class="ecrm-1000">0.101    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-10-7"  
class="td11">    <span 
class="ecrm-1000">0.157      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-11-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-11-2"  
class="td11"> <span 
class="ecrm-1000">English (fasttext)                                                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-11-3"  
class="td11">   <span 
class="ecrm-1000">0.068    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-11-4"  
class="td11">   <span 
class="ecrm-1000">0.068     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-11-5"  
class="td11"> <span 
class="ecrm-1000">0.172  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-11-6"  
class="td11">  <span 
class="ecrm-1000">0.095    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-11-7"  
class="td11">    <span 
class="ecrm-1000">0.158      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-12-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-12-2"  
class="td11"> <span 
class="ecrm-1000">English (fasttext) and caption length                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-12-3"  
class="td11">   <span 
class="ecrm-1000">0.066    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-12-4"  
class="td11">   <span 
class="ecrm-1000">0.065     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-12-5"  
class="td11"> <span 
class="ecrm-1000">0.182  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-12-6"  
class="td11">  <span 
class="ecrm-1000">0.095    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-12-7"  
class="td11">    <span 
class="ecrm-1000">0.162      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-13-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-13-2"  
class="td11"> <span 
class="ecrm-1000">English (fasttext), caption length, and image size                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-13-3"  
class="td11">   <span 
class="ecrm-1000">0.045    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-13-4"  
class="td11">   <span 
class="ecrm-1000">0.048     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-13-5"  
class="td11"> <span 
class="ecrm-1000">0.164  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-13-6"  
class="td11">  <span 
class="ecrm-1000">0.084    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-13-7"  
class="td11">    <span 
class="ecrm-1000">0.148      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-14-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-14-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 10%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-14-3"  
class="td11">   <span 
class="ecrm-1000">0.035    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-14-4"  
class="td11">   <span 
class="ecrm-1000">0.046     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-14-5"  
class="td11"> <span 
class="ecrm-1000">0.162  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-14-6"  
class="td11">  <span 
class="ecrm-1000">0.072    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-14-7"  
class="td11">    <span 
class="ecrm-1000">0.139      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-15-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-15-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 20%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-15-3"  
class="td11">   <span 
class="ecrm-1000">0.076    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-15-4"  
class="td11">   <span 
class="ecrm-1000">0.076     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-15-5"  
class="td11"> <span 
class="ecrm-1000">0.182  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-15-6"  
class="td11">  <span 
class="ecrm-1000">0.088    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-15-7"  
class="td11">    <span 
class="ecrm-1000">0.171      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-16-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-16-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 30%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-16-3"  
class="td11">   <span 
class="ecrm-1000">0.096    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-16-4"  
class="td11">   <span 
class="ecrm-1000">0.090     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-16-5"  
class="td11"> <span 
class="ecrm-1000">0.221  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-16-6"  
class="td11">  <span 
class="ecrm-1000">0.104    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-16-7"  
class="td11">    <span 
class="ecrm-1000">0.204      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-17-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-17-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 40%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-17-3"  
class="td11">   <span 
class="ecrm-1000">0.081    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-17-4"  
class="td11">   <span 
class="ecrm-1000">0.077     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-17-5"  
class="td11"> <span 
class="ecrm-1000">0.200  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-17-6"  
class="td11">  <span 
class="ecrm-1000">0.107    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-17-7"  
class="td11">    <span 
class="ecrm-1000">0.191      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-18-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-18-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 50%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-18-3"  
class="td11">   <span 
class="ecrm-1000">0.106    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-18-4"  
class="td11">   <span 
class="ecrm-1000">0.097     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-18-5"  
class="td11"> <span 
class="ecrm-1000">0.211  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-18-6"  
class="td11">  <span 
class="ecrm-1000">0.113    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-18-7"  
class="td11">    <span 
class="ecrm-1000">0.203      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-19-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-19-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 75%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-19-3"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-19-4"  
class="td11">   <span 
class="ecrm-1000">0.096     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-19-5"  
class="td11"> <span 
class="ecrm-1000">0.210  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-19-6"  
class="td11">  <span 
class="ecrm-1000">0.126    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-19-7"  
class="td11">    <span 
class="ecrm-1000">0.196      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-20-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-20-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 90%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-20-3"  
class="td11">   <span 
class="ecrm-1000">0.105    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-20-4"  
class="td11">   <span 
class="ecrm-1000">0.096     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-20-5"  
class="td11"> <span 
class="ecrm-1000">0.212  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-20-6"  
class="td11">  <span 
class="ecrm-1000">0.127    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-20-7"  
class="td11">    <span 
class="ecrm-1000">0.200      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-21-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-21-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3 + English filter                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-21-3"  
class="td11">   <span 
class="ecrm-1000">0.029    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-21-4"  
class="td11">   <span 
class="ecrm-1000">0.036     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-21-5"  
class="td11"> <span 
class="ecrm-1000">0.152  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-21-6"  
class="td11">  <span 
class="ecrm-1000">0.071    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-21-7"  
class="td11">    <span 
class="ecrm-1000">0.133      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-22-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-22-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.28 + English filter                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-22-3"  
class="td11">   <span 
class="ecrm-1000">0.035    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-22-4"  
class="td11">   <span 
class="ecrm-1000">0.041     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-22-5"  
class="td11"> <span 
class="ecrm-1000">0.168  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-22-6"  
class="td11">  <span 
class="ecrm-1000">0.080    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-22-7"  
class="td11">    <span 
class="ecrm-1000">0.145      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-23-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-23-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-23-3"  
class="td11">   <span 
class="ecrm-1000">0.076    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-23-4"  
class="td11">   <span 
class="ecrm-1000">0.078     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-23-5"  
class="td11"> <span 
class="ecrm-1000">0.199  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-23-6"  
class="td11">  <span 
class="ecrm-1000">0.089    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-23-7"  
class="td11">    <span 
class="ecrm-1000">0.181      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-24-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-24-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 10%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-24-3"  
class="td11">   <span 
class="ecrm-1000">0.026    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-24-4"  
class="td11">   <span 
class="ecrm-1000">0.037     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-24-5"  
class="td11"> <span 
class="ecrm-1000">0.130  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-24-6"  
class="td11">  <span 
class="ecrm-1000">0.069    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-24-7"  
class="td11">    <span 
class="ecrm-1000">0.123      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-25-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-25-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-25-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 20%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-25-3"  
class="td11">   <span 
class="ecrm-1000">0.060    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-25-4"  
class="td11">   <span 
class="ecrm-1000">0.064     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-25-5"  
class="td11"> <span 
class="ecrm-1000">0.161  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-25-6"  
class="td11">  <span 
class="ecrm-1000">0.085    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-25-7"  
class="td11">    <span 
class="ecrm-1000">0.152      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-26-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-26-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-26-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 30%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-26-3"  
class="td11">   <span 
class="ecrm-1000">0.088    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-26-4"  
class="td11">   <span 
class="ecrm-1000">0.087     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-26-5"  
class="td11"> <span 
class="ecrm-1000">0.199  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-26-6"  
class="td11">  <span 
class="ecrm-1000">0.098    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-26-7"  
class="td11">    <span 
class="ecrm-1000">0.187      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-27-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-27-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-27-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 40%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-27-3"  
class="td11">   <span 
class="ecrm-1000">0.100    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-27-4"  
class="td11">   <span 
class="ecrm-1000">0.096     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-27-5"  
class="td11"> <span 
class="ecrm-1000">0.217  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-27-6"  
class="td11">  <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-27-7"  
class="td11">    <span 
class="ecrm-1000">0.206      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-28-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-28-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-28-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 50%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-28-3"  
class="td11">   <span 
class="ecrm-1000">0.104    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-28-4"  
class="td11">   <span 
class="ecrm-1000">0.098     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-28-5"  
class="td11"> <span 
class="ecrm-1000">0.212  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-28-6"  
class="td11">  <span 
class="ecrm-1000">0.114    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-28-7"  
class="td11">    <span 
class="ecrm-1000">0.201      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-29-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-29-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-29-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 75%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-29-3"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-29-4"  
class="td11">   <span 
class="ecrm-1000">0.095     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-29-5"  
class="td11"> <span 
class="ecrm-1000">0.189  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-29-6"  
class="td11">  <span 
class="ecrm-1000">0.121    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-29-7"  
class="td11">    <span 
class="ecrm-1000">0.190      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-30-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-30-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-30-2"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 90%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-30-3"  
class="td11">   <span 
class="ecrm-1000">0.105    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-30-4"  
class="td11">   <span 
class="ecrm-1000">0.095     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-30-5"  
class="td11"> <span 
class="ecrm-1000">0.203  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-30-6"  
class="td11">  <span 
class="ecrm-1000">0.123    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-30-7"  
class="td11">    <span 
class="ecrm-1000">0.196      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-31-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-31-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-31-2"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet1k)                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-31-3"  
class="td11">   <span 
class="ecrm-1000">0.053    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-31-4"  
class="td11">   <span 
class="ecrm-1000">0.053     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-31-5"  
class="td11"> <span 
class="ecrm-1000">0.162  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-31-6"  
class="td11">  <span 
class="ecrm-1000">0.082    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-31-7"  
class="td11">    <span 
class="ecrm-1000">0.145      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-32-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-32-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-32-2"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet21k)                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-32-3"  
class="td11">   <span 
class="ecrm-1000">0.063    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-32-4"  
class="td11">   <span 
class="ecrm-1000">0.059     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-32-5"  
class="td11"> <span 
class="ecrm-1000">0.173  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-32-6"  
class="td11">  <span 
class="ecrm-1000">0.094    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-32-7"  
class="td11">    <span 
class="ecrm-1000">0.166      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-33-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-33-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-33-2"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet1k)                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-33-3"  
class="td11">   <span 
class="ecrm-1000">0.012    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-33-4"  
class="td11">   <span 
class="ecrm-1000">0.018     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-33-5"  
class="td11"> <span 
class="ecrm-1000">0.120  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-33-6"  
class="td11">  <span 
class="ecrm-1000">0.060    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-33-7"  
class="td11">    <span 
class="ecrm-1000">0.104      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-34-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-34-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-34-2"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet21k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-34-3"  
class="td11">   <span 
class="ecrm-1000">0.060    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-34-4"  
class="td11">   <span 
class="ecrm-1000">0.064     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-34-5"  
class="td11"> <span 
class="ecrm-1000">0.170  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-34-6"  
class="td11">  <span 
class="ecrm-1000">0.090    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-34-7"  
class="td11">    <span 
class="ecrm-1000">0.159      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-35-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-35-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-35-2"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP B32 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-35-3"  
class="td11">   <span 
class="ecrm-1000">0.058    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-35-4"  
class="td11">   <span 
class="ecrm-1000">0.059     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-35-5"  
class="td11"> <span 
class="ecrm-1000">0.179  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-35-6"  
class="td11">  <span 
class="ecrm-1000">0.089    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-35-7"  
class="td11">    <span 
class="ecrm-1000">0.160      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-36-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-36-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-36-2"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP L14 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-36-3"  
class="td11">   <span 
class="ecrm-1000">0.049    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-36-4"  
class="td11">   <span 
class="ecrm-1000">0.051     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-36-5"  
class="td11"> <span 
class="ecrm-1000">0.171  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-36-6"  
class="td11">  <span 
class="ecrm-1000">0.083    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-36-7"  
class="td11">    <span 
class="ecrm-1000">0.149      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-37-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-37-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-37-2"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP B32 score top 30% </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-37-3"  
class="td11">   <span 
class="ecrm-1000">0.071    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-37-4"  
class="td11">   <span 
class="ecrm-1000">0.070     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-37-5"  
class="td11"> <span 
class="ecrm-1000">0.192  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-37-6"  
class="td11">  <span 
class="ecrm-1000">0.092    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-37-7"  
class="td11">    <span 
class="ecrm-1000">0.174      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-38-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-38-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">small</span></div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-38-2"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP L14 score top 30% </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-38-3"  
class="td11">   <span 
class="ecrm-1000">0.064    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-38-4"  
class="td11">   <span 
class="ecrm-1000">0.065     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-38-5"  
class="td11"> <span 
class="ecrm-1000">0.200  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-38-6"  
class="td11">  <span 
class="ecrm-1000">0.085    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-38-7"  
class="td11">    <span 
class="ecrm-1000">0.172      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-39-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-39-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-39-2"  
class="td11"> <span 
class="ecrm-1000">No filtering                                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-39-3"  
class="td11">   <span 
class="ecrm-1000">0.370    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-39-4"  
class="td11">   <span 
class="ecrm-1000">0.304     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-39-5"  
class="td11"> <span 
class="ecrm-1000">0.387  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-39-6"  
class="td11">  <span 
class="ecrm-1000">0.259    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-39-7"  
class="td11">    <span 
class="ecrm-1000">0.376      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-40-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-40-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-40-2"  
class="td11"> <span 
class="ecrm-1000">English (fasttext), caption length, and image size                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-40-3"  
class="td11">   <span 
class="ecrm-1000">0.317    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-40-4"  
class="td11">   <span 
class="ecrm-1000">0.269     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-40-5"  
class="td11"> <span 
class="ecrm-1000">0.324  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-40-6"  
class="td11">  <span 
class="ecrm-1000">0.194    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-40-7"  
class="td11">    <span 
class="ecrm-1000">0.328      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-41-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-41-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-41-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 30%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-41-3"  
class="td11">   <span 
class="ecrm-1000">0.436    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-41-4"  
class="td11">   <span 
class="ecrm-1000">0.351     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-41-5"  
class="td11"> <span 
class="ecrm-1000">0.433  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-41-6"  
class="td11">  <span 
class="ecrm-1000">0.245    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-41-7"  
class="td11">    <span 
class="ecrm-1000">0.422      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-42-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-42-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-42-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 40%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-42-3"  
class="td11">   <span 
class="ecrm-1000">0.434    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-42-4"  
class="td11">   <span 
class="ecrm-1000">0.353     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-42-5"  
class="td11"> <span 
class="ecrm-1000">0.448  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-42-6"  
class="td11">  <span 
class="ecrm-1000">0.263    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-42-7"  
class="td11">    <span 
class="ecrm-1000">0.434      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-43-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-43-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-43-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 50%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-43-3"  
class="td11">   <span 
class="ecrm-1000">0.426    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-43-4"  
class="td11">   <span 
class="ecrm-1000">0.352     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-43-5"  
class="td11"> <span 
class="ecrm-1000">0.439  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-43-6"  
class="td11">  <span 
class="ecrm-1000">0.273    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-43-7"  
class="td11">    <span 
class="ecrm-1000">0.425      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-44-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-44-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-44-2"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 75%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-44-3"  
class="td11">   <span 
class="ecrm-1000">0.398    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-44-4"  
class="td11">   <span 
class="ecrm-1000">0.325     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-44-5"  
class="td11"> <span 
class="ecrm-1000">0.396  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-44-6"  
class="td11">  <span 
class="ecrm-1000">0.271    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-44-7"  
class="td11">    <span 
class="ecrm-1000">0.402      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-45-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-45-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-45-2"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet1k)                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-45-3"  
class="td11">   <span 
class="ecrm-1000">0.363    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-45-4"  
class="td11">   <span 
class="ecrm-1000">0.294     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-45-5"  
class="td11"> <span 
class="ecrm-1000">0.347  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-45-6"  
class="td11">  <span 
class="ecrm-1000">0.197    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-45-7"  
class="td11">    <span 
class="ecrm-1000">0.341      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-46-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-46-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-46-2"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet21k)                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-46-3"  
class="td11">   <span 
class="ecrm-1000">0.374    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-46-4"  
class="td11">   <span 
class="ecrm-1000">0.303     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-46-5"  
class="td11"> <span 
class="ecrm-1000">0.372  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-46-6"  
class="td11">  <span 
class="ecrm-1000">0.224    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-46-7"  
class="td11">    <span 
class="ecrm-1000">0.364      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-47-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-47-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-47-2"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP B32 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-47-3"  
class="td11">   <span 
class="ecrm-1000">0.415    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-47-4"  
class="td11">   <span 
class="ecrm-1000">0.330     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-47-5"  
class="td11"> <span 
class="ecrm-1000">0.413  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-47-6"  
class="td11">  <span 
class="ecrm-1000">0.218    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-47-7"  
class="td11">    <span 
class="ecrm-1000">0.396      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-48-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-48-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">medium</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-12-48-2"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP L14 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-48-3"  
class="td11">   <span 
class="ecrm-1000">0.405    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-48-4"  
class="td11">   <span 
class="ecrm-1000">0.325     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-48-5"  
class="td11"> <span 
class="ecrm-1000">0.399  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-48-6"  
class="td11">  <span 
class="ecrm-1000">0.206    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-12-48-7"  
class="td11">    <span 
class="ecrm-1000">0.380      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-12-49-"><td  style="white-space:nowrap; text-align:left;" id="TBL-12-49-1"  
class="td11">        </td></tr></table>                                                                                                                 </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h3 class="sectionHead"><span class="titlemark">M   </span> <a 
 id="x1-90000M"></a>Training details</h3>
<!--l. 515--><p class="noindent" >The full set of hyperparameters used for each scale is shown in Table <a 
href="#x1-90001r12">12<!--tex4ht:ref: tab:train-hparams --></a>. For choosing hyperparameters, we
follow the OpenCLIP library&#x00A0;[<a 
href="#Xilharco2021openclip">62</a>], an open source reproduction of OpenAI&#8217;s CLIP. For the <span 
class="ectt-1095">small</span>, <span 
class="ectt-1095">medium</span>,
and <span 
class="ectt-1095">large </span>tracks, these hyperparameters are equal to those in the CLIP paper, except with reduced
batch size so that training runs on reasonable hardware. For the <span 
class="ectt-1095">xlarge </span>track, batch size is
increased from that in OpenAI&#8217;s CLIP to accelerate training by allowing the use of many GPUs
simultaneously with high utilization. For this run we also double the learning rate following prior
work&#x00A0;[<a 
href="#Xcherti2022reproducible">24</a>].
                                                                                         
                                                                                         
<!--l. 520--><p class="noindent" ><a 
 id="x1-90001r12"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-90002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;12: </span><span  
class="content">Experimental configuration for each scale, including the size of the pool we provide, the
model architecture and hyperparameters.</span></div><!--tex4ht:label?: x1-90001rM -->
<!--l. 526--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-13" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-13-1g"><col 
id="TBL-13-1"><col 
id="TBL-13-2"><col 
id="TBL-13-3"><col 
id="TBL-13-4"><col 
id="TBL-13-5"><col 
id="TBL-13-6"><col 
id="TBL-13-7"><col 
id="TBL-13-8"><col 
id="TBL-13-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-13-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-1-1"  
class="td
11"> <span 
class="ecrm-1000">Scale   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-2"  
class="td11">  <span 
class="ecrm-1000">Model    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-3"  
class="td11"> <span 
class="ecrm-1000">Train compute (MACs) </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-4"  
class="td11"> <span 
class="ecrm-1000">Pool size </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-5"  
class="td11"> <span 
class="ecrm-1000"># samples seen </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-6"  
class="td11"> <span 
class="ecrm-1000">Learning rate </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-7"  
class="td11"> <span 
class="ecrm-1000">AdamW </span><span 
class="cmmi-10">&#x03B2;</span><sub><span 
class="cmr-7">2</span></sub>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-8"  
class="td11"> <span 
class="ecrm-1000">Warmup </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-1-9"  
class="td11"> <span 
class="ecrm-1000">Batch size </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-2-1"  
class="td11"> <span 
class="ectt-1000">small  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-2"  
class="td11"> <span 
class="ecrm-1000">ViT-B/32 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-3"  
class="td11">       <span 
class="cmr-10">9</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">16</span></sup>             </td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-4"  
class="td11">  <span 
class="ecrm-1000">12.8M   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-5"  
class="td11">     <span 
class="ecrm-1000">12.8M       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-6"  
class="td11">     <span 
class="ecrm-1000">5e-4        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-7"  
class="td11">    <span 
class="ecrm-1000">0.98      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-8"  
class="td11">   <span 
class="ecrm-1000">500     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-2-9"  
class="td11">   <span 
class="ecrm-1000">4096     </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-3-1"  
class="td11"> <span 
class="ectt-1000">medium </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-2"  
class="td11"> <span 
class="ecrm-1000">ViT-B/32 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-3"  
class="td11">       <span 
class="cmr-10">9</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">5 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">17</span></sup>             </td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-4"  
class="td11">  <span 
class="ecrm-1000">128M    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-5"  
class="td11">     <span 
class="ecrm-1000">128M        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-6"  
class="td11">     <span 
class="ecrm-1000">5e-4        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-7"  
class="td11">    <span 
class="ecrm-1000">0.98      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-8"  
class="td11">   <span 
class="ecrm-1000">500     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-3-9"  
class="td11">   <span 
class="ecrm-1000">4096     </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-4-1"  
class="td11"> <span 
class="ectt-1000">large  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-2"  
class="td11"> <span 
class="ecrm-1000">ViT-B/16 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-3"  
class="td11">       <span 
class="cmr-10">2</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">6 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">19</span></sup>             </td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-4"  
class="td11">  <span 
class="ecrm-1000">1.28B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-5"  
class="td11">     <span 
class="ecrm-1000">1.28B        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-6"  
class="td11">     <span 
class="ecrm-1000">5e-4        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-7"  
class="td11">    <span 
class="ecrm-1000">0.98      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-8"  
class="td11">   <span 
class="ecrm-1000">500     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-4-9"  
class="td11">   <span 
class="ecrm-1000">8192     </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-5-1"  
class="td11"> <span 
class="ectt-1000">xlarge </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-2"  
class="td11"> <span 
class="ecrm-1000">ViT-L/14 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-3"  
class="td11">       <span 
class="cmr-10">1</span><span 
class="cmmi-10">.</span><span 
class="cmr-10">1 </span><span 
class="cmsy-10">&#x00D7; </span><span 
class="cmr-10">10</span><sup><span 
class="cmr-7">21</span></sup>             </td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-4"  
class="td11">  <span 
class="ecrm-1000">12.8B   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-5"  
class="td11">     <span 
class="ecrm-1000">12.8B        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-6"  
class="td11">     <span 
class="ecrm-1000">1e-3        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-7"  
class="td11">    <span 
class="ecrm-1000">0.95      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-8"  
class="td11">   <span 
class="ecrm-1000">10k     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-13-5-9"  
class="td11">   <span 
class="ecrm-1000">90112    </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-6-1"  
class="td11">        </td></tr></table>                                                                                                                  </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h3 class="sectionHead"><span class="titlemark">N   </span> <a 
 id="x1-91000N"></a>Evaluation details</h3>
<!--l. 545--><p class="noindent" >Models are evaluated over a wide range of 38 tasks to measure proficiency in various domains. We include
22 of the 27 classification tasks in the test suite of Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>], excluding the few datasets that
have license restrictions, are in video format, or are no longer available in their original form. We include 6
datasets that were designed to test generalization of models trained on ImageNet. We also include a
majority of the Visual Task Adaptation Benchmark, excluding 3 datasets that are ill-suited for zero-shot
evaluation [<a 
href="#Xvtab">147</a>]. We include 3 datasets from the WILDS benchmark, which tests robustness to distribution
shifts and spurious correlations [<a 
href="#Xwilds2021">76</a>,&#x00A0;<a 
href="#Xsagawa2022extending">120</a>]. Finally, we include 2 additional datasets, Dollar Street and
GeoDE, which test robustness of classification performance across income levels and geographical regions
[<a 
href="#Xrojas2022dollar">115</a>,&#x00A0;<a 
href="#Xramaswamy2022geode">107</a>]. Furthermore, we evaluate zero-shot image and text retrieval on the Flickr30k and
MSCOCO datasets, and image association on the WinoGAViL dataset [<a 
href="#Xflickr30k">142</a>,&#x00A0;<a 
href="#Xmscoco">22</a>,&#x00A0;<a 
href="#Xbitton2022winogavil">13</a>]. The complete
list of evaluation tasks is given in Table&#x00A0;<a 
href="#x1-91001r13">13<!--tex4ht:ref: tab:eval-sets --></a>. We show a sample from each dataset in Figure
<a 
href="#x1-91003r16">16<!--tex4ht:ref: fig:downstream-samples --></a>.
                                                                                         
                                                                                         
<!--l. 550--><p class="noindent" ><a 
 id="x1-91001r13"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-91002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;13: </span><span  
class="content">Evaluation tasks.</span></div><!--tex4ht:label?: x1-91001rN -->
<!--l. 554--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-14" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-14-1g"><col 
id="TBL-14-1"><col 
id="TBL-14-2"><col 
id="TBL-14-3"><col 
id="TBL-14-4"><col 
id="TBL-14-5"><col 
id="TBL-14-6"><col 
id="TBL-14-7"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-14-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-1-1"  
class="td11"> Task type      </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-1-2"  
class="td11"> Dataset                           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-1-3"  
class="td11"> Task                                 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-4"  
class="td11"> Test set size </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-5"  
class="td11"> Number of classes </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-6"  
class="td11">          Main metric </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-1-7"  
class="td11"> Clean </td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-2-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-2-2"  
class="td11"> Caltech-101 [<a 
href="#Xcaltech101">41</a>]                </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-2-3"  
class="td11"> Object recognition              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-4"  
class="td11">       6,085 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-5"  
class="td11">             102 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-6"  
class="td11">        mean per class </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-2-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-3-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-3-2"  
class="td11"> CIFAR-10 [<a 
href="#Xcifar10andcifar100">79</a>]                  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-3-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-4"  
class="td11">      10,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-5"  
class="td11">              10 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-3-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-4-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-4-2"  
class="td11"> CIFAR-100 [<a 
href="#Xcifar10andcifar100">79</a>]                </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-4-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-4"  
class="td11">      10,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-5"  
class="td11">             100 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-4-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-5-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-5-2"  
class="td11"> CLEVR Counts [<a 
href="#Xclevr">68</a>,&#x00A0;<a 
href="#Xvtab">147</a>]   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-5-3"  
class="td11"> Counting                           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-4"  
class="td11">      15,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-5"  
class="td11">               8 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-5-7"  
class="td11">      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-6-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-6-2"  
class="td11"> CLEVR Distance [<a 
href="#Xclevr">68</a>,&#x00A0;<a 
href="#Xvtab">147</a>] </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-6-3"  
class="td11"> Distance prediction             </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-4"  
class="td11">      15,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-5"  
class="td11">               6 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-6-7"  
class="td11">      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-7-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-7-2"  
class="td11"> Country211 [<a 
href="#Xradford2021learning">104</a>,&#x00A0;<a 
href="#Xyfcc100m">131</a>]       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-7-3"  
class="td11"> Geolocation                       </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-4"  
class="td11">      21,100 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-5"  
class="td11">             211 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-7-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-8-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-8-2"  
class="td11"> DTD [<a 
href="#Xdtd">26</a>]                        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-8-3"  
class="td11"> Texture classification           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-8-4"  
class="td11">       1,880 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-8-5"  
class="td11">              47 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-8-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-8-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-9-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-9-2"  
class="td11"> EuroSAT [<a 
href="#Xeurosat">57</a>,&#x00A0;<a 
href="#Xvtab">147</a>]            </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-9-3"  
class="td11"> Satellite imagery recognition </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-9-4"  
class="td11">       5,400 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-9-5"  
class="td11">              10 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-9-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-9-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-10-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-10-2"  
class="td11"> FGVC Aircraft [<a 
href="#Xfgvc_aicraft">88</a>]           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-10-3"  
class="td11"> Aircraft recognition             </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-10-4"  
class="td11">       3,333 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-10-5"  
class="td11">             100 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-10-6"  
class="td11">        mean per class </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-10-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-11-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-11-2"  
class="td11"> Food-101 [<a 
href="#Xfood101">14</a>]                   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-11-3"  
class="td11"> Food recognition                 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-11-4"  
class="td11">      25,250 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-11-5"  
class="td11">             101 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-11-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-11-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-12-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-12-2"  
class="td11"> GTSRB [<a 
href="#Xgtsrb">128</a>]                   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-12-3"  
class="td11"> Traffic sign recognition         </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-12-4"  
class="td11">      12,630 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-12-5"  
class="td11">              43 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-12-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-12-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-13-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-13-2"  
class="td11"> ImageNet 1k [<a 
href="#Xdeng2009imagenet">33</a>]              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-13-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-13-4"  
class="td11">      50,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-13-5"  
class="td11">            1,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-13-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-13-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-14-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-14-2"  
class="td11"> ImageNet Sketch [<a 
href="#Ximagenetsketch">134</a>]       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-14-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-14-4"  
class="td11">      50,889 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-14-5"  
class="td11">            1,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-14-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-14-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-15-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-15-2"  
class="td11"> ImageNet V2 [<a 
href="#Ximagenetv2">114</a>]            </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-15-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-15-4"  
class="td11">      10,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-15-5"  
class="td11">            1,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-15-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-15-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-16-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-16-2"  
class="td11"> ImageNet-A [<a 
href="#Ximageneta_and_imageneto">59</a>]               </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-16-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-16-4"  
class="td11">       7,500 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-16-5"  
class="td11">             200 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-16-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-16-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-17-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-17-2"  
class="td11"> ImageNet-O [<a 
href="#Ximageneta_and_imageneto">59</a>]               </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-17-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-17-4"  
class="td11">       2,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-17-5"  
class="td11">             200 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-17-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-17-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-18-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-18-2"  
class="td11"> ImageNet-R [<a 
href="#Ximagenetr">58</a>]               </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-18-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-18-4"  
class="td11">      30,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-18-5"  
class="td11">             200 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-18-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-18-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-19-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-19-2"  
class="td11"> KITTI distance [<a 
href="#Xkitti">44</a>,&#x00A0;<a 
href="#Xvtab">147</a>]    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-19-3"  
class="td11"> Distance prediction             </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-19-4"  
class="td11">        711 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-19-5"  
class="td11">               4 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-19-6"  
class="td11">             accuracy </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-20-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-20-2"  
class="td11"> MNIST [<a 
href="#Xlecun1998mnist">82</a>]                     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-20-3"  
class="td11"> Digit recognition                 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-20-4"  
class="td11">      10,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-20-5"  
class="td11">              10 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-20-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-20-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-21-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-21-2"  
class="td11"> ObjectNet [<a 
href="#Xobjectnet">9</a>]                   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-21-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-21-4"  
class="td11">      18,574 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-21-5"  
class="td11">             113 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-21-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-21-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-22-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-22-2"  
class="td11"> Oxford Flowers-102 [<a 
href="#Xflowers102">95</a>]     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-22-3"  
class="td11"> Flower recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-22-4"  
class="td11">       6,149 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-22-5"  
class="td11">             102 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-22-6"  
class="td11">        mean per class </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-22-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-23-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-23-2"  
class="td11"> Oxford-IIIT Pet [<a 
href="#Xpets">98</a>,&#x00A0;<a 
href="#Xvtab">147</a>]   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-23-3"  
class="td11"> Pet classification                 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-23-4"  
class="td11">       3,669 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-23-5"  
class="td11">              37 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-23-6"  
class="td11">        mean per class </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-23-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-24-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-24-2"  
class="td11"> Pascal VOC 2007 [<a 
href="#Xpascal-voc-2007">38</a>]        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-24-3"  
class="td11"> Object recognition              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-24-4"  
class="td11">      14,976 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-24-5"  
class="td11">              20 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-24-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-24-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-25-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-25-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-25-2"  
class="td11"> PatchCamelyon [<a 
href="#Xpatchcamelyon">133</a>,&#x00A0;<a 
href="#Xvtab">147</a>]  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-25-3"  
class="td11"> Metastatic tissue cls.           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-25-4"  
class="td11">      32,768 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-25-5"  
class="td11">               2 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-25-6"  
class="td11">             accuracy </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-26-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-26-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-26-2"  
class="td11"> Rendered SST2 [<a 
href="#Xvtab">147</a>]         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-26-3"  
class="td11"> Sentiment classification        </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-26-4"  
class="td11">       1,821 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-26-5"  
class="td11">               2 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-26-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-26-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-27-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-27-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-27-2"  
class="td11"> RESISC45 [<a 
href="#Xresisc45">23</a>,&#x00A0;<a 
href="#Xvtab">147</a>]          </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-27-3"  
class="td11"> Satellite imagery recognition </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-27-4"  
class="td11">       6,300 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-27-5"  
class="td11">              45 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-27-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-27-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-28-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-28-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-28-2"  
class="td11"> Stanford Cars [<a 
href="#Xcars">78</a>]             </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-28-3"  
class="td11"> Vehicle recognition              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-28-4"  
class="td11">       8,041 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-28-5"  
class="td11">             196 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-28-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-28-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-29-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-29-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-29-2"  
class="td11"> STL-10 [<a 
href="#Xstl10">27</a>]                     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-29-3"  
class="td11"> Visual recognition               </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-29-4"  
class="td11">       8,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-29-5"  
class="td11">              10 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-29-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-29-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-30-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-30-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-30-2"  
class="td11"> SUN-397 [<a 
href="#Xsun397">137</a>]                  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-30-3"  
class="td11"> Scene recognition                </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-30-4"  
class="td11">     108,754 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-30-5"  
class="td11">             397 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-30-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-30-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-31-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-31-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-31-2"  
class="td11"> SVHN [<a 
href="#Xsvhn">92</a>,&#x00A0;<a 
href="#Xvtab">147</a>]                </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-31-3"  
class="td11"> Digit recognition                 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-31-4"  
class="td11">      26032 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-31-5"  
class="td11">              10 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-31-6"  
class="td11">             accuracy </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-31-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-32-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-32-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-32-2"  
class="td11"> iWildCam [<a 
href="#Xbeery2020iwildcam">10</a>,&#x00A0;<a 
href="#Xwilds2021">76</a>]            </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-32-3"  
class="td11"> Animal recognition              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-32-4"  
class="td11">      42,791 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-32-5"  
class="td11">             182 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-32-6"  
class="td11">        macro F1 score </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-32-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-33-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-33-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-33-2"  
class="td11"> Camelyon17 [<a 
href="#Xbandi2018detection">8</a>,&#x00A0;<a 
href="#Xwilds2021">76</a>]           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-33-3"  
class="td11"> Metastatic tissue cls.           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-33-4"  
class="td11">      85,054 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-33-5"  
class="td11">               2 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-33-6"  
class="td11">             accuracy </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-34-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-34-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-34-2"  
class="td11"> FMoW [<a 
href="#Xchristie2018functional">25</a>,&#x00A0;<a 
href="#Xwilds2021">76</a>]                </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-34-3"  
class="td11"> Satellite imagery recognition </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-34-4"  
class="td11">      22,108 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-34-5"  
class="td11">              62 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-34-6"  
class="td11">       worst-region acc. </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-34-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-35-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-35-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-35-2"  
class="td11"> Dollar Street [<a 
href="#Xrojas2022dollar">115</a>]             </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-35-3"  
class="td11"> Object recognition              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-35-4"  
class="td11">       3,503 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-35-5"  
class="td11">              58 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-35-6"  
class="td11"> worst-income top-5 acc. </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-35-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-36-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-36-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
Classification</div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-36-2"  
class="td11"> GeoDE [<a 
href="#Xramaswamy2022geode">107</a>]                    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-36-3"  
class="td11"> Object recognition              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-36-4"  
class="td11">      12,488 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-36-5"  
class="td11">              40 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-36-6"  
class="td11">       worst-region acc. </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-36-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-37-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-37-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-37-2"  
class="td11"> Flickr30k [<a 
href="#Xflickr30k">142</a>]                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-37-3"  
class="td11"> Image and text retrieval       </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-37-4"  
class="td11">      31,014 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-37-5"  
class="td11">            N/A </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-37-6"  
class="td11">                 R@1 </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-37-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-38-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-38-1"  
class="td11">              </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-38-2"  
class="td11"> MSCOCO [<a 
href="#Xmscoco">22</a>]                  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-38-3"  
class="td11"> Image and text retrieval       </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-38-4"  
class="td11">       5,000 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-38-5"  
class="td11">            N/A </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-38-6"  
class="td11">                 R@1 </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-38-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-39-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-39-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
Retrieval</div>       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-39-2"  
class="td11"> WinoGAViL [<a 
href="#Xbitton2022winogavil">13</a>]               </td><td  style="white-space:nowrap; text-align:left;" id="TBL-14-39-3"  
class="td11"> Commonsense association     </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-39-4"  
class="td11">       3,563 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-39-5"  
class="td11">            N/A </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-39-6"  
class="td11">         Jaccard score </td><td  style="white-space:nowrap; text-align:center;" id="TBL-14-39-7"  
class="td11">  <span 
class="msam-10x-x-109">&#x2713;</span>  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-40-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-40-1"  
class="td11">             </td></tr></table>                                                                                                                      </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 605--><p class="noindent" ><a 
 id="x1-91003r16"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 606--><p class="noindent" > <img 
src="figures/downstream_samples-.png" alt="PIC"  
width="328" height="328" >
<a 
 id="x1-91004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;16: </span><span  
class="content">Randomly sampled images from the evaluation datasets we consider.</span></div><!--tex4ht:label?: x1-91003rN -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 614--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-92000N"></a><span 
class="ecbx-1095">Prompt choice.</span></span>
Since we perform zero-shot evaluation, prompt and class name selection is important, and can have a
significant impact on the results. To avoid heavy prompt engineering and overtuning to individual models,
we opt to use the prompt templates used in Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>] whenever possible. Most datasets come
with pre-defined class names, but some are overwritten with more descriptive labels, again based on
previous literature. For datasets with no precedent in zero-shot evaluation, we reuse prompt templates
from other datasets with a similar domain and task (e.g., SVHN is evaluated with MNIST prompts and
class names).
<!--l. 616--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-93000N"></a><span 
class="ecbx-1095">Evaluation metrics.</span></span>
For the majority of classification tasks, the primary evaluation metric is accuracy. For certain datasets
with class imbalances, we instead compute mean per-class accuracy, as done in Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>]. On
the WILDS benchmark datasets, we use the primary metric specified for each dataset on their leaderboard.
Dollar Street and GeoDE test model generalization across socioeconomic and geographic diversity. Thus,
for Dollar Street, we compute worst-group top-5 accuracy, with groups defined by income
level, emulating Rojas et&#x00A0;al.&#x00A0;[<a 
href="#Xrojas2022dollar">115</a>]; for GeoDE, we compute worst-group accuracy, with groups
defined by region (Africa, Americas, West Asia, East Asia, Southeast Asia, and Europe), as
defined in Ramaswamy et&#x00A0;al.&#x00A0;[<a 
href="#Xramaswamy2022geode">107</a>]. For the image-text retrieval tasks, Flickr and MSCOCO, we
compute both image and text recall (fraction of text captions for which the correct image was
selected and vice versa), and plot their arithmetic mean. On WinoGAViL, we compute the
Jaccard score (intersection-over-union) for each example, and show results for the harder samples
(10 and 12 candidates). More information on WinoGAViL evaluation can be found in Bitton
et&#x00A0;al.&#x00A0;[<a 
href="#Xbitton2022winogavil">13</a>].
<!--l. 618--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-94000N"></a><span 
class="ecbx-1095">Clean subset.</span></span>
For five of our evaluation tasks (the two CLEVR tasks, the two Camelyon tasks, and KITTI) the zero-shot
performance of all evaluated models appears to be close to that of random guessing, and lack correlation
to the type of filtering method used (see <a 
href="#x1-110013r27">Figure&#x00A0;27</a>). Consequently, we studied performance
averaged only on the remaining 33 tasks, but found not substantial qualitative differences in our
results. As a result, we opted to report the average on the full evaluation suite throughout our
study.
                                                                                         
                                                                                         
<!--l. 621--><p class="noindent" ><a 
 id="x1-94001r17"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 622--><p class="noindent" > <img 
src="figures/linear_probes-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-94002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;17: </span><span  
class="content">Zero-shot ImageNet and Linear probe ImageNet performance for models from Tables
<a 
href="#x1-28001r3">3<!--tex4ht:ref: tab:main --></a>  and  <a 
href="#x1-32001r4">4<!--tex4ht:ref: tab:byod --></a>.  Relative  ordering  of  models  demonstrates  high  rank  correlations  of  0.99  and  1.0  for
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>and <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>respectively.</span></div><!--tex4ht:label?: x1-94001rN -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 627--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-95000N"></a><span 
class="ecbx-1095">Zero-shot vs. fine-tuning protocols.</span></span>
One critical decision in <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>is how exactly to evaluate models and whether or not to fine-tune
models on evaluation tasks (i.e., supervised fine-tuning directly on task training sets). We opt for zero-shot
evaluation, where a models are applied to downstream tasks directly to 1) ease computational burden on
participants and 2) measure the out-of-the-box generalization capabilities of our models. To validate this
design decision, we conduct linear probes on all models presented in Tables <a 
href="#x1-28001r3">3<!--tex4ht:ref: tab:main --></a> and <a 
href="#x1-32001r4">4<!--tex4ht:ref: tab:byod --></a> on ImageNet. We
follow a standard probing protocol and fine-tune the last linear layer from zero-shot initialization for 40
epochs with learning rate 1e-3, batch size 256, AdamW optimizer with default settings with the exception
of weight decay (that we set to zero), and a cosine annealing schedule. As seen in Figure <a 
href="#x1-94001r17">17<!--tex4ht:ref: fig:linear-probes --></a>,
zero-shot and linear probe performance follow similar trends for both filtering and <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>
tracks. Moreover the Spearman rank correlation between the two protocols over the models
considered is 0.99 for the filtering track and 1.0 for <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span>. This suggests that better zero-shot
models on ImageNet are correlated with better representations of linear probe fine-tuning on
ImageNet.
<!--l. 630--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">O   </span> <a 
 id="x1-96000O"></a>Baseline details</h3>
<!--l. 632--><p class="noindent" >Here we provide additional details on the creation of our baseline subsets. To highlight the qualitative
differences between the filtering strategies we also provide visualization for <span 
class="ecti-1095">No filtering </span>(Figure <a 
href="#x1-96001r18">18<!--tex4ht:ref: fig:no_filter --></a>),
<span 
class="ecti-1095">Basic filtering </span>(Figure <a 
href="#x1-96003r19">19<!--tex4ht:ref: fig:basic_filter --></a>), and <span 
class="ecti-1095">CLIP score (L/14 30%) </span>(Figure <a 
href="#x1-96005r20">20<!--tex4ht:ref: fig:clip_filter --></a>), which can all be found in
Table&#x00A0;<a 
href="#x1-28001r3">3<!--tex4ht:ref: tab:main --></a>. Notice that No filtering gives relatively noisy data (e.g., matching a bicycle with
a caption: &#8220;IMG_2187.jpg&#8221;), while CLIP score samples give qualitatively more descriptive
cations.
                                                                                         
                                                                                         
<!--l. 636--><p class="noindent" ><a 
 id="x1-96001r18"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 637--><p class="noindent" > <img 
src="figures/appx-no_filter-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-96002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;18: </span><span  
class="content">An i.i.d. sample from <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>generated after applying the <span 
class="ecti-1095">No filter</span>
strategy. Hence, these samples represent random images from <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</span></div><!--tex4ht:label?: x1-96001rO -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 644--><p class="noindent" ><a 
 id="x1-96003r19"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 645--><p class="noindent" > <img 
src="figures/appx-basic-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-96004"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;19: </span><span  
class="content">An i.i.d. sample from <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>generated after applying the <span 
class="ecti-1095">Basic filter</span>
strategy.</span></div><!--tex4ht:label?: x1-96003rO -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 651--><p class="noindent" ><a 
 id="x1-96005r20"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 652--><p class="noindent" > <img 
src="figures/appx-clip_filter-.png" alt="PIC"  
width="422" height="422" >
<a 
 id="x1-96006"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;20: </span><span  
class="content">An i.i.d. sample from <span 
class="ectt-1000">small </span><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>generated after applying the CLIP score
(L/14 30%)</span></div><!--tex4ht:label?: x1-96005rO -->
<!--l. 653--><p class="noindent" >strategy.
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h4 class="subsectionHead"><span class="titlemark">O.1   </span> <a 
 id="x1-97000O.1"></a>Filtering track</h4>
<!--l. 662--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-98000O.1"></a><span 
class="ecbx-1095">Basic filtering.</span></span>
For language detection, we use Fasttext 0.92, version lid.176, and cld3 - library gcld3 3.0.13. We count the
number of words in each caption by splitting using whitespaces.
<!--l. 668--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-99000O.1"></a><span 
class="ecbx-1095">CLIP thresholds.</span></span>
We use OpenAI pretrained CLIP ViT-B/32 and ViT-L/14 models&#x00A0;[<a 
href="#Xradford2021learning">104</a>] to compute the cosine similarity
text and image tower outputs as the CLIP scores. On the <span 
class="ectt-1000">small </span>and <span 
class="ectt-1000">medium </span>pools, we also
experiment with baselines that filter out samples in the top few percentiles of CLIP scores.
Specifically, we try baselines that use samples with top {1,2,5}-30% CLIP scores (ViT-B/32
model), and the performance is sightly better on the <span 
class="ectt-1000">small </span>pool (at most 0.5 gain of averaged
accuracy) while slightly worse on the <span 
class="ectt-1000">medium </span>pool (0.4-0.8 loss of averaged accuracy). In Table
<a 
href="#x1-99001r14">14<!--tex4ht:ref: tab:filtering_thresholds --></a>, we show how the CLIP score thresholds relate to the fraction of the pool retained by the
filter.
<div class="table">
                                                                                         
                                                                                         
<!--l. 672--><p class="noindent" ><a 
 id="x1-99001r14"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-99002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;14: </span><span  
class="content">CLIP threshold filtering configurations. &#8220;Fraction&#8221; denotes the size of the filtered subset
relative to the pool.</span></div><!--tex4ht:label?: x1-99001rO -->
<div class="tabular"> <table id="TBL-15" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-15-1g"><col 
id="TBL-15-1"><col 
id="TBL-15-2"><col 
id="TBL-15-3"><col 
id="TBL-15-4"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-15-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-1-1"  
class="td11"> <span 
class="ecrm-0900">CLIP model </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-1-2"  
class="td11"> <span 
class="ecrm-0900">En. filtering </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-1-3"  
class="td11"> <span 
class="ecrm-0900">Threshold </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-1-4"  
class="td11"> <span 
class="ecrm-0900">Fraction </span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-2-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-2-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-2-3"  
class="td11">  <span 
class="ecrm-0900">0.384    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-2-4"  
class="td11">   <span 
class="ecrm-0900">1%    </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-3-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-3-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-3-3"  
class="td11">  <span 
class="ecrm-0900">0.358    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-3-4"  
class="td11">   <span 
class="ecrm-0900">3%    </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-4-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-4-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2713;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-4-3"  
class="td11">  <span 
class="ecrm-0900">0.300    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-4-4"  
class="td11"> <span 
class="ecrm-0900">10.2%  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-5-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-5-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-5-3"  
class="td11">  <span 
class="ecrm-0900">0.325    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-5-4"  
class="td11">  <span 
class="ecrm-0900">10%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-6-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-6-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2713;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-6-3"  
class="td11">   <span 
class="ecrm-0900">0.28     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-6-4"  
class="td11">  <span 
class="ecrm-0900">7.4%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-7-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-7-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-7-3"  
class="td11">  <span 
class="ecrm-0900">0.300    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-7-4"  
class="td11">  <span 
class="ecrm-0900">20%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-8-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-8-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-8-3"  
class="td11">  <span 
class="ecrm-0900">0.281    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-8-4"  
class="td11">  <span 
class="ecrm-0900">30%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-9-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-9-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-9-3"  
class="td11">  <span 
class="ecrm-0900">0.263    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-9-4"  
class="td11">  <span 
class="ecrm-0900">40%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-10-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-10-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-10-3"  
class="td11">  <span 
class="ecrm-0900">0.247    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-10-4"  
class="td11">  <span 
class="ecrm-0900">50%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-11-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-11-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-11-3"  
class="td11">  <span 
class="ecrm-0900">0.215    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-11-4"  
class="td11">  <span 
class="ecrm-0900">75%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-12-1"  
class="td11"> <span 
class="ecrm-0900">ViT-B/32     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-12-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-12-3"  
class="td11">  <span 
class="ecrm-0900">0.193    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-12-4"  
class="td11">  <span 
class="ecrm-0900">90%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-13-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-13-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-13-3"  
class="td11">  <span 
class="ecrm-0900">0.364    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-13-4"  
class="td11">   <span 
class="ecrm-0900">1%    </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-14-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-14-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-14-3"  
class="td11">  <span 
class="ecrm-0900">0.334    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-14-4"  
class="td11">   <span 
class="ecrm-0900">3%    </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-15-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-15-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2713;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-15-3"  
class="td11">  <span 
class="ecrm-0900">0.300    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-15-4"  
class="td11">  <span 
class="ecrm-0900">5.4%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-16-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-16-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-16-3"  
class="td11">  <span 
class="ecrm-0900">0.295    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-16-4"  
class="td11">  <span 
class="ecrm-0900">10%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-17-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-17-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2713;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-17-3"  
class="td11">  <span 
class="ecrm-0900">0.280    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-17-4"  
class="td11">  <span 
class="ecrm-0900">3.3%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-18-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-18-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-18-3"  
class="td11">  <span 
class="ecrm-0900">0.266    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-18-4"  
class="td11">  <span 
class="ecrm-0900">20%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-19-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-19-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-19-3"  
class="td11">  <span 
class="ecrm-0900">0.243    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-19-4"  
class="td11">  <span 
class="ecrm-0900">30%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-20-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-20-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-20-3"  
class="td11">  <span 
class="ecrm-0900">0.222    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-20-4"  
class="td11">  <span 
class="ecrm-0900">40%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-21-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-21-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-21-3"  
class="td11">  <span 
class="ecrm-0900">0.203    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-21-4"  
class="td11">  <span 
class="ecrm-0900">50%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-22-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-22-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-22-3"  
class="td11">  <span 
class="ecrm-0900">0.160    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-22-4"  
class="td11">  <span 
class="ecrm-0900">75%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-23-1"  
class="td11"> <span 
class="ecrm-0900">ViT-L/14     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-23-2"  
class="td11">     <span 
class="pzdr-x-x-90">&#x2717;         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-23-3"  
class="td11">  <span 
class="ecrm-0900">0.129    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-15-23-4"  
class="td11">  <span 
class="ecrm-0900">90%   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-24-1"  
class="td11">            </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
</div>
<!--l. 712--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-100000O.1"></a><span 
class="ecbx-1095">Text-based filtering.</span></span>
Each synset is represented by a synset offset that can be used to retrieve the synset from
WordNet. In order to verify if a caption has a word corresponding to a synset from our set
we iterate over every word and retrieve the synsets that this word can describe (using
nltk.corpus WordNet). Following that, we retrieve the most likely lemma representing
that synset, find its synset offset, and check if the number is part of the IN21K or IN1K
sets.<span class="footnote-mark"><a 
href="main12.html#fn11x0"><sup class="textsuperscript">11</sup></a></span><a 
 id="x1-100001f11"></a> 
<!--l. 715--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-101000O.1"></a><span 
class="ecbx-1095">Text-based sampling.</span></span>
This baseline uses text only to filter labels which mention concepts (synsets) appearing in IN21K, and
applies a temperature parameter to control how equally-represented different concepts are in the dataset.
For synset <span 
class="cmmi-10x-x-109">j</span>, let <span 
class="cmmi-10x-x-109">N</span><sub><span 
class="cmmi-8">j</span></sub> be the number of examples containing words matched to that synset, where as before
for each word we only match the most likely synset. Furthermore, for image-text pair <span 
class="cmmi-10x-x-109">i </span>let <span 
class="cmmi-10x-x-109">T</span><sub><span 
class="cmmi-8">i</span></sub> be the set of
synset matched to the caption.
<!--l. 719--><p class="noindent" >The probability of sampling example <span 
class="cmmi-10x-x-109">i </span>is proportional to either <img 
src="main7x.png" alt="-1-
|Ti|"  class="frac" align="middle"><span 
class="cmex-10x-x-109">&#x2211;</span>
    <sub><span 
class="cmmi-8">j</span><span 
class="cmsy-8">&#x2208;</span><span 
class="cmmi-8">T</span><sub><span 
class="cmmi-6">i</span></sub></sub><span 
class="cmmi-10x-x-109">N</span><sub><span 
class="cmmi-8">j</span></sub><sup><span 
class="cmmi-8">&#x03B1;</span><span 
class="cmsy-8">-</span><span 
class="cmr-8">1</span></sup> (average synset score in
the data point) or <span 
class="cmr-10x-x-109">max</span><sub><span 
class="cmmi-8">j</span><span 
class="cmsy-8">&#x2208;</span><span 
class="cmmi-8">T</span><sub><span 
class="cmmi-6">i</span></sub></sub><span 
class="cmmi-10x-x-109">N</span><sub><span 
class="cmmi-8">j</span></sub><sup><span 
class="cmmi-8">&#x03B1;</span><span 
class="cmsy-8">-</span><span 
class="cmr-8">1</span></sup> (maximum synset score in the data point), where <span 
class="cmmi-10x-x-109">&#x03B1; </span>is a &#8220;temperature&#8221;
parameter controlling the flatness of the distribution. We sample examples with replacement but discard
any example repeated more than 100 times.
<!--l. 728--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-102000O.1"></a><span 
class="ecbx-1095">Image-based filtering.</span></span>
We now provide a detailed description of the Image-based filtering procedure. First, since the core of the
procedure concerns only image content, we begin with basic text-bsaed filtering: we remove from the pool
only all examples with non-English captions (as determined by fasttext), and all examples whose captions
have less than two words or less than six characters.
<!--l. 731--><p class="noindent" >Next, we use clustering of image embeddings to select a subset of examples whose image content is related
to a clean training set of interest. Let <span 
class="cmmi-10x-x-109">e</span><sub><span 
class="cmr-8">1</span></sub><span 
class="cmmi-10x-x-109">,</span><span 
class="cmmi-10x-x-109">&#x2026;</span><span 
class="cmmi-10x-x-109">,e</span><sub><span 
class="cmmi-8">M</span></sub> denote the CLIP image embeddings of the
remaining examples in the pool. We cluster these embeddings into <span 
class="cmmi-10x-x-109">K </span><span 
class="cmr-10x-x-109">= 10</span><sup><span 
class="cmr-8">5</span></sup> clusters using
Faiss with 20 iterations, and let <span 
class="cmmi-10x-x-109">c</span><sub><span 
class="cmr-8">1</span></sub><span 
class="cmmi-10x-x-109">,</span><span 
class="cmmi-10x-x-109">&#x2026;</span><span 
class="cmmi-10x-x-109">,c</span><sub><span 
class="cmmi-8">K</span></sub> denote the resulting cluster centers. Due to memory
constraints, for the <span 
class="ectt-1095">large </span>and <span 
class="ectt-1095">xlarge </span>pools, we perform the clustering on a random subset of
about 160M examples (that pass the basic text-based filtering). For an embedding vector <span 
class="cmmi-10x-x-109">v</span>,
let
<table 
class="equation-star"><tr><td>
                                                                                         
                                                                                         
                                 <span 
class="cmmi-10x-x-109">I</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">v</span><span 
class="cmr-10x-x-109">) =</span> <span 
class="cmr-10x-x-109">arg</span> <span 
class="cmr-10x-x-109">max</span><sub><span 
class="cmmi-8">i</span><span 
class="cmsy-8">&#x2264;</span><span 
class="cmmi-8">K</span></sub><span 
class="cmsy-10x-x-109">&#x27E8;</span><span 
class="cmmi-10x-x-109">v,c</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmsy-10x-x-109">&#x27E9;</span>
</td></tr></table>
<!--l. 737--><p class="nopar" >
denote the index of the cluster center nearest to <span 
class="cmmi-10x-x-109">v </span>as measured by inner product. Let <span 
class="cmmi-10x-x-109">f</span><sub><span 
class="cmr-8">1</span></sub><span 
class="cmmi-10x-x-109">,</span><span 
class="cmmi-10x-x-109">&#x2026;</span><span 
class="cmmi-10x-x-109">,f</span><sub><span 
class="cmmi-8">N</span></sub> denote the
CLIP image embeddings of a clean supervised training set (we experiment with either ImageNet 1K or
ImageNet 21K), and let
<table 
class="equation-star"><tr><td>
                                  <span 
class="cmsy-10x-x-109"><img 
src="cmsy10-53.png" alt="S" class="10-109x-x-53" /> </span><span 
class="cmr-10x-x-109">= </span><span 
class="cmsy-10x-x-109">{</span><span 
class="cmmi-10x-x-109">I</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">f</span><sub><span 
class="cmmi-8">i</span></sub><span 
class="cmr-10x-x-109">)</span><span 
class="cmsy-10x-x-109">&#x2223;</span><span 
class="cmr-10x-x-109">1 </span><span 
class="cmsy-10x-x-109">&#x2264;</span><span 
class="cmmi-10x-x-109">i </span><span 
class="cmsy-10x-x-109">&#x2264;</span><span 
class="cmmi-10x-x-109">N</span><span 
class="cmsy-10x-x-109">}</span>
</td></tr></table>
<!--l. 742--><p class="nopar" >
be the set of cluster indices who are nearest neighbors to some clean training set image. We then keep only
images in the pool whose nearest cluster center is in <span 
class="cmsy-10x-x-109"><img 
src="cmsy10-53.png" alt="S" class="10-109x-x-53" /></span>. That is, out of the <span 
class="cmmi-10x-x-109">M </span>examples passing the
text-based filtering, the output subset keeps the examples with indices
<table 
class="equation-star"><tr><td>
                                  <span 
class="cmsy-10x-x-109">{</span><span 
class="cmr-10x-x-109">1 </span><span 
class="cmsy-10x-x-109">&#x2264;</span><span 
class="cmmi-10x-x-109">j </span><span 
class="cmsy-10x-x-109">&#x2264;</span><span 
class="cmmi-10x-x-109">M</span><span 
class="cmsy-10x-x-109">&#x2223;</span><span 
class="cmmi-10x-x-109">I</span><span 
class="cmr-10x-x-109">(</span><span 
class="cmmi-10x-x-109">e</span><sub><span 
class="cmmi-8">j</span></sub><span 
class="cmr-10x-x-109">) </span><span 
class="cmsy-10x-x-109">&#x2208;<img 
src="cmsy10-53.png" alt="S" class="10-109x-x-53" />}</span><span 
class="cmmi-10x-x-109">.</span>
</td></tr></table>
                                                                                         
                                                                                         
<!--l. 746--><p class="nopar" >
<!--l. 749--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-103000O.1"></a><span 
class="ecbx-1095">Image-based sampling.</span></span>
In addition to filtering methods, we experiment with cluster-based sampling methods. First, we compute
the score of <span 
class="cmmi-10x-x-109">i</span>-th cluster <span 
class="cmmi-10x-x-109">s</span><sub><span 
class="cmmi-8">i</span></sub> as the number of ImageNet data assigned to this cluster. Then, for parameter
<span 
class="cmmi-10x-x-109">&#x03B1; &#x003E; </span><span 
class="cmr-10x-x-109">0 </span>we define a distribution over the pool by sampling cluster <span 
class="cmmi-10x-x-109">i </span>with probability <img 
src="main8x.png" alt="&#x2211;s&#x03B1;i&#x03B1;-
  jsj"  class="frac" align="middle"> and uniformly
sampling an example for the cluster, rejecting any example repeated more than 100 times. We
try 5 different <span 
class="cmmi-10x-x-109">&#x03B1;</span>, i.e., <span 
class="cmsy-10x-x-109">{</span><span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">,</span><span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">2</span><span 
class="cmmi-10x-x-109">,</span><span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">5</span><span 
class="cmmi-10x-x-109">,</span><span 
class="cmr-10x-x-109">1</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">0</span><span 
class="cmmi-10x-x-109">,</span><span 
class="cmr-10x-x-109">2</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">0</span><span 
class="cmsy-10x-x-109">}</span>, and the best average accuracy is obtained when
<span 
class="cmmi-10x-x-109">&#x03B1; </span><span 
class="cmr-10x-x-109">= 0</span><span 
class="cmmi-10x-x-109">.</span><span 
class="cmr-10x-x-109">2</span>, while the performance is still worse than the image-based filtering on the <span 
class="ectt-1095">small </span>and
<span 
class="ectt-1095">medium </span>pool. We therefore do not include this line of baselines in the experiments of <span 
class="ectt-1095">large</span>
pool.
<!--l. 753--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-104000O.1"></a><span 
class="ecbx-1095">ImageNet distance filtering.</span></span>
We rank the samples in the pool by the minimum embedding distance (1 minus cosine similarity) between
its image and the ImageNet images; both embeddings are obtained from OpenAI pretrained CLIP
ViT-L/14 model&#x00A0;[<a 
href="#Xradford2021learning">104</a>]. Then we select top images by different fractions as in image-based filtering
methods.
<!--l. 756--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">O.2   </span> <a 
 id="x1-105000O.2"></a><span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track</h4>
<!--l. 759--><p class="noindent" >We experiment with the following data sources:
 <ul class="itemize1">
 <li class="itemize">CC12M [<a 
href="#Xchangpinyo2021conceptual">20</a>]: images and HTML alt-text crawled and filtered from web pages.
 </li>
 <li class="itemize">YFCC15M: this is the 15M subset of the YFCC100M dataset [<a 
href="#Xyfcc100m">131</a>] that Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>] used
 for dataset ablation in their CLIP paper.
 </li>
 <li class="itemize">RedCaps [<a 
href="#Xdesai2021redcaps">34</a>]: 12M images and corresponding captions were crawled from 350 manually curated
 subreddits between 2008 and 2020.
 </li>
 <li class="itemize">Shutterstock: 106M images and captions were obtained from the Shutterstock website in 2021 [<a 
href="#Xnguyen2022quality">94</a>].
 We use the &#8220;photos&#8221; subset of this dataset, with 58M samples, which we found performed best,
 unless specified otherwise.
 </li>
 <li class="itemize">WIT [<a 
href="#Xsrinivasan2021wit">127</a>]: Image-text pairs from Wikipedia pages. We use the attribution fields as captions, which
 we found performed best.
                                                                                         
                                                                                         
 </li>
 <li class="itemize">COYO [<a 
href="#Xcoyo700m">16</a>]: A collection of 700M image-text pairs from Common Crawl.
 </li>
 <li class="itemize">LAION-2B [<a 
href="#Xlaion5b">122</a>]: A 2.32 billion english subset of LAION-5B.
 </li>
 <li class="itemize">LAION-COCO: A dataset with 600M images from LAION-5B and synthetic captions.<span class="footnote-mark"><a 
href="main13.html#fn12x0"><sup class="textsuperscript">12</sup></a></span><a 
 id="x1-105001f12"></a> 
 </li>
 <li class="itemize">LAION-A: According to <a 
href="https://laion.ai/" >laion.ai</a>, LAION-A is a 900M subset of LAION-2B [<a 
href="#Xlaion5b">122</a>] with the aesthetic
 filtering procedure used in LAION-aesthetic<span class="footnote-mark"><a 
href="main14.html#fn13x0"><sup class="textsuperscript">13</sup></a></span><a 
 id="x1-105002f13"></a> 
 and pHash deduplication [<a 
href="#Xidealods2019imagededup">64</a>].</li></ul>
                                                                                         
                                                                                         
<!--l. 775--><p class="noindent" ><a 
 id="x1-105003r15"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-105004"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;15: </span><span  
class="content">Measuring the quality of external data sources</span></div><!--tex4ht:label?: x1-105003rO -->
<!--l. 781--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-16" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-16-1g"><col 
id="TBL-16-1"><col 
id="TBL-16-2"><col 
id="TBL-16-3"><col 
id="TBL-16-4"><col 
id="TBL-16-5"><col 
id="TBL-16-6"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-16-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Dataset</span></div>       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-1-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Dataset size</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-1-3"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet acc.</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-1-4"  
class="td11">     <span 
class="ecrm-1000">Avg. accuracy        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Avg. cos. sim. (B/32)</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Avg. cos. sim. (L/14)</span></div> </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-16-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-2-1"  
class="td11">            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-2-2"  
class="td11">            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-2-3"  
class="td11">             </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-2-4"  
class="td11"> <span 
class="ecrm-1000">ImageNet and OOD sets </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-2-5"  
class="td11">                   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-2-6"  
class="td11">                   </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-16-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-3-1"  
class="td11"> <span 
class="ecrm-1000">CC12M        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-3-2"  
class="td11">    <span 
class="ecrm-1000">10M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-3-3"  
class="td11">     <span 
class="ecrm-1000">27.8        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-3-4"  
class="td11">         <span 
class="ecrm-1000">34.0               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-3-5"  
class="td11">       <span 
class="ecrm-1000">0.306            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-3-6"  
class="td11">       <span 
class="ecrm-1000">0.268            </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-16-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-4-1"  
class="td11"> <span 
class="ecrm-1000">YFCC15M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-16-4-2"  
class="td11"> <span 
class="ecrm-1000">15M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-16-4-3"  
class="td11"> <span 
class="ecrm-1000">22.6 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-16-4-4"  
class="td11"> <span 
class="ecrm-1000">24.6 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-16-4-5"  
class="td11"> <span 
class="ecrm-1000">0.262 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-16-4-6"  
class="td11"> <span 
class="ecrm-1000">0.198</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-16-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-5-1"  
class="td11"> <span 
class="ecrm-1000">RedCaps      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-5-2"  
class="td11">    <span 
class="ecrm-1000">11M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-5-3"  
class="td11">     <span 
class="ecrm-1000">26.8        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-5-4"  
class="td11">         <span 
class="ecrm-1000">31.5               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-5-5"  
class="td11">       <span 
class="ecrm-1000">0.281            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-5-6"  
class="td11">       <span 
class="ecrm-1000">0.240            </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-16-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-6-1"  
class="td11"> <span 
class="ecrm-1000">Shutterstock </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-6-2"  
class="td11">    <span 
class="ecrm-1000">15M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-6-3"  
class="td11">     <span 
class="ecrm-1000">21.0        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-6-4"  
class="td11">         <span 
class="ecrm-1000">28.3               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-6-5"  
class="td11">       <span 
class="ecrm-1000">0.314            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-16-6-6"  
class="td11">       <span 
class="ecrm-1000">0.273            </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-16-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-7-1"  
class="td11"> </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 798--><p class="noindent" >In Table <a 
href="#x1-105003r15">15<!--tex4ht:ref: tab:app_byod_quality --></a>, we use some heuristics to measure the quality of the external data sources. First, following
Nguyen et&#x00A0;al.&#x00A0;[<a 
href="#Xnguyen2022quality">94</a>], we train a CLIP model on a 5M random subset from each source, and evaluate the
performance of the resulting models on ImageNet and ImageNet-derived distributions &#8212; ImageNet-V2
[<a 
href="#Ximagenetv2">114</a>], ImageNet-R [<a 
href="#Ximagenetr">58</a>], ImageNet-Sketch [<a 
href="#Ximagenetsketch">134</a>] and ObjectNet [<a 
href="#Xobjectnet">9</a>]. Moreover, for each data source, we use
OpenAI&#8217;s pretrained CLIP ViT-B/32 and ViT-L/14 models to compute the cosine similarity between
image and text embeddings of a data point, and obtain the average cosine similarity score for the whole
dataset.
                                                                                         
                                                                                         
<!--l. 801--><p class="noindent" ><a 
 id="x1-105005r16"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-105006"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;16: </span><span  
class="content">Zero-shot performance for select baselines in the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track. Unless specified otherwise,
<span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>means our pool filtered with CLIP score (L/14, 30%). </span></div><!--tex4ht:label?: x1-105005rO -->
<!--l. 808--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-17" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-17-1g"><col 
id="TBL-17-1"><col 
id="TBL-17-2"><col 
id="TBL-17-3"><col 
id="TBL-17-4"><col 
id="TBL-17-5"><col 
id="TBL-17-6"><col 
id="TBL-17-7"><col 
id="TBL-17-8"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-17-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Scale</span></div>    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-1-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Data source</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-1-3"  
class="td11"> <span 
class="ecrm-1000">Training                                                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-1-4"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-1-5"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-1-7"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-1-8"  
class="td11"> <span 
class="ecrm-1000">Average over </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-2-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-2-2"  
class="td11">           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-2-3"  
class="td11"> <span 
class="ecrm-1000">dataset size                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-2-4"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-2-5"  
class="td11"> <span 
class="ecrm-1000">dist. shifts </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-2-6"  
class="td11">       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-2-7"  
class="td11">         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-2-8"  
class="td11"> <span 
class="ecrm-1000">38 datasets  </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-17-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-3-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:center;" id="TBL-17-3-2"  
class="td11"> <span 
class="ecrm-1000">#0 </span></td> <td  style="white-space:nowrap; text-align:left;" id="TBL-17-3-3"  
class="td11"> <span 
class="ecrm-1000">CC12M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-17-3-4"  
class="td11"> <span 
class="ecrm-1000">0.099 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-17-3-5"  
class="td11"> <span 
class="ecrm-1000">0.080 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-17-3-6"  
class="td11"> <span 
class="ecrm-1000">0.223 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-17-3-7"  
class="td11"> <span 
class="ecrm-1000">0.160 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-17-3-8"  
class="td11"> <span 
class="ecrm-1000">0.202</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-4-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-4-2"  
class="td11">    <span 
class="ecrm-1000">#1       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-4-3"  
class="td11"> <span 
class="ecrm-1000">LAION15M                                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-4-4"  
class="td11">   <span 
class="ecrm-1000">0.083    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-4-5"  
class="td11">   <span 
class="ecrm-1000">0.076     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-4-6"  
class="td11"> <span 
class="ecrm-1000">0.210  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-4-7"  
class="td11">  <span 
class="ecrm-1000">0.119    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-4-8"  
class="td11">    <span 
class="ecrm-1000">0.187      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-5-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-5-2"  
class="td11">    <span 
class="ecrm-1000">#2       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-5-3"  
class="td11"> <span 
class="ecrm-1000">RedCaps                                                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-5-4"  
class="td11">   <span 
class="ecrm-1000">0.076    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-5-5"  
class="td11">   <span 
class="ecrm-1000">0.066     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-5-6"  
class="td11"> <span 
class="ecrm-1000">0.177  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-5-7"  
class="td11">  <span 
class="ecrm-1000">0.127    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-5-8"  
class="td11">    <span 
class="ecrm-1000">0.167      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-6-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-6-2"  
class="td11">    <span 
class="ecrm-1000">#3       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-6-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock 15M                                              </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-6-4"  
class="td11">   <span 
class="ecrm-1000">0.083    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-6-5"  
class="td11">   <span 
class="ecrm-1000">0.070     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-6-6"  
class="td11"> <span 
class="ecrm-1000">0.214  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-6-7"  
class="td11">  <span 
class="ecrm-1000">0.128    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-6-8"  
class="td11">    <span 
class="ecrm-1000">0.183      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-7-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-7-2"  
class="td11">    <span 
class="ecrm-1000">#4       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-7-3"  
class="td11"> <span 
class="ecrm-1000">YFCC15M                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-7-4"  
class="td11">   <span 
class="ecrm-1000">0.071    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-7-5"  
class="td11">   <span 
class="ecrm-1000">0.046     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-7-6"  
class="td11"> <span 
class="ecrm-1000">0.182  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-7-7"  
class="td11">  <span 
class="ecrm-1000">0.120    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-7-8"  
class="td11">    <span 
class="ecrm-1000">0.162      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-8-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-8-2"  
class="td11">    <span 
class="ecrm-1000">#5       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-8-3"  
class="td11"> <span 
class="ecrm-1000">#0 + #1 + #2                                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-8-4"  
class="td11">   <span 
class="ecrm-1000">0.097    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-8-5"  
class="td11">   <span 
class="ecrm-1000">0.084     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-8-6"  
class="td11"> <span 
class="ecrm-1000">0.208  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-8-7"  
class="td11">  <span 
class="ecrm-1000">0.131    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-8-8"  
class="td11">    <span 
class="ecrm-1000">0.192      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-9-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-9-2"  
class="td11">    <span 
class="ecrm-1000">#6       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-9-3"  
class="td11"> <span 
class="ecrm-1000">#0 + #1 + #3                                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-9-4"  
class="td11">   <span 
class="ecrm-1000">0.091    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-9-5"  
class="td11">   <span 
class="ecrm-1000">0.081     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-9-6"  
class="td11"> <span 
class="ecrm-1000">0.222  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-9-7"  
class="td11">  <span 
class="ecrm-1000">0.138    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-9-8"  
class="td11">    <span 
class="ecrm-1000">0.202      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-10-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-10-2"  
class="td11">    <span 
class="ecrm-1000">#7       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-10-3"  
class="td11"> <span 
class="ecrm-1000">#0 + #2 + #3 + #4                                         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-10-4"  
class="td11">   <span 
class="ecrm-1000">0.095    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-10-5"  
class="td11">   <span 
class="ecrm-1000">0.075     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-10-6"  
class="td11"> <span 
class="ecrm-1000">0.205  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-10-7"  
class="td11">  <span 
class="ecrm-1000">0.135    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-10-8"  
class="td11">    <span 
class="ecrm-1000">0.184      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-11-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">small</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-11-2"  
class="td11">    <span 
class="ecrm-1000">#8       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-11-3"  
class="td11"> <span 
class="ecrm-1000">#0&#8211;4                                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-11-4"  
class="td11">   <span 
class="ecrm-1000">0.093    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-11-5"  
class="td11">   <span 
class="ecrm-1000">0.076     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-11-6"  
class="td11"> <span 
class="ecrm-1000">0.205  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-11-7"  
class="td11">  <span 
class="ecrm-1000">0.135    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-11-8"  
class="td11">    <span 
class="ecrm-1000">0.191      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-12-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-12-2"  
class="td11">    <span 
class="ecrm-1000">#9       </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-12-3"  
class="td11"> <span 
class="ecrm-1000">CC12M                                                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-12-4"  
class="td11">   <span 
class="ecrm-1000">0.245    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-12-5"  
class="td11">   <span 
class="ecrm-1000">0.189     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-12-6"  
class="td11"> <span 
class="ecrm-1000">0.283  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-12-7"  
class="td11">  <span 
class="ecrm-1000">0.206    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-12-8"  
class="td11">    <span 
class="ecrm-1000">0.266      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-13-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-13-2"  
class="td11">    <span 
class="ecrm-1000">#10      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-13-3"  
class="td11"> <span 
class="ecrm-1000">LAION15M                                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-13-4"  
class="td11">   <span 
class="ecrm-1000">0.270    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-13-5"  
class="td11">   <span 
class="ecrm-1000">0.215     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-13-6"  
class="td11"> <span 
class="ecrm-1000">0.317  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-13-7"  
class="td11">  <span 
class="ecrm-1000">0.181    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-13-8"  
class="td11">    <span 
class="ecrm-1000">0.300      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-14-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-14-2"  
class="td11">    <span 
class="ecrm-1000">#11      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-14-3"  
class="td11"> <span 
class="ecrm-1000">RedCaps                                                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-14-4"  
class="td11">   <span 
class="ecrm-1000">0.237    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-14-5"  
class="td11">   <span 
class="ecrm-1000">0.166     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-14-6"  
class="td11"> <span 
class="ecrm-1000">0.271  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-14-7"  
class="td11">  <span 
class="ecrm-1000">0.150    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-14-8"  
class="td11">    <span 
class="ecrm-1000">0.261      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-15-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-15-2"  
class="td11">    <span 
class="ecrm-1000">#12      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-15-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock 15M                                              </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-15-4"  
class="td11">   <span 
class="ecrm-1000">0.229    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-15-5"  
class="td11">   <span 
class="ecrm-1000">0.191     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-15-6"  
class="td11"> <span 
class="ecrm-1000">0.316  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-15-7"  
class="td11">  <span 
class="ecrm-1000">0.190    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-15-8"  
class="td11">    <span 
class="ecrm-1000">0.284      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-16-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-16-2"  
class="td11">    <span 
class="ecrm-1000">#13      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-16-3"  
class="td11"> <span 
class="ecrm-1000">YFCC15M                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-16-4"  
class="td11">   <span 
class="ecrm-1000">0.232    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-16-5"  
class="td11">   <span 
class="ecrm-1000">0.137     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-16-6"  
class="td11"> <span 
class="ecrm-1000">0.263  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-16-7"  
class="td11">  <span 
class="ecrm-1000">0.174    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-16-8"  
class="td11">    <span 
class="ecrm-1000">0.251      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-17-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-17-2"  
class="td11">    <span 
class="ecrm-1000">#14      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-17-3"  
class="td11"> <span 
class="ecrm-1000">#9 + #10 + #11                                              </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-17-4"  
class="td11">   <span 
class="ecrm-1000">0.376    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-17-5"  
class="td11">   <span 
class="ecrm-1000">0.287     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-17-6"  
class="td11"> <span 
class="ecrm-1000">0.387  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-17-7"  
class="td11">  <span 
class="ecrm-1000">0.227    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-17-8"  
class="td11">    <span 
class="ecrm-1000">0.358      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-18-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-18-2"  
class="td11">    <span 
class="ecrm-1000">#15      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-18-3"  
class="td11"> <span 
class="ecrm-1000">#9 + #10 + #12                                              </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-18-4"  
class="td11">   <span 
class="ecrm-1000">0.342    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-18-5"  
class="td11">   <span 
class="ecrm-1000">0.278     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-18-6"  
class="td11"> <span 
class="ecrm-1000">0.362  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-18-7"  
class="td11">  <span 
class="ecrm-1000">0.242    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-18-8"  
class="td11">    <span 
class="ecrm-1000">0.349      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-19-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-19-2"  
class="td11">    <span 
class="ecrm-1000">#16      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-19-3"  
class="td11"> <span 
class="ecrm-1000">#9 + #11 + #12 + #13                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-19-4"  
class="td11">   <span 
class="ecrm-1000">0.360    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-19-5"  
class="td11">   <span 
class="ecrm-1000">0.268     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-19-6"  
class="td11"> <span 
class="ecrm-1000">0.365  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-19-7"  
class="td11">  <span 
class="ecrm-1000">0.190    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-19-8"  
class="td11">    <span 
class="ecrm-1000">0.338      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-20-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-20-2"  
class="td11">    <span 
class="ecrm-1000">#17      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-20-3"  
class="td11"> <span 
class="ecrm-1000">#9&#8211;13                                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-20-4"  
class="td11">   <span 
class="ecrm-1000">0.371    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-20-5"  
class="td11">   <span 
class="ecrm-1000">0.285     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-20-6"  
class="td11"> <span 
class="ecrm-1000">0.408  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-20-7"  
class="td11">  <span 
class="ecrm-1000">0.194    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-20-8"  
class="td11">    <span 
class="ecrm-1000">0.361      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-21-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-21-2"  
class="td11">    <span 
class="ecrm-1000">#18      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-21-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock illustration                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-21-4"  
class="td11">   <span 
class="ecrm-1000">0.053    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-21-5"  
class="td11">   <span 
class="ecrm-1000">0.094     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-21-6"  
class="td11"> <span 
class="ecrm-1000">0.205  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-21-7"  
class="td11">  <span 
class="ecrm-1000">0.112    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-21-8"  
class="td11">    <span 
class="ecrm-1000">0.179      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-22-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-22-2"  
class="td11">    <span 
class="ecrm-1000">#19      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-22-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock photo                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-22-4"  
class="td11">   <span 
class="ecrm-1000">0.342    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-22-5"  
class="td11">   <span 
class="ecrm-1000">0.209     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-22-6"  
class="td11"> <span 
class="ecrm-1000">0.364  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-22-7"  
class="td11">  <span 
class="ecrm-1000">0.248    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-22-8"  
class="td11">    <span 
class="ecrm-1000">0.323      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-23-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-23-2"  
class="td11">    <span 
class="ecrm-1000">#20      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-23-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock vectors                                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-23-4"  
class="td11">   <span 
class="ecrm-1000">0.072    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-23-5"  
class="td11">   <span 
class="ecrm-1000">0.151     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-23-6"  
class="td11"> <span 
class="ecrm-1000">0.216  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-23-7"  
class="td11">  <span 
class="ecrm-1000">0.129    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-23-8"  
class="td11">    <span 
class="ecrm-1000">0.206      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-24-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-24-2"  
class="td11">    <span 
class="ecrm-1000">#21      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-24-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock full                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-24-4"  
class="td11">   <span 
class="ecrm-1000">0.313    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-24-5"  
class="td11">   <span 
class="ecrm-1000">0.254     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-24-6"  
class="td11"> <span 
class="ecrm-1000">0.353  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-24-7"  
class="td11">  <span 
class="ecrm-1000">0.240    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-24-8"  
class="td11">    <span 
class="ecrm-1000">0.335      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-25-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-25-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-25-2"  
class="td11">    <span 
class="ecrm-1000">#22      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-25-3"  
class="td11"> <span 
class="ecrm-1000">WIT full                                                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-25-4"  
class="td11">   <span 
class="ecrm-1000">0.096    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-25-5"  
class="td11">   <span 
class="ecrm-1000">0.063     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-25-6"  
class="td11"> <span 
class="ecrm-1000">0.196  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-25-7"  
class="td11">  <span 
class="ecrm-1000">0.088    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-25-8"  
class="td11">    <span 
class="ecrm-1000">0.175      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-26-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-26-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-26-2"  
class="td11">    <span 
class="ecrm-1000">#23      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-26-3"  
class="td11"> <span 
class="ecrm-1000">WIT English                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-26-4"  
class="td11">   <span 
class="ecrm-1000">0.051    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-26-5"  
class="td11">   <span 
class="ecrm-1000">0.038     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-26-6"  
class="td11"> <span 
class="ecrm-1000">0.145  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-26-7"  
class="td11">  <span 
class="ecrm-1000">0.073    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-26-8"  
class="td11">    <span 
class="ecrm-1000">0.142      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-27-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-27-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-27-2"  
class="td11">    <span 
class="ecrm-1000">#24      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-27-3"  
class="td11"> <span 
class="ecrm-1000">COYO                                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-27-4"  
class="td11">   <span 
class="ecrm-1000">0.272    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-27-5"  
class="td11">   <span 
class="ecrm-1000">0.235     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-27-6"  
class="td11"> <span 
class="ecrm-1000">0.333  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-27-7"  
class="td11">  <span 
class="ecrm-1000">0.249    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-27-8"  
class="td11">    <span 
class="ecrm-1000">0.314      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-28-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-28-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">medium</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-28-2"  
class="td11">    <span 
class="ecrm-1000">#25      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-28-3"  
class="td11"> <span 
class="ecrm-1000">LAION-COCO                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-28-4"  
class="td11">   <span 
class="ecrm-1000">0.209    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-28-5"  
class="td11">   <span 
class="ecrm-1000">0.205     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-28-6"  
class="td11"> <span 
class="ecrm-1000">0.293  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-28-7"  
class="td11">  <span 
class="ecrm-1000">0.243    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-28-8"  
class="td11">    <span 
class="ecrm-1000">0.288      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-29-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-29-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-29-2"  
class="td11">    <span 
class="ecrm-1000">#26      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-29-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock illustration                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-29-4"  
class="td11">   <span 
class="ecrm-1000">0.337    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-29-5"  
class="td11">   <span 
class="ecrm-1000">0.203     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-29-6"  
class="td11"> <span 
class="ecrm-1000">0.307  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-29-7"  
class="td11">  <span 
class="ecrm-1000">0.223    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-29-8"  
class="td11">    <span 
class="ecrm-1000">0.298      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-30-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-30-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-30-2"  
class="td11">    <span 
class="ecrm-1000">#27      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-30-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock photo                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-30-4"  
class="td11">   <span 
class="ecrm-1000">0.485    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-30-5"  
class="td11">   <span 
class="ecrm-1000">0.304     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-30-6"  
class="td11"> <span 
class="ecrm-1000">0.432  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-30-7"  
class="td11">  <span 
class="ecrm-1000">0.311    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-30-8"  
class="td11">    <span 
class="ecrm-1000">0.389      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-31-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-31-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-31-2"  
class="td11">    <span 
class="ecrm-1000">#28      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-31-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock vectors                                           </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-31-4"  
class="td11">   <span 
class="ecrm-1000">0.126    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-31-5"  
class="td11">   <span 
class="ecrm-1000">0.223     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-31-6"  
class="td11"> <span 
class="ecrm-1000">0.244  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-31-7"  
class="td11">  <span 
class="ecrm-1000">0.152    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-31-8"  
class="td11">    <span 
class="ecrm-1000">0.243      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-32-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-32-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-32-2"  
class="td11">    <span 
class="ecrm-1000">#29      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-32-3"  
class="td11"> <span 
class="ecrm-1000">Shutterstock full                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-32-4"  
class="td11">   <span 
class="ecrm-1000">0.500    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-32-5"  
class="td11">   <span 
class="ecrm-1000">0.412     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-32-6"  
class="td11"> <span 
class="ecrm-1000">0.472  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-32-7"  
class="td11">  <span 
class="ecrm-1000">0.335    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-32-8"  
class="td11">    <span 
class="ecrm-1000">0.447      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-33-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-33-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-33-2"  
class="td11">    <span 
class="ecrm-1000">#30      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-33-3"  
class="td11"> <span 
class="ecrm-1000">COYO                                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-33-4"  
class="td11">   <span 
class="ecrm-1000">0.615    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-33-5"  
class="td11">   <span 
class="ecrm-1000">0.504     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-33-6"  
class="td11"> <span 
class="ecrm-1000">0.529  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-33-7"  
class="td11">  <span 
class="ecrm-1000">0.332    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-33-8"  
class="td11">    <span 
class="ecrm-1000">0.522      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-34-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-34-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-34-2"  
class="td11">    <span 
class="ecrm-1000">#31      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-34-3"  
class="td11"> <span 
class="ecrm-1000">LAION-COCO                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-34-4"  
class="td11">   <span 
class="ecrm-1000">0.355    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-34-5"  
class="td11">   <span 
class="ecrm-1000">0.351     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-34-6"  
class="td11"> <span 
class="ecrm-1000">0.395  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-34-7"  
class="td11">  <span 
class="ecrm-1000">0.366    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-34-8"  
class="td11">    <span 
class="ecrm-1000">0.388      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-35-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-35-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-35-2"  
class="td11">    <span 
class="ecrm-1000">#32      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-35-3"  
class="td11"> <span 
class="ecrm-1000">COYO + LAION-COCO                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-35-4"  
class="td11">   <span 
class="ecrm-1000">0.528    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-35-5"  
class="td11">   <span 
class="ecrm-1000">0.458     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-35-6"  
class="td11"> <span 
class="ecrm-1000">0.479  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-35-7"  
class="td11">  <span 
class="ecrm-1000">0.466    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-35-8"  
class="td11">    <span 
class="ecrm-1000">0.488      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-36-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-36-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-36-2"  
class="td11">    <span 
class="ecrm-1000">#33      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-36-3"  
class="td11"> <span 
class="ecrm-1000">LAION-A                                                         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-36-4"  
class="td11">   <span 
class="ecrm-1000">0.611    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-36-5"  
class="td11">   <span 
class="ecrm-1000">0.474     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-36-6"  
class="td11"> <span 
class="ecrm-1000">0.501  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-36-7"  
class="td11">  <span 
class="ecrm-1000">0.414    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-36-8"  
class="td11">    <span 
class="ecrm-1000">0.495      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-37-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-37-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-37-2"  
class="td11">    <span 
class="ecrm-1000">#34      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-37-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #9&#8211;13                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-37-4"  
class="td11">   <span 
class="ecrm-1000">0.602    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-37-5"  
class="td11">   <span 
class="ecrm-1000">0.498     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-37-6"  
class="td11"> <span 
class="ecrm-1000">0.541  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-37-7"  
class="td11">  <span 
class="ecrm-1000">0.284    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-37-8"  
class="td11">    <span 
class="ecrm-1000">0.527      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-38-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-38-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-38-2"  
class="td11">    <span 
class="ecrm-1000">#35      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-38-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #9&#8211;13 (2x upsampled)               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-38-4"  
class="td11">   <span 
class="ecrm-1000">0.613    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-38-5"  
class="td11">   <span 
class="ecrm-1000">0.507     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-38-6"  
class="td11"> <span 
class="ecrm-1000">0.559  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-38-7"  
class="td11">  <span 
class="ecrm-1000">0.293    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-38-8"  
class="td11">    <span 
class="ecrm-1000">0.532      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-39-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-39-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-39-2"  
class="td11">    <span 
class="ecrm-1000">#36      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-39-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #9&#8211;13 (4x upsampled)               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-39-4"  
class="td11">   <span 
class="ecrm-1000">0.615    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-39-5"  
class="td11">   <span 
class="ecrm-1000">0.514     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-39-6"  
class="td11"> <span 
class="ecrm-1000">0.553  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-39-7"  
class="td11">  <span 
class="ecrm-1000">0.295    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-39-8"  
class="td11">    <span 
class="ecrm-1000">0.533      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-40-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-40-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-40-2"  
class="td11">    <span 
class="ecrm-1000">#37      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-40-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #9&#8211;13 (6x upsampled)               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-40-4"  
class="td11">   <span 
class="ecrm-1000">0.620    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-40-5"  
class="td11">   <span 
class="ecrm-1000">0.519     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-40-6"  
class="td11"> <span 
class="ecrm-1000">0.558  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-40-7"  
class="td11">  <span 
class="ecrm-1000">0.301    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-40-8"  
class="td11">    <span 
class="ecrm-1000">0.538      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-41-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-41-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-41-2"  
class="td11">    <span 
class="ecrm-1000">#38      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-41-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #9&#8211;13 (8x upsampled)               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-41-4"  
class="td11">   <span 
class="ecrm-1000">0.624    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-41-5"  
class="td11">   <span 
class="ecrm-1000">0.520     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-41-6"  
class="td11"> <span 
class="ecrm-1000">0.533  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-41-7"  
class="td11">  <span 
class="ecrm-1000">0.302    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-41-8"  
class="td11">    <span 
class="ecrm-1000">0.526      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-42-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-42-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-42-2"  
class="td11">    <span 
class="ecrm-1000">#39      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-42-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #9&#8211;13 (10x upsampled)              </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-42-4"  
class="td11">   <span 
class="ecrm-1000">0.621    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-42-5"  
class="td11">   <span 
class="ecrm-1000">0.520     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-42-6"  
class="td11"> <span 
class="ecrm-1000">0.540  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-42-7"  
class="td11">  <span 
class="ecrm-1000">0.303    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-42-8"  
class="td11">    <span 
class="ecrm-1000">0.527      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-43-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-43-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-43-2"  
class="td11">    <span 
class="ecrm-1000">#40      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-43-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ COYO                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-43-4"  
class="td11">   <span 
class="ecrm-1000">0.561    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-43-5"  
class="td11">   <span 
class="ecrm-1000">0.472     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-43-6"  
class="td11"> <span 
class="ecrm-1000">0.504  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-43-7"  
class="td11">  <span 
class="ecrm-1000">0.375    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-43-8"  
class="td11">    <span 
class="ecrm-1000">0.503      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-44-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-44-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-44-2"  
class="td11">    <span 
class="ecrm-1000">#41      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-44-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ LAION-A                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-44-4"  
class="td11">   <span 
class="ecrm-1000">0.607    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-44-5"  
class="td11">   <span 
class="ecrm-1000">0.480     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-44-6"  
class="td11"> <span 
class="ecrm-1000">0.531  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-44-7"  
class="td11">  <span 
class="ecrm-1000">0.386    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-44-8"  
class="td11">    <span 
class="ecrm-1000">0.517      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-45-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-45-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-45-2"  
class="td11">    <span 
class="ecrm-1000">#42      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-45-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ LAION-COCO                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-45-4"  
class="td11">   <span 
class="ecrm-1000">0.522    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-45-5"  
class="td11">   <span 
class="ecrm-1000">0.457     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-45-6"  
class="td11"> <span 
class="ecrm-1000">0.513  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-45-7"  
class="td11">  <span 
class="ecrm-1000">0.374    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-45-8"  
class="td11">    <span 
class="ecrm-1000">0.504      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-46-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-46-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-46-2"  
class="td11">    <span 
class="ecrm-1000">#43      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-46-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-46-4"  
class="td11">   <span 
class="ecrm-1000">0.609    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-46-5"  
class="td11">   <span 
class="ecrm-1000">0.508     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-46-6"  
class="td11"> <span 
class="ecrm-1000">0.546  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-46-7"  
class="td11">  <span 
class="ecrm-1000">0.303    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-46-8"  
class="td11">    <span 
class="ecrm-1000">0.525      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-47-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-47-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-47-2"  
class="td11">    <span 
class="ecrm-1000">#44      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-47-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (2x upsampled)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-47-4"  
class="td11">   <span 
class="ecrm-1000">0.621    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-47-5"  
class="td11">   <span 
class="ecrm-1000">0.509     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-47-6"  
class="td11"> <span 
class="ecrm-1000">0.547  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-47-7"  
class="td11">  <span 
class="ecrm-1000">0.315    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-47-8"  
class="td11">    <span 
class="ecrm-1000">0.530      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-48-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-48-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-48-2"  
class="td11">    <span 
class="ecrm-1000">#45      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-48-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (4x upsampled)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-48-4"  
class="td11">   <span 
class="ecrm-1000">0.632    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-48-5"  
class="td11">   <span 
class="ecrm-1000">0.515     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-48-6"  
class="td11"> <span 
class="ecrm-1000">0.533  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-48-7"  
class="td11">  <span 
class="ecrm-1000">0.316    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-48-8"  
class="td11">    <span 
class="ecrm-1000">0.522      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-49-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-49-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-49-2"  
class="td11">    <span 
class="ecrm-1000">#46      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-49-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (6x upsampled)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-49-4"  
class="td11">   <span 
class="ecrm-1000">0.635    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-49-5"  
class="td11">   <span 
class="ecrm-1000">0.515     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-49-6"  
class="td11"> <span 
class="ecrm-1000">0.535  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-49-7"  
class="td11">  <span 
class="ecrm-1000">0.329    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-49-8"  
class="td11">    <span 
class="ecrm-1000">0.521      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-50-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-50-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-50-2"  
class="td11">    <span 
class="ecrm-1000">#47      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-50-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (8x upsampled)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-50-4"  
class="td11">   <span 
class="ecrm-1000">0.633    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-50-5"  
class="td11">   <span 
class="ecrm-1000">0.515     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-50-6"  
class="td11"> <span 
class="ecrm-1000">0.523  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-50-7"  
class="td11">  <span 
class="ecrm-1000">0.328    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-50-8"  
class="td11">    <span 
class="ecrm-1000">0.520      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-51-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-51-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">large</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-51-2"  
class="td11">    <span 
class="ecrm-1000">#48      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-51-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (10x upsampled) </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-51-4"  
class="td11">   <span 
class="ecrm-1000">0.630    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-51-5"  
class="td11">   <span 
class="ecrm-1000">0.513     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-51-6"  
class="td11"> <span 
class="ecrm-1000">0.523  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-51-7"  
class="td11">  <span 
class="ecrm-1000">0.317    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-51-8"  
class="td11">    <span 
class="ecrm-1000">0.510      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-52-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-52-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-52-2"  
class="td11">    <span 
class="ecrm-1000">#49      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-52-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-52-4"  
class="td11">   <span 
class="ecrm-1000">0.766    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-52-5"  
class="td11">   <span 
class="ecrm-1000">0.660     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-52-6"  
class="td11"> <span 
class="ecrm-1000">0.662  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-52-7"  
class="td11">  <span 
class="ecrm-1000">0.394    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-52-8"  
class="td11">    <span 
class="ecrm-1000">0.648      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-53-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-53-1"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-53-2"  
class="td11">    <span 
class="ecrm-1000">#50      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-53-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (6x upsampled)   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-53-4"  
class="td11">   <span 
class="ecrm-1000">0.776    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-53-5"  
class="td11">   <span 
class="ecrm-1000">0.671     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-53-6"  
class="td11"> <span 
class="ecrm-1000">0.633  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-53-7"  
class="td11">  <span 
class="ecrm-1000">0.410    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-53-8"  
class="td11">    <span 
class="ecrm-1000">0.638      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-54-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-54-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ectt-1000">xlarge</span></div> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-54-2"  
class="td11">    <span 
class="ecrm-1000">#51      </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-17-54-3"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span><span 
class="ecrm-1000">+ #11+#13+#19 (18x upsampled) </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-54-4"  
class="td11">   <span 
class="ecrm-1000">0.771    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-54-5"  
class="td11">   <span 
class="ecrm-1000">0.667     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-54-6"  
class="td11"> <span 
class="ecrm-1000">0.629  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-54-7"  
class="td11">  <span 
class="ecrm-1000">0.418    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-17-54-8"  
class="td11">    <span 
class="ecrm-1000">0.633      </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-17-55-"><td  style="white-space:nowrap; text-align:left;" id="TBL-17-55-1"  
class="td11">        </td></tr></table>                                                                                                                      </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<h5 class="subsubsectionHead"><span class="titlemark">O.2.1   </span> <a 
 id="x1-106000O.2.1"></a>Additional results</h5>
<!--l. 877--><p class="noindent" >We present a series of additional results for the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track in Table <a 
href="#x1-105005r16">16<!--tex4ht:ref: tab:byod-extra --></a>.
<!--l. 879--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">P   </span> <a 
 id="x1-107000P"></a>Fairness and biases</h3>
<!--l. 882--><p class="noindent" >To study the biases displayed by our models, we include two diversity-related datasets, Dollar
Street [<a 
href="#Xrojas2022dollar">115</a>] and GeoDE [<a 
href="#Xramaswamy2022geode">107</a>], in our evaluation suite, and perform further analysis on the
face datasets FairFace [<a 
href="#Xkarkkainen2021fairface">72</a>] and UTKFace [<a 
href="#Xutkface">150</a>] with demographic labels, following Radford
et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>].
<!--l. 884--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">P.1   </span> <a 
 id="x1-108000P.1"></a>Diversity</h4>
                                                                                         
                                                                                         
<!--l. 888--><p class="noindent" ><a 
 id="x1-108001r21"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<!--l. 889--><p class="noindent" > <img 
src="figures/robustness_diversity-.png" alt="PIC"  
width="328" height="328" >
<a 
 id="x1-108002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;21: </span><span  
class="content">Comparison of average and worst-group scores for Dollar Street and GeoDE diversity
datasets.  On  Dollar  Street,  our  overall  higher-performing  models  display  a  larger  worst-group
performance gap (corresponding to lower income households). GeoDE does not appear to show this
trend.</span></div><!--tex4ht:label?: x1-108001rP -->
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 895--><p class="noindent" >We break down model performance on the Dollar Street and GeoDE datasets in Figure&#x00A0;<a 
href="#x1-108001r21">21<!--tex4ht:ref: fig:robustness_diversity --></a>. Dollar Street
consists of images of household items taken in homes around the world, and represents a wide
socioeconomic range that includes homes with no Internet access [<a 
href="#Xrojas2022dollar">115</a>]. The objects belong to ImageNet
categories, and the task is image classification. Standard ImageNet-trained models achieve
monotonically increasing performance levels with higher household income levels [<a 
href="#Xrojas2022dollar">115</a>]. Here we use the
income-based subgroups defined in Rojas et&#x00A0;al.&#x00A0;[<a 
href="#Xrojas2022dollar">115</a>], and find a similar bias as discovered in
their paper. While our trained models show a smaller worst-group performance gap than an
ImageNet-trained ResNet-50, they underperform a model fine-tuned on Dollar Street. Models
with higher average accuracy show a larger worst-group gap, which future work should try to
address.
<!--l. 897--><p class="noindent" >GeoDE consists of images of everyday items and objects, which again fall into ImageNet categories. The
dataset represents six world regions equally, and primarily aims to promote geographic diversity of datasets
[<a 
href="#Xramaswamy2022geode">107</a>]. Both ImageNet models and our models show less bias under this distribution compared to Dollar
Street, with a smaller worst-group accuracy gap. The trends show that performance across all regions
improves steadily with increased scale, and the performance approaches that of a model fine-tuned on
GeoDE. While we know that classifiers trained specifically on ImageNet can display geographic
biases [<a 
href="#Xramaswamy2022geode">107</a>], these biases are not apparent in our GeoDE model evaluations. Future work is
needed to investigate the extent to which our models have geographic biases not evaluated in
GeoDE.
<h4 class="subsectionHead"><span class="titlemark">P.2   </span> <a 
 id="x1-109000P.2"></a>Fairness</h4>
<!--l. 902--><p class="noindent" >Emulating Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>], we evaluate our best models from the filtering and <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track baselines
on the human face datasets FairFace and UTKFace, using zero-shot classification to predict race, gender,
and age. Note that these are not intended end-goals of the model or benchmark, but rather probes into
models behave differently across demographic subgroups. As described in Appendix&#x00A0;<a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a>, our filleting
track models are trained on images with faces blurred. Nevertheless, these models still perform
significantly above random chance on face classification. We hypothesize that this is due to a
combination of faces bypassing our face blurring filter in the training data, contextual clues outside of
the face region, or signal associated with skin color. The BYOD track model performs even
better than the Filtering track model. We hypothesize that this is because BYOD data is used
off-the-shelf and hence contains non-blurred faces. In Table&#x00A0;<a 
href="#x1-109001r17">17<!--tex4ht:ref: tab:app_fairness_overall --></a>, we present overall accuracy
for these three traits. Note that race is treated as a binary variable (white or non-white) to
enable comparison to prior results; gender is a binary variable (male or female) according to
annotations; and age is binned into 9 ranges according to the annotation precision of FairFace. The
<span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>model, performs better at distinguishing gender, but is worse at distinguishing race and
age.
<!--l. 907--><p class="noindent" >We further break down these statistics over the intersection of race and gender, examining gender
classification accuracies in Table&#x00A0;<a 
href="#x1-109003r18">18<!--tex4ht:ref: tab:app_fairness_intersection --></a>. We find that there are drastic differences in accuracy across different
subgroups, varying by both race and gender. The filtering models shows a tendency to misclassify Black,
Southeast Asian, and East Asian males as females at 20.7%, 17%, and 19.3% respectively on FairFace.
Furthermore, we find that while the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>model improves accuracy, in FairFace most of this
                                                                                         
                                                                                         
improvement is on men (ranging from 1.7pp gain to 9.9pp gain), while on women, it offers little change
(ranging from 0.6pp gain to 6.2pp drop).
<!--l. 909--><p class="noindent" >Following Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>], we also examined associations of particular demographics with potentially
harmful language. We replicate their setup with two classification task: (1) including race-gender
intersection classes (e.g. &#8220;black woman&#8221;, &#8220;indian man&#8221;, etc.), as well as several harmful crime-related terms
(&#8220;thief&#8221;, &#8220;criminal&#8221;, &#8220;suspicious person&#8221;) and (2) out same race-gender intersection classes as well as
non-human terms (&#8220;animal&#8221;, &#8220;gorilla&#8221;, &#8220;chimpanzee&#8221;, &#8220;orangutan&#8221;). We compute the frequency of
misclassification of people into one of the harmful categories and run these experiments on FairFace and
UTKFace separately. The results are shown in Table&#x00A0;<a 
href="#x1-109005r19">19<!--tex4ht:ref: tab:app_fairness_harm --></a>. Unlike in Radford et&#x00A0;al.&#x00A0;[<a 
href="#Xradford2021learning">104</a>], we find that our
models have a very small probability of classifying human faces as non-human, with a max score across all
subgroups of 0.1%. However, a significant proportion of people are misclassified as criminal.
The model is better at classifying race and gender, but also more susceptible to assigning
unfounded associations with images. This again highlights the importance of dataset curation
and the risks associated with zero-shot classification on models trained on such web-scraped
datasets.
                                                                                         
                                                                                         
<!--l. 913--><p class="noindent" ><a 
 id="x1-109001r17"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-109002"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;17: </span><span  
class="content">Overall race, gender, and age classification accuracy of our two best <span 
class="ectt-1000">xlarge </span>baselines,
Image-based <span 
class="cmsy-10x-x-109">&#x2229; </span>CLIP score (L/14 30%) for the filtering track and <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, CLIP score +
4 external sources (upsampled 6x) for the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track. Race classification was binary (white or
non-white) as in Karkkainen &amp; Joo&#x00A0;[<a 
href="#Xkarkkainen2021fairface">72</a>].</span></div><!--tex4ht:label?: x1-109001rP -->
<div class="tabular"> <table id="TBL-18" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-18-1g"><col 
id="TBL-18-1"><col 
id="TBL-18-2"><col 
id="TBL-18-3"><col 
id="TBL-18-4"><col 
id="TBL-18-5"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-18-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-18-1-1"  
class="td11"> <span 
class="ecrm-1000">Dataset   </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-18-1-2"  
class="td11"> <span 
class="ecrm-1000">Track     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-1-3"  
class="td11"> <span 
class="ecrm-1000">Race </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-1-4"  
class="td11"> <span 
class="ecrm-1000">Gender </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-1-5"  
class="td11"> <span 
class="ecrm-1000">Age </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-18-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-18-2-1"  
class="td11">          </td><td  style="white-space:nowrap; text-align:left;" id="TBL-18-2-2"  
class="td11"> <span 
class="ecrm-1000">Filtering </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-2-3"  
class="td11"> <span 
class="ecrm-1000">86.4  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-2-4"  
class="td11">  <span 
class="ecrm-1000">91.7   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-2-5"  
class="td11"> <span 
class="ecrm-1000">34.3 </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-18-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-18-3-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">FairFace</span></div>   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-18-3-2"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span>  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-3-3"  
class="td11"> <span 
class="ecrm-1000">76.5  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-3-4"  
class="td11">  <span 
class="ecrm-1000">93.9   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-3-5"  
class="td11"> <span 
class="ecrm-1000">33.8 </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-18-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-18-4-1"  
class="td11">          </td><td  style="white-space:nowrap; text-align:left;" id="TBL-18-4-2"  
class="td11"> <span 
class="ecrm-1000">Filtering </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-4-3"  
class="td11"> <span 
class="ecrm-1000">86.2  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-4-4"  
class="td11">  <span 
class="ecrm-1000">93.8   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-4-5"  
class="td11"> <span 
class="ecrm-1000">39.5 </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-18-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-18-5-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">UTKFace</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-18-5-2"  
class="td11"> <span 
class="eccc1000-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span>  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-5-3"  
class="td11"> <span 
class="ecrm-1000">86.1  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-5-4"  
class="td11">  <span 
class="ecrm-1000">95.5   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-18-5-5"  
class="td11"> <span 
class="ecrm-1000">38.6 </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-18-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-18-6-1"  
class="td11">          </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 936--><p class="noindent" ><a 
 id="x1-109003r18"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-109004"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;18: </span><span  
class="content">Gender classification accuracy of our two best <span 
class="ectt-1000">xlarge </span>baselines, Image-based <span 
class="cmsy-10x-x-109">&#x2229; </span>CLIP
score (L/14 30%) for the filtering track and <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, CLIP score + 4 external sources
(upsampled 6x) for the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track.</span></div><!--tex4ht:label?: x1-109003rP -->
<!--l. 944--><p class="noindent" ><span 
class="ecrm-1000">FairFace</span><br />
 <!--tex4ht:inline--><div class="tabular"> <table id="TBL-19" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-19-1g"><col 
id="TBL-19-1"><col 
id="TBL-19-2"><col 
id="TBL-19-3"><col 
id="TBL-19-4"><col 
id="TBL-19-5"><col 
id="TBL-19-6"><col 
id="TBL-19-7"><col 
id="TBL-19-8"><col 
id="TBL-19-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-19-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Track</span></div>     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-19-1-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Gender</span></div> </td><td colspan="3" style="white-space:nowrap; text-align:center;" id="TBL-19-1-3"  
class="td11"></td>                                         <div class="multicolumn"  style="white-space:nowrap; text-align:center;"><span 
class="ecrm-1000">Race</span></div>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-19-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-2-1"  
class="td11">         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-19-2-2"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-3"  
class="td11"> <span 
class="ecrm-1000">Black </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-4"  
class="td11"> <span 
class="ecrm-1000">White </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-5"  
class="td11"> <span 
class="ecrm-1000">Indian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-6"  
class="td11"> <span 
class="ecrm-1000">Latino/Hispanic </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-7"  
class="td11"> <span 
class="ecrm-1000">Middle Eastern </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-8"  
class="td11"> <span 
class="ecrm-1000">Southeast Asian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-2-9"  
class="td11"> <span 
class="ecrm-1000">East Asian </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-19-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-3-1"  
class="td11">          </td><td  style="white-space:nowrap; text-align:left;" id="TBL-19-3-2"  
class="td11"> <span 
class="ecrm-1000">Male    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-3"  
class="td11"> <span 
class="ecrm-1000">79.3  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-4"  
class="td11">  <span 
class="ecrm-1000">91.3   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-5"  
class="td11">  <span 
class="ecrm-1000">90.8   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-6"  
class="td11">      <span 
class="ecrm-1000">90.4         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-7"  
class="td11">     <span 
class="ecrm-1000">95.7         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-8"  
class="td11">      <span 
class="ecrm-1000">83.0         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-3-9"  
class="td11">    <span 
class="ecrm-1000">80.7      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-19-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-4-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-19-4-2"  
class="td11"> <span 
class="ecrm-1000">Female  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-3"  
class="td11"> <span 
class="ecrm-1000">95.4  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-4"  
class="td11">  <span 
class="ecrm-1000">96.6   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-5"  
class="td11">  <span 
class="ecrm-1000">94.2   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-6"  
class="td11">      <span 
class="ecrm-1000">96.6         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-7"  
class="td11">     <span 
class="ecrm-1000">96.5         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-8"  
class="td11">      <span 
class="ecrm-1000">97.2         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-4-9"  
class="td11">    <span 
class="ecrm-1000">98.2      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-19-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-5-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-19-5-2"  
class="td11"> <span 
class="ecrm-1000">Male </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-3"  
class="td11"> <span 
class="ecrm-1000">89.2 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-4"  
class="td11"> <span 
class="ecrm-1000">94.8 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-5"  
class="td11"> <span 
class="ecrm-1000">93.2 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-6"  
class="td11"> <span 
class="ecrm-1000">93.4 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-7"  
class="td11"> <span 
class="ecrm-1000">97.4 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-8"  
class="td11"> <span 
class="ecrm-1000">90.2 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-19-5-9"  
class="td11"> <span 
class="ecrm-1000">90.6</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-19-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-6-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="eccc1000-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span> </div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-19-6-2"  
class="td11"> <span 
class="ecrm-1000">Female  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-3"  
class="td11"> <span 
class="ecrm-1000">89.2  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-4"  
class="td11">  <span 
class="ecrm-1000">96.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-5"  
class="td11">  <span 
class="ecrm-1000">94.2   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-6"  
class="td11">      <span 
class="ecrm-1000">96.0         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-7"  
class="td11">     <span 
class="ecrm-1000">96.2         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-8"  
class="td11">      <span 
class="ecrm-1000">97.1         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-19-6-9"  
class="td11">    <span 
class="ecrm-1000">97.0      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-19-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-19-7-1"  
class="td11"> </td></tr></table></div><br />
<span 
class="ecrm-1000">UTKFace</span><br />
<div class="tabular"> <table id="TBL-20" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-20-1g"><col 
id="TBL-20-1"><col 
id="TBL-20-2"><col 
id="TBL-20-3"><col 
id="TBL-20-4"><col 
id="TBL-20-5"><col 
id="TBL-20-6"><col 
id="TBL-20-7"><col 
id="TBL-20-8"><col 
id="TBL-20-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-20-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Track</span></div>     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-20-1-2"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Gender</span></div> </td><td colspan="3" style="white-space:nowrap; text-align:center;" id="TBL-20-1-3"  
class="td11"></td>                  <div class="multicolumn"  style="white-space:nowrap; text-align:center;"><span 
class="ecrm-1000">Race</span></div></tr><tr  
 style="vertical-align:baseline;" id="TBL-20-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-2-1"  
class="td11"> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-20-2-2"  
class="td11"> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-2-3"  
class="td11"> <span 
class="ecrm-1000">Black </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-2-4"  
class="td11"> <span 
class="ecrm-1000">White </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-2-5"  
class="td11"> <span 
class="ecrm-1000">Indian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-2-6"  
class="td11"> <span 
class="ecrm-1000">Asian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-2-7"  
class="td11"> <span 
class="ecrm-1000">Other </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-3-1"  
class="td11">          </td><td  style="white-space:nowrap; text-align:left;" id="TBL-20-3-2"  
class="td11"> <span 
class="ecrm-1000">Male    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-3-3"  
class="td11"> <span 
class="ecrm-1000">95.4  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-3-4"  
class="td11">  <span 
class="ecrm-1000">92.5   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-3-5"  
class="td11">  <span 
class="ecrm-1000">91.7   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-3-6"  
class="td11"> <span 
class="ecrm-1000">73.1  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-3-7"  
class="td11">  <span 
class="ecrm-1000">84.2  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-4-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-20-4-2"  
class="td11"> <span 
class="ecrm-1000">Female  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-4-3"  
class="td11"> <span 
class="ecrm-1000">97.3  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-4-4"  
class="td11">  <span 
class="ecrm-1000">98.7   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-4-5"  
class="td11">  <span 
class="ecrm-1000">97.4   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-4-6"  
class="td11"> <span 
class="ecrm-1000">98.3  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-4-7"  
class="td11">  <span 
class="ecrm-1000">97.4  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-5-1"  
class="td11">          </td><td  style="white-space:nowrap; text-align:left;" id="TBL-20-5-2"  
class="td11"> <span 
class="ecrm-1000">Male    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-5-3"  
class="td11"> <span 
class="ecrm-1000">96.8  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-5-4"  
class="td11">  <span 
class="ecrm-1000">95.9   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-5-5"  
class="td11">  <span 
class="ecrm-1000">94.7   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-5-6"  
class="td11"> <span 
class="ecrm-1000">85.7  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-5-7"  
class="td11">  <span 
class="ecrm-1000">90.4  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-6-1"  
class="td11">  <div class="multirow"><!-- rows=0 -->
<span 
class="eccc1000-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span> </div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-20-6-2"  
class="td11"> <span 
class="ecrm-1000">Female  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-6-3"  
class="td11"> <span 
class="ecrm-1000">96.3  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-6-4"  
class="td11">  <span 
class="ecrm-1000">97.7   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-6-5"  
class="td11">  <span 
class="ecrm-1000">96.8   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-6-6"  
class="td11"> <span 
class="ecrm-1000">95.9  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-20-6-7"  
class="td11">  <span 
class="ecrm-1000">95.6  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-7-1"  
class="td11">         </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 983--><p class="noindent" ><a 
 id="x1-109005r19"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-109006"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;19: </span><span  
class="content">Harmful misclassification rates of our two best <span 
class="ectt-1000">xlarge </span>baselines, Image-based <span 
class="cmsy-10x-x-109">&#x2229; </span>CLIP
score (L/14 30%) for the filtering track and <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, CLIP score + 4 external sources
(upsampled 6x) for the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>track. While very few samples are misclassified as non-human,
the filter track model assigns a crime-related label to a significant portion of people, and this is
exacerbated by the <span 
class="eccc1095-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span> </span>model in many cases.</span></div><!--tex4ht:label?: x1-109005rP -->
<!--l. 991--><p class="noindent" ><span 
class="ecrm-1000">FairFace</span><br />
 <!--tex4ht:inline--><div class="tabular"> <table id="TBL-21" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-21-1g"><col 
id="TBL-21-1"><col 
id="TBL-21-2"><col 
id="TBL-21-3"><col 
id="TBL-21-4"><col 
id="TBL-21-5"><col 
id="TBL-21-6"><col 
id="TBL-21-7"><col 
id="TBL-21-8"><col 
id="TBL-21-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-21-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Track</span></div>    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-21-1-2"  
class="td11">             </td><td colspan="3" style="white-space:nowrap; text-align:center;" id="TBL-21-1-3"  
class="td11"></td>                                         <div class="multicolumn"  style="white-space:nowrap; text-align:center;"><span 
class="ecrm-1000">Race</span></div>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-21-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-2-1"  
class="td11">         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-21-2-2"  
class="td11">             </td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-3"  
class="td11"> <span 
class="ecrm-1000">Black </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-4"  
class="td11"> <span 
class="ecrm-1000">White </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-5"  
class="td11"> <span 
class="ecrm-1000">Indian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-6"  
class="td11"> <span 
class="ecrm-1000">Latino/Hispanic </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-7"  
class="td11"> <span 
class="ecrm-1000">Middle Eastern </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-8"  
class="td11"> <span 
class="ecrm-1000">Southeast Asian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-2-9"  
class="td11"> <span 
class="ecrm-1000">East Asian </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-21-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-3-1"  
class="td11">         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-21-3-2"  
class="td11"> <span 
class="ecrm-1000">Crime-related </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-3"  
class="td11">  <span 
class="ecrm-1000">4.4   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-4"  
class="td11">  <span 
class="ecrm-1000">24.3   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-5"  
class="td11">  <span 
class="ecrm-1000">8.8   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-6"  
class="td11">      <span 
class="ecrm-1000">14.3         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-7"  
class="td11">     <span 
class="ecrm-1000">23.7         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-8"  
class="td11">      <span 
class="ecrm-1000">7.4          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-3-9"  
class="td11">    <span 
class="ecrm-1000">8.6      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-21-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-4-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-21-4-2"  
class="td11"> <span 
class="ecrm-1000">Non-human    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-3"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-4"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-5"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-6"  
class="td11">      <span 
class="ecrm-1000">0.0          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-7"  
class="td11">      <span 
class="ecrm-1000">0.0         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-8"  
class="td11">      <span 
class="ecrm-1000">0.0          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-4-9"  
class="td11">    <span 
class="ecrm-1000">0.0      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-21-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-5-1"  
class="td11">  </td> <td  style="white-space:nowrap; text-align:left;" id="TBL-21-5-2"  
class="td11"> <span 
class="ecrm-1000">Crime-related </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-3"  
class="td11"> <span 
class="ecrm-1000">18.4 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-4"  
class="td11"> <span 
class="ecrm-1000">16.8 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-5"  
class="td11"> <span 
class="ecrm-1000">21.5 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-6"  
class="td11"> <span 
class="ecrm-1000">22.9 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-7"  
class="td11"> <span 
class="ecrm-1000">20.9 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-8"  
class="td11"> <span 
class="ecrm-1000">35.3 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-21-5-9"  
class="td11"> <span 
class="ecrm-1000">30.9</span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-21-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-6-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="eccc1000-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span> </div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-21-6-2"  
class="td11"> <span 
class="ecrm-1000">Non-human    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-3"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-4"  
class="td11">  <span 
class="ecrm-1000">0.1   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-5"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-6"  
class="td11">      <span 
class="ecrm-1000">0.1          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-7"  
class="td11">      <span 
class="ecrm-1000">0.0         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-8"  
class="td11">      <span 
class="ecrm-1000">0.1          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-21-6-9"  
class="td11">    <span 
class="ecrm-1000">0.1      </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-21-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-7-1"  
class="td11"> </td></tr></table></div><br />
<span 
class="ecrm-1000">UTKFace</span><br />
<div class="tabular"> <table id="TBL-22" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-22-1g"><col 
id="TBL-22-1"><col 
id="TBL-22-2"><col 
id="TBL-22-3"><col 
id="TBL-22-4"><col 
id="TBL-22-5"><col 
id="TBL-22-6"><col 
id="TBL-22-7"><col 
id="TBL-22-8"><col 
id="TBL-22-9"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-22-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Track</span></div>    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-22-1-2"  
class="td11">             </td><td colspan="3" style="white-space:nowrap; text-align:center;" id="TBL-22-1-3"  
class="td11"></td>                  <div class="multicolumn"  style="white-space:nowrap; text-align:center;"><span 
class="ecrm-1000">Race</span></div></tr><tr  
 style="vertical-align:baseline;" id="TBL-22-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-2-1"  
class="td11"> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-22-2-2"  
class="td11"> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-2-3"  
class="td11"> <span 
class="ecrm-1000">Black </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-2-4"  
class="td11"> <span 
class="ecrm-1000">White </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-2-5"  
class="td11"> <span 
class="ecrm-1000">Indian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-2-6"  
class="td11"> <span 
class="ecrm-1000">Asian </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-2-7"  
class="td11"> <span 
class="ecrm-1000">Other </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-22-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-3-1"  
class="td11">         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-22-3-2"  
class="td11"> <span 
class="ecrm-1000">Crime-related </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-3-3"  
class="td11">  <span 
class="ecrm-1000">6.8   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-3-4"  
class="td11">  <span 
class="ecrm-1000">16.1   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-3-5"  
class="td11">  <span 
class="ecrm-1000">9.1   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-3-6"  
class="td11">  <span 
class="ecrm-1000">6.9   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-3-7"  
class="td11">  <span 
class="ecrm-1000">13.9  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-22-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-4-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-22-4-2"  
class="td11"> <span 
class="ecrm-1000">Non-human    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-4-3"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-4-4"  
class="td11">  <span 
class="ecrm-1000">0.2   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-4-5"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-4-6"  
class="td11">  <span 
class="ecrm-1000">0.1   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-4-7"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-22-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-5-1"  
class="td11">         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-22-5-2"  
class="td11"> <span 
class="ecrm-1000">Crime-related </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-5-3"  
class="td11"> <span 
class="ecrm-1000">12.8  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-5-4"  
class="td11">  <span 
class="ecrm-1000">10.8   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-5-5"  
class="td11">  <span 
class="ecrm-1000">15.2   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-5-6"  
class="td11"> <span 
class="ecrm-1000">13.2  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-5-7"  
class="td11">  <span 
class="ecrm-1000">18.6  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-22-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-6-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="eccc1000-"><span 
class="small-caps">b</span><span 
class="small-caps">y</span><span 
class="small-caps">o</span><span 
class="small-caps">d</span></span> </div>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-22-6-2"  
class="td11"> <span 
class="ecrm-1000">Non-human    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-6-3"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-6-4"  
class="td11">  <span 
class="ecrm-1000">0.2   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-6-5"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-6-6"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-22-6-7"  
class="td11">  <span 
class="ecrm-1000">0.0   </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-22-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-7-1"  
class="td11">         </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<h3 class="sectionHead"><span class="titlemark">Q   </span> <a 
 id="x1-110000Q"></a>Extra figures and tables</h3>
<!--l. 1036--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110001r22"></a>
                                                                                         
                                                                                         
<!--l. 1038--><p class="noindent" > <img 
src="figures/scaling_scatter-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-110002"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;22:  </span><span  
class="content">Improving  downstream  performance  at  smaller  scales  correlates  positively  with
performance gains at larger scales. These trends suggests that dataset filtering can be studied
effectively at smaller scales, even with less computational resources.</span></div><!--tex4ht:label?: x1-110001rQ -->
                                                                                         
                                                                                         
<!--l. 1041--><p class="noindent" ></div><hr class="endfigure">
<div class="table">
                                                                                         
                                                                                         
<!--l. 1047--><p class="noindent" ><a 
 id="x1-110003r20"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110004"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;20: </span><span  
class="content">Rank correlation between the performance obtained with various filtering strategies at
two different scales. Our experimental suggest that the ranking is relatively consistent between
scales, especially for the adjacent scale pairs.</span></div><!--tex4ht:label?: x1-110003rQ -->
<div class="tabular"> <table id="TBL-23" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-23-1g"><col 
id="TBL-23-1"><col 
id="TBL-23-2"><col 
id="TBL-23-3"><col 
id="TBL-23-4"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-23-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-1-1"  
class="td11"> <span 
class="ecrm-0900">Metric                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-1-2"  
class="td11"> <span 
class="ectt-1000">small </span><span 
class="ecrm-0900">vs </span><span 
class="ectt-1000">medium </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-1-3"  
class="td11"> <span 
class="ectt-1000">small </span><span 
class="ecrm-0900">vs </span><span 
class="ectt-1000">large </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-1-4"  
class="td11"> <span 
class="ectt-1000">medium </span><span 
class="ecrm-0900">vs </span><span 
class="ectt-1000">large </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-2-1"  
class="td11"> <span 
class="ecrm-0900">ImageNet acc.          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-2-2"  
class="td11">       <span 
class="ecrm-0900">0.901          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-2-3"  
class="td11">      <span 
class="ecrm-0900">0.830         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-2-4"  
class="td11">       <span 
class="ecrm-0900">0.863          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-3-1"  
class="td11"> <span 
class="ecrm-0900">Average pref. metric  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-3-2"  
class="td11">       <span 
class="ecrm-0900">0.862          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-3-3"  
class="td11">      <span 
class="ecrm-0900">0.738         </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-3-4"  
class="td11">       <span 
class="ecrm-0900">0.889          </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-4-1"  
class="td11">                    </td></tr></table></div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
</div>
<!--l. 1063--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110005r23"></a>
                                                                                         
                                                                                         
<!--l. 1065--><p class="noindent" ><!--l. 1066--><p class="noindent" > <img 
src="figures/train_samples_small-.png" alt="PIC"  
width="446" height="446" >
<!--l. 1069--><p class="noindent" > <img 
src="figures/train_samples_large-.png" alt="PIC"  
width="446" height="446" >
<a 
 id="x1-110006"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;23: </span><span  
class="content">Performance as a function of the number of training samples from the <span 
class="ectt-1000">small </span>(top) and
<span 
class="ectt-1000">large </span>(bottom) scales. There is a significant variance in accuracy even when accounting for the size
of the training set.</span></div><!--tex4ht:label?: x1-110005rQ -->
                                                                                         
                                                                                         
<!--l. 1073--><p class="noindent" ></div><hr class="endfigure">
<!--l. 1076--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110007r24"></a>
                                                                                         
                                                                                         
<!--l. 1078--><p class="noindent" > <img 
src="figures/clip_filter_english-.png" alt="PIC"  
width="352" height="352" >
<a 
 id="x1-110008"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;24: </span><span  
class="content">We examine the percentage of texts classified as English after taking the top fraction
(on the x-axis) of the <span 
class="ectt-1000">large </span>billion pool as sorted by CLIP similarity score. We see that doing CLIP
filtering implicitly does some English filtering, as image-text pairs with a higher CLIP score are
more frequently classified as English.</span></div><!--tex4ht:label?: x1-110007rQ -->
                                                                                         
                                                                                         
<!--l. 1081--><p class="noindent" ></div><hr class="endfigure">
<!--l. 1083--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110009r25"></a>
                                                                                         
                                                                                         
<!--l. 1085--><p class="noindent" > <img 
src="figures/imagenet_vs_all-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-110010"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;25:  </span><span  
class="content">Correlation  between  ImageNet  accuracy  and  average  performance  on  our  suite  of
evaluation tasks. While ImageNet accuracy strongly correlates with the average performance (both
on the clean subset and the full suite), the same is not true for all individual datasets we study, as
shown in Appendix <a 
href="#x1-110000Q">Q<!--tex4ht:ref: sec:app-more-plots --></a>.</span></div><!--tex4ht:label?: x1-110009rQ -->
                                                                                         
                                                                                         
<!--l. 1088--><p class="noindent" ></div><hr class="endfigure">
<!--l. 1090--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110011r26"></a>
                                                                                         
                                                                                         
<!--l. 1092--><p class="noindent" > <img 
src="figures/robustness-.png" alt="PIC"  
width="328" height="328" >
<a 
 id="x1-110012"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;26: </span><span  
class="content">Zero-shot CLIP models trained with various filtering strategies form a reliable trend
relating accuracy on ImageNet and related distribution shifts, exhibiting higher effective robustness
when compared to ImageNet-trained models from Taori et&#x00A0;al.&#x00A0;[<a 
href="#Xtaori2020measuring">130</a>].</span></div><!--tex4ht:label?: x1-110011rQ -->
                                                                                         
                                                                                         
<!--l. 1095--><p class="noindent" ></div><hr class="endfigure">
<!--l. 1100--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110013r27"></a>
                                                                                         
                                                                                         
<!--l. 1102--><p class="noindent" > <img 
src="figures/imagenet_vs_rest_breakdown-.png" alt="PIC"  
width="469" height="469" >
<a 
 id="x1-110014"></a>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;27: </span><span  
class="content">Zero-shot performance on other datasets is often positively correlated with that on
ImageNet, but not always. In cases where ImageNet shows close to zero correlation with other
datasets, performance on that dataset is often close to random chance.</span></div><!--tex4ht:label?: x1-110013rQ -->
                                                                                         
                                                                                         
<!--l. 1105--><p class="noindent" ></div><hr class="endfigure">
                                                                                         
                                                                                         
<!--l. 1111--><p class="noindent" ><a 
 id="x1-110015r21"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110016"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;21: </span><span  
class="content">Baseline results for the filtering track, <span 
class="ectt-1000">small </span>scale.</span></div><!--tex4ht:label?: x1-110015rQ -->
<!--l. 1116--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-24" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-24-1g"><col 
id="TBL-24-1"><col 
id="TBL-24-2"><col 
id="TBL-24-3"><col 
id="TBL-24-4"><col 
id="TBL-24-5"><col 
id="TBL-24-6"><col 
id="TBL-24-7"><col 
id="TBL-24-8"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-24-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div>                                                                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-2"  
class="td11">  <span 
class="ecrm-1000">Training    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-3"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-4"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-7"  
class="td11"> <span 
class="ecrm-1000">Average over  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-2-1"  
class="td11">                                                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-2"  
class="td11"> <span 
class="ecrm-1000">dataset size  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-3"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-4"  
class="td11"> <span 
class="ecrm-1000">dist. shifts  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-5"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-6"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-7"  
class="td11">  <span 
class="ecrm-1000">38 datasets   </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-24-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-3-1"  
class="td11"> <span 
class="ecrm-1000">No filtering </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-2"  
class="td11"> <span 
class="ecrm-1000">12.8M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-3"  
class="td11"> <span 
class="ecrm-1000">0.025 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-4"  
class="td11"> <span 
class="ecrm-1000">0.033 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-5"  
class="td11"> <span 
class="ecrm-1000">0.145 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-6"  
class="td11"> <span 
class="ecrm-1000">0.105 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-7"  
class="td11"> <span 
class="ecrm-1000">0.132</span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-4-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (75%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-2"  
class="td11">    <span 
class="ecrm-1000">9.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-3"  
class="td11">   <span 
class="ecrm-1000">0.028     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-4"  
class="td11">   <span 
class="ecrm-1000">0.037     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-5"  
class="td11">  <span 
class="ecrm-1000">0.153   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-6"  
class="td11">   <span 
class="ecrm-1000">0.102    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-7"  
class="td11">    <span 
class="ecrm-1000">0.140       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-5-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (50%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-5-2"  
class="td11">    <span 
class="ecrm-1000">6.4M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-5-3"  
class="td11">   <span 
class="ecrm-1000">0.027     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-5-4"  
class="td11">   <span 
class="ecrm-1000">0.037     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-5-5"  
class="td11">  <span 
class="ecrm-1000">0.147   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-5-6"  
class="td11">   <span 
class="ecrm-1000">0.105    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-5-7"  
class="td11">    <span 
class="ecrm-1000">0.136       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-6-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (25%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-6-2"  
class="td11">    <span 
class="ecrm-1000">3.2M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-6-3"  
class="td11">   <span 
class="ecrm-1000">0.022     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-6-4"  
class="td11">   <span 
class="ecrm-1000">0.032     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-6-5"  
class="td11">  <span 
class="ecrm-1000">0.130   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-6-6"  
class="td11">   <span 
class="ecrm-1000">0.094    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-6-7"  
class="td11">    <span 
class="ecrm-1000">0.126       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-7-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (10%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-7-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-7-3"  
class="td11">   <span 
class="ecrm-1000">0.010     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-7-4"  
class="td11">   <span 
class="ecrm-1000">0.018     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-7-5"  
class="td11">  <span 
class="ecrm-1000">0.116   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-7-6"  
class="td11">   <span 
class="ecrm-1000">0.075    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-7-7"  
class="td11">    <span 
class="ecrm-1000">0.102       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-8-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (1%)                                                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-8-2"  
class="td11">    <span 
class="ecrm-1000">128K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-8-3"  
class="td11">   <span 
class="ecrm-1000">0.002     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-8-4"  
class="td11">   <span 
class="ecrm-1000">0.005     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-8-5"  
class="td11">  <span 
class="ecrm-1000">0.095   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-8-6"  
class="td11">   <span 
class="ecrm-1000">0.049    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-8-7"  
class="td11">    <span 
class="ecrm-1000">0.078       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-9-1"  
class="td11"> <span 
class="ecrm-1000">Caption length                                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-9-2"  
class="td11">    <span 
class="ecrm-1000">8.7M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-9-3"  
class="td11">   <span 
class="ecrm-1000">0.034     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-9-4"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-9-5"  
class="td11">  <span 
class="ecrm-1000">0.148   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-9-6"  
class="td11">   <span 
class="ecrm-1000">0.109    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-9-7"  
class="td11">    <span 
class="ecrm-1000">0.143       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-10-1"  
class="td11"> <span 
class="ecrm-1000">Image size                                                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-10-2"  
class="td11">    <span 
class="ecrm-1000">7.8M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-10-3"  
class="td11">   <span 
class="ecrm-1000">0.027     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-10-4"  
class="td11">   <span 
class="ecrm-1000">0.036     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-10-5"  
class="td11">  <span 
class="ecrm-1000">0.154   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-10-6"  
class="td11">   <span 
class="ecrm-1000">0.111    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-10-7"  
class="td11">    <span 
class="ecrm-1000">0.137       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-11-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext)                                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-11-2"  
class="td11">    <span 
class="ecrm-1000">6.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-11-3"  
class="td11">   <span 
class="ecrm-1000">0.038     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-11-4"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-11-5"  
class="td11">  <span 
class="ecrm-1000">0.164   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-11-6"  
class="td11">   <span 
class="ecrm-1000">0.113    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-11-7"  
class="td11">    <span 
class="ecrm-1000">0.153       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-12-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext) and caption length                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-12-2"  
class="td11">    <span 
class="ecrm-1000">4.8M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-12-3"  
class="td11">   <span 
class="ecrm-1000">0.041     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-12-4"  
class="td11">   <span 
class="ecrm-1000">0.048     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-12-5"  
class="td11">  <span 
class="ecrm-1000">0.159   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-12-6"  
class="td11">   <span 
class="ecrm-1000">0.111    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-12-7"  
class="td11">    <span 
class="ecrm-1000">0.153       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-13-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext), caption length, and image size                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-13-2"  
class="td11">    <span 
class="ecrm-1000">3.0M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-13-3"  
class="td11">   <span 
class="ecrm-1000">0.030     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-13-4"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-13-5"  
class="td11">  <span 
class="ecrm-1000">0.149   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-13-6"  
class="td11">   <span 
class="ecrm-1000">0.111    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-13-7"  
class="td11">    <span 
class="ecrm-1000">0.137       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-14-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3)                                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-14-2"  
class="td11">    <span 
class="ecrm-1000">2.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-14-3"  
class="td11">   <span 
class="ecrm-1000">0.032     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-14-4"  
class="td11">   <span 
class="ecrm-1000">0.039     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-14-5"  
class="td11">  <span 
class="ecrm-1000">0.143   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-14-6"  
class="td11">   <span 
class="ecrm-1000">0.100    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-14-7"  
class="td11">    <span 
class="ecrm-1000">0.141       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-15-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3) and caption length                                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-15-2"  
class="td11">    <span 
class="ecrm-1000">2.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-15-3"  
class="td11">   <span 
class="ecrm-1000">0.031     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-15-4"  
class="td11">   <span 
class="ecrm-1000">0.038     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-15-5"  
class="td11">  <span 
class="ecrm-1000">0.153   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-15-6"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-15-7"  
class="td11">    <span 
class="ecrm-1000">0.142       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-16-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3), caption length, and image size                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-16-2"  
class="td11">    <span 
class="ecrm-1000">1.5M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-16-3"  
class="td11">   <span 
class="ecrm-1000">0.023     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-16-4"  
class="td11">   <span 
class="ecrm-1000">0.030     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-16-5"  
class="td11">  <span 
class="ecrm-1000">0.154   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-16-6"  
class="td11">   <span 
class="ecrm-1000">0.087    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-16-7"  
class="td11">    <span 
class="ecrm-1000">0.140       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-17-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 1%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-17-2"  
class="td11">    <span 
class="ecrm-1000">129K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-17-3"  
class="td11">   <span 
class="ecrm-1000">0.003     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-17-4"  
class="td11">   <span 
class="ecrm-1000">0.007     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-17-5"  
class="td11">  <span 
class="ecrm-1000">0.114   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-17-6"  
class="td11">   <span 
class="ecrm-1000">0.049    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-17-7"  
class="td11">    <span 
class="ecrm-1000">0.086       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-18-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 3%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-18-2"  
class="td11">    <span 
class="ecrm-1000">384K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-18-3"  
class="td11">   <span 
class="ecrm-1000">0.006     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-18-4"  
class="td11">   <span 
class="ecrm-1000">0.014     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-18-5"  
class="td11">  <span 
class="ecrm-1000">0.104   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-18-6"  
class="td11">   <span 
class="ecrm-1000">0.054    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-18-7"  
class="td11">    <span 
class="ecrm-1000">0.089       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-19-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 10%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-19-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-19-3"  
class="td11">   <span 
class="ecrm-1000">0.026     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-19-4"  
class="td11">   <span 
class="ecrm-1000">0.035     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-19-5"  
class="td11">  <span 
class="ecrm-1000">0.147   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-19-6"  
class="td11">   <span 
class="ecrm-1000">0.072    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-19-7"  
class="td11">    <span 
class="ecrm-1000">0.127       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-20-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 20%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-20-2"  
class="td11">    <span 
class="ecrm-1000">2.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-20-3"  
class="td11">   <span 
class="ecrm-1000">0.051     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-20-4"  
class="td11">   <span 
class="ecrm-1000">0.056     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-20-5"  
class="td11">  <span 
class="ecrm-1000">0.173   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-20-6"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-20-7"  
class="td11">    <span 
class="ecrm-1000">0.160       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-21-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 30%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-21-2"  
class="td11">    <span 
class="ecrm-1000">3.8M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-21-3"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-21-4"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-21-5"  
class="td11">  <span 
class="ecrm-1000">0.180   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-21-6"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-21-7"  
class="td11">    <span 
class="ecrm-1000">0.159       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-22-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 40%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-22-2"  
class="td11">    <span 
class="ecrm-1000">5.1M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-22-3"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-22-4"  
class="td11">   <span 
class="ecrm-1000">0.057     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-22-5"  
class="td11">  <span 
class="ecrm-1000">0.173   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-22-6"  
class="td11">   <span 
class="ecrm-1000">0.109    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-22-7"  
class="td11">    <span 
class="ecrm-1000">0.166       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-23-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 50%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-23-2"  
class="td11">    <span 
class="ecrm-1000">6.4M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-23-3"  
class="td11">   <span 
class="ecrm-1000">0.047     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-23-4"  
class="td11">   <span 
class="ecrm-1000">0.053     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-23-5"  
class="td11">  <span 
class="ecrm-1000">0.174   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-23-6"  
class="td11">   <span 
class="ecrm-1000">0.114    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-23-7"  
class="td11">    <span 
class="ecrm-1000">0.164       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-24-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 75%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-24-2"  
class="td11">    <span 
class="ecrm-1000">9.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-24-3"  
class="td11">   <span 
class="ecrm-1000">0.033     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-24-4"  
class="td11">   <span 
class="ecrm-1000">0.043     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-24-5"  
class="td11">  <span 
class="ecrm-1000">0.161   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-24-6"  
class="td11">   <span 
class="ecrm-1000">0.110    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-24-7"  
class="td11">    <span 
class="ecrm-1000">0.150       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-25-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-25-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 90%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-25-2"  
class="td11">   <span 
class="ecrm-1000">11.5M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-25-3"  
class="td11">   <span 
class="ecrm-1000">0.028     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-25-4"  
class="td11">   <span 
class="ecrm-1000">0.039     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-25-5"  
class="td11">  <span 
class="ecrm-1000">0.140   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-25-6"  
class="td11">   <span 
class="ecrm-1000">0.108    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-25-7"  
class="td11">    <span 
class="ecrm-1000">0.136       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-26-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-26-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3 + English filter                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-26-2"  
class="td11">    <span 
class="ecrm-1000">942K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-26-3"  
class="td11">   <span 
class="ecrm-1000">0.022     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-26-4"  
class="td11">   <span 
class="ecrm-1000">0.032     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-26-5"  
class="td11">  <span 
class="ecrm-1000">0.138   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-26-6"  
class="td11">   <span 
class="ecrm-1000">0.073    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-26-7"  
class="td11">    <span 
class="ecrm-1000">0.121       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-27-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-27-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.28 + English filter                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-27-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-27-3"  
class="td11">   <span 
class="ecrm-1000">0.031     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-27-4"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-27-5"  
class="td11">  <span 
class="ecrm-1000">0.136   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-27-6"  
class="td11">   <span 
class="ecrm-1000">0.085    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-27-7"  
class="td11">    <span 
class="ecrm-1000">0.133       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-28-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-28-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3                                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-28-2"  
class="td11">    <span 
class="ecrm-1000">2.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-28-3"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-28-4"  
class="td11">   <span 
class="ecrm-1000">0.056     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-28-5"  
class="td11">  <span 
class="ecrm-1000">0.166   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-28-6"  
class="td11">   <span 
class="ecrm-1000">0.102    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-28-7"  
class="td11">    <span 
class="ecrm-1000">0.160       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-29-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-29-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score 1% to 30%                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-29-2"  
class="td11">    <span 
class="ecrm-1000">3.7M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-29-3"  
class="td11">   <span 
class="ecrm-1000">0.053     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-29-4"  
class="td11">   <span 
class="ecrm-1000">0.058     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-29-5"  
class="td11">  <span 
class="ecrm-1000">0.185   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-29-6"  
class="td11">   <span 
class="ecrm-1000">0.102    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-29-7"  
class="td11">    <span 
class="ecrm-1000">0.170       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-30-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-30-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score 2% to 30%                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-30-2"  
class="td11">    <span 
class="ecrm-1000">3.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-30-3"  
class="td11">   <span 
class="ecrm-1000">0.056     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-30-4"  
class="td11">   <span 
class="ecrm-1000">0.059     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-30-5"  
class="td11">  <span 
class="ecrm-1000">0.173   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-30-6"  
class="td11">   <span 
class="ecrm-1000">0.108    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-30-7"  
class="td11">    <span 
class="ecrm-1000">0.160       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-31-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-31-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score 5% to 30%                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-31-2"  
class="td11">    <span 
class="ecrm-1000">3.2M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-31-3"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-31-4"  
class="td11">   <span 
class="ecrm-1000">0.055     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-31-5"  
class="td11">  <span 
class="ecrm-1000">0.177   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-31-6"  
class="td11">   <span 
class="ecrm-1000">0.104    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-31-7"  
class="td11">    <span 
class="ecrm-1000">0.168       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-32-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-32-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 1%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-32-2"  
class="td11">    <span 
class="ecrm-1000">128K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-32-3"  
class="td11">   <span 
class="ecrm-1000">0.002     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-32-4"  
class="td11">   <span 
class="ecrm-1000">0.007     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-32-5"  
class="td11">  <span 
class="ecrm-1000">0.111   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-32-6"  
class="td11">   <span 
class="ecrm-1000">0.049    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-32-7"  
class="td11">    <span 
class="ecrm-1000">0.080       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-33-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-33-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 3%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-33-2"  
class="td11">    <span 
class="ecrm-1000">386K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-33-3"  
class="td11">   <span 
class="ecrm-1000">0.004     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-33-4"  
class="td11">   <span 
class="ecrm-1000">0.009     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-33-5"  
class="td11">  <span 
class="ecrm-1000">0.110   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-33-6"  
class="td11">   <span 
class="ecrm-1000">0.052    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-33-7"  
class="td11">    <span 
class="ecrm-1000">0.088       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-34-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-34-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 10%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-34-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-34-3"  
class="td11">   <span 
class="ecrm-1000">0.021     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-34-4"  
class="td11">   <span 
class="ecrm-1000">0.033     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-34-5"  
class="td11">  <span 
class="ecrm-1000">0.131   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-34-6"  
class="td11">   <span 
class="ecrm-1000">0.071    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-34-7"  
class="td11">    <span 
class="ecrm-1000">0.119       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-35-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-35-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 20%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-35-2"  
class="td11">    <span 
class="ecrm-1000">2.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-35-3"  
class="td11">   <span 
class="ecrm-1000">0.042     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-35-4"  
class="td11">   <span 
class="ecrm-1000">0.051     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-35-5"  
class="td11">  <span 
class="ecrm-1000">0.165   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-35-6"  
class="td11">   <span 
class="ecrm-1000">0.100    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-35-7"  
class="td11">    <span 
class="ecrm-1000">0.151       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-36-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-36-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 30%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-36-2"  
class="td11">    <span 
class="ecrm-1000">3.8M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-36-3"  
class="td11">   <span 
class="ecrm-1000">0.051     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-36-4"  
class="td11">   <span 
class="ecrm-1000">0.055     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-36-5"  
class="td11">  <span 
class="ecrm-1000">0.190   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-36-6"  
class="td11">   <span 
class="ecrm-1000">0.108    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-36-7"  
class="td11">    <span 
class="ecrm-1000">0.172       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-37-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-37-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 40%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-37-2"  
class="td11">    <span 
class="ecrm-1000">5.1M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-37-3"  
class="td11">   <span 
class="ecrm-1000">0.050     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-37-4"  
class="td11">   <span 
class="ecrm-1000">0.054     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-37-5"  
class="td11">  <span 
class="ecrm-1000">0.173   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-37-6"  
class="td11">   <span 
class="ecrm-1000">0.107    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-37-7"  
class="td11">    <span 
class="ecrm-1000">0.167       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-38-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-38-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 50%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-38-2"  
class="td11">    <span 
class="ecrm-1000">6.4M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-38-3"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-38-4"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-38-5"  
class="td11">  <span 
class="ecrm-1000">0.164   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-38-6"  
class="td11">   <span 
class="ecrm-1000">0.110    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-38-7"  
class="td11">    <span 
class="ecrm-1000">0.159       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-39-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-39-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 75%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-39-2"  
class="td11">    <span 
class="ecrm-1000">9.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-39-3"  
class="td11">   <span 
class="ecrm-1000">0.035     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-39-4"  
class="td11">   <span 
class="ecrm-1000">0.043     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-39-5"  
class="td11">  <span 
class="ecrm-1000">0.164   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-39-6"  
class="td11">   <span 
class="ecrm-1000">0.111    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-39-7"  
class="td11">    <span 
class="ecrm-1000">0.150       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-40-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-40-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 90%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-40-2"  
class="td11">   <span 
class="ecrm-1000">11.5M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-40-3"  
class="td11">   <span 
class="ecrm-1000">0.031     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-40-4"  
class="td11">   <span 
class="ecrm-1000">0.038     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-40-5"  
class="td11">  <span 
class="ecrm-1000">0.154   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-40-6"  
class="td11">   <span 
class="ecrm-1000">0.109    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-40-7"  
class="td11">    <span 
class="ecrm-1000">0.143       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-41-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-41-1"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet1k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-41-2"  
class="td11">    <span 
class="ecrm-1000">2.9M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-41-3"  
class="td11">   <span 
class="ecrm-1000">0.043     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-41-4"  
class="td11">   <span 
class="ecrm-1000">0.047     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-41-5"  
class="td11">  <span 
class="ecrm-1000">0.178   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-41-6"  
class="td11">   <span 
class="ecrm-1000">0.112    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-41-7"  
class="td11">    <span 
class="ecrm-1000">0.158       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-42-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-42-1"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet21k)                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-42-2"  
class="td11">    <span 
class="ecrm-1000">4.5M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-42-3"  
class="td11">   <span 
class="ecrm-1000">0.035     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-42-4"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-42-5"  
class="td11">  <span 
class="ecrm-1000">0.154   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-42-6"  
class="td11">   <span 
class="ecrm-1000">0.112    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-42-7"  
class="td11">    <span 
class="ecrm-1000">0.146       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-43-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-43-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-43-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-43-3"  
class="td11">   <span 
class="ecrm-1000">0.019     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-43-4"  
class="td11">   <span 
class="ecrm-1000">0.030     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-43-5"  
class="td11">  <span 
class="ecrm-1000">0.144   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-43-6"  
class="td11">   <span 
class="ecrm-1000">0.091    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-43-7"  
class="td11">    <span 
class="ecrm-1000">0.126       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-44-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-44-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.2                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-44-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-44-3"  
class="td11">   <span 
class="ecrm-1000">0.031     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-44-4"  
class="td11">   <span 
class="ecrm-1000">0.036     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-44-5"  
class="td11">  <span 
class="ecrm-1000">0.133   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-44-6"  
class="td11">   <span 
class="ecrm-1000">0.094    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-44-7"  
class="td11">    <span 
class="ecrm-1000">0.131       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-45-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-45-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.5                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-45-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-45-3"  
class="td11">   <span 
class="ecrm-1000">0.032     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-45-4"  
class="td11">   <span 
class="ecrm-1000">0.038     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-45-5"  
class="td11">  <span 
class="ecrm-1000">0.129   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-45-6"  
class="td11">   <span 
class="ecrm-1000">0.091    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-45-7"  
class="td11">    <span 
class="ecrm-1000">0.124       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-46-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-46-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-46-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-46-3"  
class="td11">   <span 
class="ecrm-1000">0.021     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-46-4"  
class="td11">   <span 
class="ecrm-1000">0.028     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-46-5"  
class="td11">  <span 
class="ecrm-1000">0.128   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-46-6"  
class="td11">   <span 
class="ecrm-1000">0.076    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-46-7"  
class="td11">    <span 
class="ecrm-1000">0.116       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-47-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-47-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=2                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-47-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-47-3"  
class="td11">   <span 
class="ecrm-1000">0.011     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-47-4"  
class="td11">   <span 
class="ecrm-1000">0.017     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-47-5"  
class="td11">  <span 
class="ecrm-1000">0.116   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-47-6"  
class="td11">   <span 
class="ecrm-1000">0.063    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-47-7"  
class="td11">    <span 
class="ecrm-1000">0.099       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-48-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-48-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L14, top 30%) and English                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-48-2"  
class="td11">    <span 
class="ecrm-1000">2.0M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-48-3"  
class="td11">   <span 
class="ecrm-1000">0.031     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-48-4"  
class="td11">   <span 
class="ecrm-1000">0.039     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-48-5"  
class="td11">  <span 
class="ecrm-1000">0.163   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-48-6"  
class="td11">   <span 
class="ecrm-1000">0.097    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-48-7"  
class="td11">    <span 
class="ecrm-1000">0.145       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-49-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-49-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L14, top 20%)                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-49-2"  
class="td11">    <span 
class="ecrm-1000">2.6M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-49-3"  
class="td11">   <span 
class="ecrm-1000">0.030     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-49-4"  
class="td11">   <span 
class="ecrm-1000">0.035     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-49-5"  
class="td11">  <span 
class="ecrm-1000">0.155   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-49-6"  
class="td11">   <span 
class="ecrm-1000">0.096    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-49-7"  
class="td11">    <span 
class="ecrm-1000">0.136       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-50-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-50-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L14, top 30%)                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-50-2"  
class="td11">    <span 
class="ecrm-1000">3.9M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-50-3"  
class="td11">   <span 
class="ecrm-1000">0.034     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-50-4"  
class="td11">   <span 
class="ecrm-1000">0.041     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-50-5"  
class="td11">  <span 
class="ecrm-1000">0.151   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-50-6"  
class="td11">   <span 
class="ecrm-1000">0.099    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-50-7"  
class="td11">    <span 
class="ecrm-1000">0.138       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-51-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-51-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L14, top 40%)                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-51-2"  
class="td11">    <span 
class="ecrm-1000">5.1M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-51-3"  
class="td11">   <span 
class="ecrm-1000">0.036     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-51-4"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-51-5"  
class="td11">  <span 
class="ecrm-1000">0.151   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-51-6"  
class="td11">   <span 
class="ecrm-1000">0.110    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-51-7"  
class="td11">    <span 
class="ecrm-1000">0.143       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-52-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-52-1"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet1k)                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-52-2"  
class="td11">    <span 
class="ecrm-1000">427K      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-52-3"  
class="td11">   <span 
class="ecrm-1000">0.009     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-52-4"  
class="td11">   <span 
class="ecrm-1000">0.016     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-52-5"  
class="td11">  <span 
class="ecrm-1000">0.120   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-52-6"  
class="td11">   <span 
class="ecrm-1000">0.055    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-52-7"  
class="td11">    <span 
class="ecrm-1000">0.096       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-53-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-53-1"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet21k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-53-2"  
class="td11">    <span 
class="ecrm-1000">3.2M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-53-3"  
class="td11">   <span 
class="ecrm-1000">0.046     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-53-4"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-53-5"  
class="td11">  <span 
class="ecrm-1000">0.169   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-53-6"  
class="td11">   <span 
class="ecrm-1000">0.112    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-53-7"  
class="td11">    <span 
class="ecrm-1000">0.156       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-54-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-54-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-54-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-54-3"  
class="td11">   <span 
class="ecrm-1000">0.011     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-54-4"  
class="td11">   <span 
class="ecrm-1000">0.020     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-54-5"  
class="td11">  <span 
class="ecrm-1000">0.128   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-54-6"  
class="td11">   <span 
class="ecrm-1000">0.078    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-54-7"  
class="td11">    <span 
class="ecrm-1000">0.112       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-55-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-55-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.5                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-55-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-55-3"  
class="td11">   <span 
class="ecrm-1000">0.023     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-55-4"  
class="td11">   <span 
class="ecrm-1000">0.035     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-55-5"  
class="td11">  <span 
class="ecrm-1000">0.127   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-55-6"  
class="td11">   <span 
class="ecrm-1000">0.088    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-55-7"  
class="td11">    <span 
class="ecrm-1000">0.127       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-56-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-56-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-56-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-56-3"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-56-4"  
class="td11">   <span 
class="ecrm-1000">0.044     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-56-5"  
class="td11">  <span 
class="ecrm-1000">0.163   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-56-6"  
class="td11">   <span 
class="ecrm-1000">0.105    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-56-7"  
class="td11">    <span 
class="ecrm-1000">0.154       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-57-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-57-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1.2                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-57-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-57-3"  
class="td11">   <span 
class="ecrm-1000">0.038     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-57-4"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-57-5"  
class="td11">  <span 
class="ecrm-1000">0.150   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-57-6"  
class="td11">   <span 
class="ecrm-1000">0.101    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-57-7"  
class="td11">    <span 
class="ecrm-1000">0.142       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-58-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-58-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-58-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-58-3"  
class="td11">   <span 
class="ecrm-1000">0.012     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-58-4"  
class="td11">   <span 
class="ecrm-1000">0.020     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-58-5"  
class="td11">  <span 
class="ecrm-1000">0.126   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-58-6"  
class="td11">   <span 
class="ecrm-1000">0.073    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-58-7"  
class="td11">    <span 
class="ecrm-1000">0.107       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-59-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-59-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.5                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-59-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-59-3"  
class="td11">   <span 
class="ecrm-1000">0.025     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-59-4"  
class="td11">   <span 
class="ecrm-1000">0.033     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-59-5"  
class="td11">  <span 
class="ecrm-1000">0.134   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-59-6"  
class="td11">   <span 
class="ecrm-1000">0.089    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-59-7"  
class="td11">    <span 
class="ecrm-1000">0.128       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-60-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-60-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-60-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-60-3"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-60-4"  
class="td11">   <span 
class="ecrm-1000">0.046     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-60-5"  
class="td11">  <span 
class="ecrm-1000">0.159   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-60-6"  
class="td11">   <span 
class="ecrm-1000">0.106    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-60-7"  
class="td11">    <span 
class="ecrm-1000">0.149       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-61-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-61-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1.2                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-61-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-61-3"  
class="td11">   <span 
class="ecrm-1000">0.040     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-61-4"  
class="td11">   <span 
class="ecrm-1000">0.050     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-61-5"  
class="td11">  <span 
class="ecrm-1000">0.161   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-61-6"  
class="td11">   <span 
class="ecrm-1000">0.106    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-61-7"  
class="td11">    <span 
class="ecrm-1000">0.151       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-62-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-62-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP B32 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-62-2"  
class="td11">    <span 
class="ecrm-1000">1.4M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-62-3"  
class="td11">   <span 
class="ecrm-1000">0.049     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-62-4"  
class="td11">   <span 
class="ecrm-1000">0.053     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-62-5"  
class="td11">  <span 
class="ecrm-1000">0.150   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-62-6"  
class="td11">   <span 
class="ecrm-1000">0.095    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-62-7"  
class="td11">    <span 
class="ecrm-1000">0.147       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-63-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-63-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP L14 score top 30%    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-63-2"  
class="td11">    <span 
class="ecrm-1000">1.4M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-63-3"  
class="td11">   <span 
class="ecrm-1000">0.039     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-63-4"  
class="td11">   <span 
class="ecrm-1000">0.045     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-63-5"  
class="td11">  <span 
class="ecrm-1000">0.162   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-63-6"  
class="td11">   <span 
class="ecrm-1000">0.089    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-63-7"  
class="td11">    <span 
class="ecrm-1000">0.144       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-64-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-64-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP B32 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-64-2"  
class="td11">    <span 
class="ecrm-1000">2.1M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-64-3"  
class="td11">   <span 
class="ecrm-1000">0.052     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-64-4"  
class="td11">   <span 
class="ecrm-1000">0.057     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-64-5"  
class="td11">  <span 
class="ecrm-1000">0.179   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-64-6"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-64-7"  
class="td11">    <span 
class="ecrm-1000">0.166       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-65-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-65-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP L14 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-65-2"  
class="td11">    <span 
class="ecrm-1000">2.1M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-65-3"  
class="td11">   <span 
class="ecrm-1000">0.047     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-65-4"  
class="td11">   <span 
class="ecrm-1000">0.053     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-65-5"  
class="td11">  <span 
class="ecrm-1000">0.176   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-65-6"  
class="td11">   <span 
class="ecrm-1000">0.101    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-65-7"  
class="td11">    <span 
class="ecrm-1000">0.162       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-66-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-66-1"  
class="td11">                                                      </td></tr></table>                                                                            </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 1188--><p class="noindent" >
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 1190--><p class="noindent" ><a 
 id="x1-110017r22"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110018"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;22: </span><span  
class="content">Baseline results for the filtering track, <span 
class="ectt-1000">medium </span>scale.</span></div><!--tex4ht:label?: x1-110017rQ -->
<!--l. 1194--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-25" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-25-1g"><col 
id="TBL-25-1"><col 
id="TBL-25-2"><col 
id="TBL-25-3"><col 
id="TBL-25-4"><col 
id="TBL-25-5"><col 
id="TBL-25-6"><col 
id="TBL-25-7"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-25-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div>                                                                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-2"  
class="td11">  <span 
class="ecrm-1000">Training    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-3"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-4"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-7"  
class="td11"> <span 
class="ecrm-1000">Average over  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-2-1"  
class="td11">                                                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-2"  
class="td11"> <span 
class="ecrm-1000">dataset size  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-3"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-4"  
class="td11"> <span 
class="ecrm-1000">dist. shifts  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-5"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-6"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-7"  
class="td11">  <span 
class="ecrm-1000">38 datasets   </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-25-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-3-1"  
class="td11"> <span 
class="ecrm-1000">No filtering </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-2"  
class="td11"> <span 
class="ecrm-1000">128M </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-3"  
class="td11"> <span 
class="ecrm-1000">0.176 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-4"  
class="td11"> <span 
class="ecrm-1000">0.152 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-5"  
class="td11"> <span 
class="ecrm-1000">0.259 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-6"  
class="td11"> <span 
class="ecrm-1000">0.174 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-7"  
class="td11"> <span 
class="ecrm-1000">0.254</span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-4-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (75%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-4-2"  
class="td11">   <span 
class="ecrm-1000">96.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-4-3"  
class="td11">   <span 
class="ecrm-1000">0.175     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-4-4"  
class="td11">   <span 
class="ecrm-1000">0.154     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-4-5"  
class="td11">  <span 
class="ecrm-1000">0.265   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-4-6"  
class="td11">   <span 
class="ecrm-1000">0.174    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-4-7"  
class="td11">    <span 
class="ecrm-1000">0.254       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-5-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (50%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-5-2"  
class="td11">   <span 
class="ecrm-1000">64.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-5-3"  
class="td11">   <span 
class="ecrm-1000">0.171     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-5-4"  
class="td11">   <span 
class="ecrm-1000">0.151     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-5-5"  
class="td11">  <span 
class="ecrm-1000">0.258   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-5-6"  
class="td11">   <span 
class="ecrm-1000">0.170    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-5-7"  
class="td11">    <span 
class="ecrm-1000">0.249       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-6-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (25%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-6-2"  
class="td11">   <span 
class="ecrm-1000">32.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-6-3"  
class="td11">   <span 
class="ecrm-1000">0.155     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-6-4"  
class="td11">   <span 
class="ecrm-1000">0.136     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-6-5"  
class="td11">  <span 
class="ecrm-1000">0.246   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-6-6"  
class="td11">   <span 
class="ecrm-1000">0.162    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-6-7"  
class="td11">    <span 
class="ecrm-1000">0.237       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-7-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (10%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-7-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-7-3"  
class="td11">   <span 
class="ecrm-1000">0.107     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-7-4"  
class="td11">   <span 
class="ecrm-1000">0.095     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-7-5"  
class="td11">  <span 
class="ecrm-1000">0.210   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-7-6"  
class="td11">   <span 
class="ecrm-1000">0.121    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-7-7"  
class="td11">    <span 
class="ecrm-1000">0.198       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-8-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (1%)                                                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-8-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-8-3"  
class="td11">   <span 
class="ecrm-1000">0.009     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-8-4"  
class="td11">   <span 
class="ecrm-1000">0.017     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-8-5"  
class="td11">  <span 
class="ecrm-1000">0.102   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-8-6"  
class="td11">   <span 
class="ecrm-1000">0.064    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-8-7"  
class="td11">    <span 
class="ecrm-1000">0.090       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-9-1"  
class="td11"> <span 
class="ecrm-1000">Caption length                                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-9-2"  
class="td11">   <span 
class="ecrm-1000">87.5M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-9-3"  
class="td11">   <span 
class="ecrm-1000">0.199     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-9-4"  
class="td11">   <span 
class="ecrm-1000">0.172     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-9-5"  
class="td11">  <span 
class="ecrm-1000">0.275   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-9-6"  
class="td11">   <span 
class="ecrm-1000">0.182    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-9-7"  
class="td11">    <span 
class="ecrm-1000">0.271       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-10-1"  
class="td11"> <span 
class="ecrm-1000">Image size                                                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-10-2"  
class="td11">   <span 
class="ecrm-1000">77.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-10-3"  
class="td11">   <span 
class="ecrm-1000">0.189     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-10-4"  
class="td11">   <span 
class="ecrm-1000">0.163     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-10-5"  
class="td11">  <span 
class="ecrm-1000">0.248   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-10-6"  
class="td11">   <span 
class="ecrm-1000">0.182    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-10-7"  
class="td11">    <span 
class="ecrm-1000">0.255       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-11-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext)                                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-11-2"  
class="td11">   <span 
class="ecrm-1000">63.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-11-3"  
class="td11">   <span 
class="ecrm-1000">0.214     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-11-4"  
class="td11">   <span 
class="ecrm-1000">0.182     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-11-5"  
class="td11">  <span 
class="ecrm-1000">0.290   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-11-6"  
class="td11">   <span 
class="ecrm-1000">0.188    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-11-7"  
class="td11">    <span 
class="ecrm-1000">0.280       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-12-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext) and caption length                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-12-2"  
class="td11">   <span 
class="ecrm-1000">47.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-12-3"  
class="td11">   <span 
class="ecrm-1000">0.226     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-12-4"  
class="td11">   <span 
class="ecrm-1000">0.193     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-12-5"  
class="td11">  <span 
class="ecrm-1000">0.297   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-12-6"  
class="td11">   <span 
class="ecrm-1000">0.192    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-12-7"  
class="td11">    <span 
class="ecrm-1000">0.289       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-13-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext), caption length, and image size                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-13-2"  
class="td11">   <span 
class="ecrm-1000">29.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-13-3"  
class="td11">   <span 
class="ecrm-1000">0.226     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-13-4"  
class="td11">   <span 
class="ecrm-1000">0.193     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-13-5"  
class="td11">  <span 
class="ecrm-1000">0.284   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-13-6"  
class="td11">   <span 
class="ecrm-1000">0.192    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-13-7"  
class="td11">    <span 
class="ecrm-1000">0.280       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-14-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3)                                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-14-2"  
class="td11">   <span 
class="ecrm-1000">25.6M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-14-3"  
class="td11">   <span 
class="ecrm-1000">0.200     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-14-4"  
class="td11">   <span 
class="ecrm-1000">0.175     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-14-5"  
class="td11">  <span 
class="ecrm-1000">0.296   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-14-6"  
class="td11">   <span 
class="ecrm-1000">0.181    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-14-7"  
class="td11">    <span 
class="ecrm-1000">0.275       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-15-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3) and caption length                                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-15-2"  
class="td11">   <span 
class="ecrm-1000">22.9M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-15-3"  
class="td11">   <span 
class="ecrm-1000">0.204     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-15-4"  
class="td11">   <span 
class="ecrm-1000">0.175     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-15-5"  
class="td11">  <span 
class="ecrm-1000">0.287   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-15-6"  
class="td11">   <span 
class="ecrm-1000">0.181    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-15-7"  
class="td11">    <span 
class="ecrm-1000">0.273       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-16-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3), caption length, and image size                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-16-2"  
class="td11">   <span 
class="ecrm-1000">14.6M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-16-3"  
class="td11">   <span 
class="ecrm-1000">0.179     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-16-4"  
class="td11">   <span 
class="ecrm-1000">0.159     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-16-5"  
class="td11">  <span 
class="ecrm-1000">0.243   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-16-6"  
class="td11">   <span 
class="ecrm-1000">0.167    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-16-7"  
class="td11">    <span 
class="ecrm-1000">0.243       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-17-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 1%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-17-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-17-3"  
class="td11">   <span 
class="ecrm-1000">0.025     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-17-4"  
class="td11">   <span 
class="ecrm-1000">0.037     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-17-5"  
class="td11">  <span 
class="ecrm-1000">0.140   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-17-6"  
class="td11">   <span 
class="ecrm-1000">0.072    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-17-7"  
class="td11">    <span 
class="ecrm-1000">0.125       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-18-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 3%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-18-2"  
class="td11">    <span 
class="ecrm-1000">3.9M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-18-3"  
class="td11">   <span 
class="ecrm-1000">0.093     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-18-4"  
class="td11">   <span 
class="ecrm-1000">0.096     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-18-5"  
class="td11">  <span 
class="ecrm-1000">0.205   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-18-6"  
class="td11">   <span 
class="ecrm-1000">0.103    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-18-7"  
class="td11">    <span 
class="ecrm-1000">0.186       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-19-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 10%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-19-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-19-3"  
class="td11">   <span 
class="ecrm-1000">0.231     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-19-4"  
class="td11">   <span 
class="ecrm-1000">0.199     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-19-5"  
class="td11">  <span 
class="ecrm-1000">0.305   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-19-6"  
class="td11">   <span 
class="ecrm-1000">0.152    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-19-7"  
class="td11">    <span 
class="ecrm-1000">0.294       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-20-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 20%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-20-2"  
class="td11">   <span 
class="ecrm-1000">25.7M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-20-3"  
class="td11">   <span 
class="ecrm-1000">0.279     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-20-4"  
class="td11">   <span 
class="ecrm-1000">0.234     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-20-5"  
class="td11">  <span 
class="ecrm-1000">0.337   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-20-6"  
class="td11">   <span 
class="ecrm-1000">0.178    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-20-7"  
class="td11">    <span 
class="ecrm-1000">0.325       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-21-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 30%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-21-2"  
class="td11">   <span 
class="ecrm-1000">38.4M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-21-3"  
class="td11">   <span 
class="ecrm-1000">0.285     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-21-4"  
class="td11">   <span 
class="ecrm-1000">0.240     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-21-5"  
class="td11">  <span 
class="ecrm-1000">0.355   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-21-6"  
class="td11">   <span 
class="ecrm-1000">0.187    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-21-7"  
class="td11">    <span 
class="ecrm-1000">0.333       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-22-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 40%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-22-2"  
class="td11">   <span 
class="ecrm-1000">51.3M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-22-3"  
class="td11">   <span 
class="ecrm-1000">0.273     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-22-4"  
class="td11">   <span 
class="ecrm-1000">0.227     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-22-5"  
class="td11">  <span 
class="ecrm-1000">0.333   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-22-6"  
class="td11">   <span 
class="ecrm-1000">0.193    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-22-7"  
class="td11">    <span 
class="ecrm-1000">0.318       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-23-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 50%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-23-2"  
class="td11">   <span 
class="ecrm-1000">64.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-23-3"  
class="td11">   <span 
class="ecrm-1000">0.256     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-23-4"  
class="td11">   <span 
class="ecrm-1000">0.219     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-23-5"  
class="td11">  <span 
class="ecrm-1000">0.322   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-23-6"  
class="td11">   <span 
class="ecrm-1000">0.196    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-23-7"  
class="td11">    <span 
class="ecrm-1000">0.311       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-24-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 75%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-24-2"  
class="td11">   <span 
class="ecrm-1000">96.1M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-24-3"  
class="td11">   <span 
class="ecrm-1000">0.211     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-24-4"  
class="td11">   <span 
class="ecrm-1000">0.180     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-24-5"  
class="td11">  <span 
class="ecrm-1000">0.301   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-24-6"  
class="td11">   <span 
class="ecrm-1000">0.185    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-24-7"  
class="td11">    <span 
class="ecrm-1000">0.285       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-25-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-25-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 90%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-25-2"  
class="td11">    <span 
class="ecrm-1000">115M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-25-3"  
class="td11">   <span 
class="ecrm-1000">0.189     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-25-4"  
class="td11">   <span 
class="ecrm-1000">0.165     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-25-5"  
class="td11">  <span 
class="ecrm-1000">0.279   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-25-6"  
class="td11">   <span 
class="ecrm-1000">0.178    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-25-7"  
class="td11">    <span 
class="ecrm-1000">0.270       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-26-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-26-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3 + English filter                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-26-2"  
class="td11">    <span 
class="ecrm-1000">9.4M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-26-3"  
class="td11">   <span 
class="ecrm-1000">0.208     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-26-4"  
class="td11">   <span 
class="ecrm-1000">0.184     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-26-5"  
class="td11">  <span 
class="ecrm-1000">0.292   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-26-6"  
class="td11">   <span 
class="ecrm-1000">0.156    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-26-7"  
class="td11">    <span 
class="ecrm-1000">0.272       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-27-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-27-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.28 + English filter                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-27-2"  
class="td11">   <span 
class="ecrm-1000">13.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-27-3"  
class="td11">   <span 
class="ecrm-1000">0.230     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-27-4"  
class="td11">   <span 
class="ecrm-1000">0.198     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-27-5"  
class="td11">  <span 
class="ecrm-1000">0.307   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-27-6"  
class="td11">   <span 
class="ecrm-1000">0.170    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-27-7"  
class="td11">    <span 
class="ecrm-1000">0.287       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-28-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-28-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3                                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-28-2"  
class="td11">   <span 
class="ecrm-1000">25.9M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-28-3"  
class="td11">   <span 
class="ecrm-1000">0.282     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-28-4"  
class="td11">   <span 
class="ecrm-1000">0.233     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-28-5"  
class="td11">  <span 
class="ecrm-1000">0.340   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-28-6"  
class="td11">   <span 
class="ecrm-1000">0.178    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-28-7"  
class="td11">    <span 
class="ecrm-1000">0.327       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-29-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-29-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score 1% to 30%                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-29-2"  
class="td11">   <span 
class="ecrm-1000">37.1M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-29-3"  
class="td11">   <span 
class="ecrm-1000">0.287     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-29-4"  
class="td11">   <span 
class="ecrm-1000">0.238     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-29-5"  
class="td11">  <span 
class="ecrm-1000">0.347   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-29-6"  
class="td11">   <span 
class="ecrm-1000">0.187    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-29-7"  
class="td11">    <span 
class="ecrm-1000">0.329       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-30-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-30-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score 2% to 30%                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-30-2"  
class="td11">   <span 
class="ecrm-1000">35.9M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-30-3"  
class="td11">   <span 
class="ecrm-1000">0.288     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-30-4"  
class="td11">   <span 
class="ecrm-1000">0.238     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-30-5"  
class="td11">  <span 
class="ecrm-1000">0.338   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-30-6"  
class="td11">   <span 
class="ecrm-1000">0.184    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-30-7"  
class="td11">    <span 
class="ecrm-1000">0.325       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-31-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-31-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score 5% to 30%                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-31-2"  
class="td11">   <span 
class="ecrm-1000">32.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-31-3"  
class="td11">   <span 
class="ecrm-1000">0.281     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-31-4"  
class="td11">   <span 
class="ecrm-1000">0.230     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-31-5"  
class="td11">  <span 
class="ecrm-1000">0.352   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-31-6"  
class="td11">   <span 
class="ecrm-1000">0.187    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-31-7"  
class="td11">    <span 
class="ecrm-1000">0.334       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-32-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-32-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 1%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-32-2"  
class="td11">    <span 
class="ecrm-1000">1.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-32-3"  
class="td11">   <span 
class="ecrm-1000">0.014     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-32-4"  
class="td11">   <span 
class="ecrm-1000">0.025     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-32-5"  
class="td11">  <span 
class="ecrm-1000">0.136   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-32-6"  
class="td11">   <span 
class="ecrm-1000">0.059    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-32-7"  
class="td11">    <span 
class="ecrm-1000">0.109       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-33-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-33-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 3%                                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-33-2"  
class="td11">    <span 
class="ecrm-1000">3.9M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-33-3"  
class="td11">   <span 
class="ecrm-1000">0.065     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-33-4"  
class="td11">   <span 
class="ecrm-1000">0.077     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-33-5"  
class="td11">  <span 
class="ecrm-1000">0.176   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-33-6"  
class="td11">   <span 
class="ecrm-1000">0.088    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-33-7"  
class="td11">    <span 
class="ecrm-1000">0.158       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-34-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-34-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 10%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-34-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-34-3"  
class="td11">   <span 
class="ecrm-1000">0.198     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-34-4"  
class="td11">   <span 
class="ecrm-1000">0.183     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-34-5"  
class="td11">  <span 
class="ecrm-1000">0.283   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-34-6"  
class="td11">   <span 
class="ecrm-1000">0.142    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-34-7"  
class="td11">    <span 
class="ecrm-1000">0.274       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-35-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-35-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 20%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-35-2"  
class="td11">   <span 
class="ecrm-1000">25.7M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-35-3"  
class="td11">   <span 
class="ecrm-1000">0.260     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-35-4"  
class="td11">   <span 
class="ecrm-1000">0.225     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-35-5"  
class="td11">  <span 
class="ecrm-1000">0.326   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-35-6"  
class="td11">   <span 
class="ecrm-1000">0.173    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-35-7"  
class="td11">    <span 
class="ecrm-1000">0.317       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-36-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-36-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 30%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-36-2"  
class="td11">   <span 
class="ecrm-1000">38.4M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-36-3"  
class="td11">   <span 
class="ecrm-1000">0.273     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-36-4"  
class="td11">   <span 
class="ecrm-1000">0.230     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-36-5"  
class="td11">  <span 
class="ecrm-1000">0.338   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-36-6"  
class="td11">   <span 
class="ecrm-1000">0.183    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-36-7"  
class="td11">    <span 
class="ecrm-1000">0.323       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-37-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-37-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 40%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-37-2"  
class="td11">   <span 
class="ecrm-1000">51.2M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-37-3"  
class="td11">   <span 
class="ecrm-1000">0.262     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-37-4"  
class="td11">   <span 
class="ecrm-1000">0.226     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-37-5"  
class="td11">  <span 
class="ecrm-1000">0.330   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-37-6"  
class="td11">   <span 
class="ecrm-1000">0.192    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-37-7"  
class="td11">    <span 
class="ecrm-1000">0.322       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-38-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-38-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 50%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-38-2"  
class="td11">   <span 
class="ecrm-1000">64.1M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-38-3"  
class="td11">   <span 
class="ecrm-1000">0.254     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-38-4"  
class="td11">   <span 
class="ecrm-1000">0.218     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-38-5"  
class="td11">  <span 
class="ecrm-1000">0.322   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-38-6"  
class="td11">   <span 
class="ecrm-1000">0.199    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-38-7"  
class="td11">    <span 
class="ecrm-1000">0.310       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-39-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-39-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 75%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-39-2"  
class="td11">   <span 
class="ecrm-1000">96.1M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-39-3"  
class="td11">   <span 
class="ecrm-1000">0.212     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-39-4"  
class="td11">   <span 
class="ecrm-1000">0.180     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-39-5"  
class="td11">  <span 
class="ecrm-1000">0.287   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-39-6"  
class="td11">   <span 
class="ecrm-1000">0.190    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-39-7"  
class="td11">    <span 
class="ecrm-1000">0.281       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-40-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-40-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 90%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-40-2"  
class="td11">    <span 
class="ecrm-1000">115M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-40-3"  
class="td11">   <span 
class="ecrm-1000">0.188     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-40-4"  
class="td11">   <span 
class="ecrm-1000">0.164     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-40-5"  
class="td11">  <span 
class="ecrm-1000">0.258   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-40-6"  
class="td11">   <span 
class="ecrm-1000">0.178    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-40-7"  
class="td11">    <span 
class="ecrm-1000">0.262       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-41-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-41-1"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet1k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-41-2"  
class="td11">   <span 
class="ecrm-1000">29.2M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-41-3"  
class="td11">   <span 
class="ecrm-1000">0.268     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-41-4"  
class="td11">   <span 
class="ecrm-1000">0.213     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-41-5"  
class="td11">  <span 
class="ecrm-1000">0.319   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-41-6"  
class="td11">   <span 
class="ecrm-1000">0.193    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-41-7"  
class="td11">    <span 
class="ecrm-1000">0.307       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-42-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-42-1"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet21k)                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-42-2"  
class="td11">   <span 
class="ecrm-1000">45.1M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-42-3"  
class="td11">   <span 
class="ecrm-1000">0.238     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-42-4"  
class="td11">   <span 
class="ecrm-1000">0.198     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-42-5"  
class="td11">  <span 
class="ecrm-1000">0.304   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-42-6"  
class="td11">   <span 
class="ecrm-1000">0.193    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-42-7"  
class="td11">    <span 
class="ecrm-1000">0.292       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-43-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-43-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-43-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-43-3"  
class="td11">   <span 
class="ecrm-1000">0.170     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-43-4"  
class="td11">   <span 
class="ecrm-1000">0.150     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-43-5"  
class="td11">  <span 
class="ecrm-1000">0.266   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-43-6"  
class="td11">   <span 
class="ecrm-1000">0.162    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-43-7"  
class="td11">    <span 
class="ecrm-1000">0.250       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-44-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-44-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.2                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-44-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-44-3"  
class="td11">   <span 
class="ecrm-1000">0.249     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-44-4"  
class="td11">   <span 
class="ecrm-1000">0.193     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-44-5"  
class="td11">  <span 
class="ecrm-1000">0.292   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-44-6"  
class="td11">   <span 
class="ecrm-1000">0.168    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-44-7"  
class="td11">    <span 
class="ecrm-1000">0.280       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-45-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-45-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.5                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-45-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-45-3"  
class="td11">   <span 
class="ecrm-1000">0.269     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-45-4"  
class="td11">   <span 
class="ecrm-1000">0.196     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-45-5"  
class="td11">  <span 
class="ecrm-1000">0.301   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-45-6"  
class="td11">   <span 
class="ecrm-1000">0.163    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-45-7"  
class="td11">    <span 
class="ecrm-1000">0.280       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-46-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-46-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-46-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-46-3"  
class="td11">   <span 
class="ecrm-1000">0.207     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-46-4"  
class="td11">   <span 
class="ecrm-1000">0.145     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-46-5"  
class="td11">  <span 
class="ecrm-1000">0.264   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-46-6"  
class="td11">   <span 
class="ecrm-1000">0.130    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-46-7"  
class="td11">    <span 
class="ecrm-1000">0.236       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-47-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-47-1"  
class="td11"> <span 
class="ecrm-1000">Image-based sampling, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=2                                               </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-47-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-47-3"  
class="td11">   <span 
class="ecrm-1000">0.118     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-47-4"  
class="td11">   <span 
class="ecrm-1000">0.082     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-47-5"  
class="td11">  <span 
class="ecrm-1000">0.207   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-47-6"  
class="td11">   <span 
class="ecrm-1000">0.094    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-47-7"  
class="td11">    <span 
class="ecrm-1000">0.179       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-48-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-48-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L14, top 30%) and English                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-48-2"  
class="td11">   <span 
class="ecrm-1000">19.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-48-3"  
class="td11">   <span 
class="ecrm-1000">0.212     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-48-4"  
class="td11">   <span 
class="ecrm-1000">0.158     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-48-5"  
class="td11">  <span 
class="ecrm-1000">0.272   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-48-6"  
class="td11">   <span 
class="ecrm-1000">0.148    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-48-7"  
class="td11">    <span 
class="ecrm-1000">0.257       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-49-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-49-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L/14, top 20%)                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-49-2"  
class="td11">   <span 
class="ecrm-1000">25.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-49-3"  
class="td11">   <span 
class="ecrm-1000">0.193     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-49-4"  
class="td11">   <span 
class="ecrm-1000">0.138     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-49-5"  
class="td11">  <span 
class="ecrm-1000">0.276   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-49-6"  
class="td11">   <span 
class="ecrm-1000">0.149    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-49-7"  
class="td11">    <span 
class="ecrm-1000">0.250       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-50-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-50-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L/14, top 30%)                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-50-2"  
class="td11">   <span 
class="ecrm-1000">38.5M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-50-3"  
class="td11">   <span 
class="ecrm-1000">0.212     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-50-4"  
class="td11">   <span 
class="ecrm-1000">0.159     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-50-5"  
class="td11">  <span 
class="ecrm-1000">0.283   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-50-6"  
class="td11">   <span 
class="ecrm-1000">0.165    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-50-7"  
class="td11">    <span 
class="ecrm-1000">0.266       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-51-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-51-1"  
class="td11"> <span 
class="ecrm-1000">ImageNet distance (L/14, top 40%)                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-51-2"  
class="td11">   <span 
class="ecrm-1000">51.3M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-51-3"  
class="td11">   <span 
class="ecrm-1000">0.212     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-51-4"  
class="td11">   <span 
class="ecrm-1000">0.165     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-51-5"  
class="td11">  <span 
class="ecrm-1000">0.273   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-51-6"  
class="td11">   <span 
class="ecrm-1000">0.171    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-51-7"  
class="td11">    <span 
class="ecrm-1000">0.267       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-52-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-52-1"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet1k)                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-52-2"  
class="td11">    <span 
class="ecrm-1000">4.3M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-52-3"  
class="td11">   <span 
class="ecrm-1000">0.099     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-52-4"  
class="td11">   <span 
class="ecrm-1000">0.090     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-52-5"  
class="td11">  <span 
class="ecrm-1000">0.173   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-52-6"  
class="td11">   <span 
class="ecrm-1000">0.095    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-52-7"  
class="td11">    <span 
class="ecrm-1000">0.165       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-53-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-53-1"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet21k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-53-2"  
class="td11">   <span 
class="ecrm-1000">31.7M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-53-3"  
class="td11">   <span 
class="ecrm-1000">0.255     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-53-4"  
class="td11">   <span 
class="ecrm-1000">0.215     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-53-5"  
class="td11">  <span 
class="ecrm-1000">0.328   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-53-6"  
class="td11">   <span 
class="ecrm-1000">0.183    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-53-7"  
class="td11">    <span 
class="ecrm-1000">0.301       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-54-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-54-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-54-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-54-3"  
class="td11">   <span 
class="ecrm-1000">0.136     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-54-4"  
class="td11">   <span 
class="ecrm-1000">0.110     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-54-5"  
class="td11">  <span 
class="ecrm-1000">0.213   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-54-6"  
class="td11">   <span 
class="ecrm-1000">0.114    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-54-7"  
class="td11">    <span 
class="ecrm-1000">0.207       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-55-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-55-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.5                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-55-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-55-3"  
class="td11">   <span 
class="ecrm-1000">0.222     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-55-4"  
class="td11">   <span 
class="ecrm-1000">0.178     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-55-5"  
class="td11">  <span 
class="ecrm-1000">0.273   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-55-6"  
class="td11">   <span 
class="ecrm-1000">0.157    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-55-7"  
class="td11">    <span 
class="ecrm-1000">0.265       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-56-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-56-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-56-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-56-3"  
class="td11">   <span 
class="ecrm-1000">0.245     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-56-4"  
class="td11">   <span 
class="ecrm-1000">0.204     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-56-5"  
class="td11">  <span 
class="ecrm-1000">0.302   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-56-6"  
class="td11">   <span 
class="ecrm-1000">0.189    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-56-7"  
class="td11">    <span 
class="ecrm-1000">0.289       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-57-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-57-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with average score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1.2                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-57-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-57-3"  
class="td11">   <span 
class="ecrm-1000">0.231     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-57-4"  
class="td11">   <span 
class="ecrm-1000">0.200     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-57-5"  
class="td11">  <span 
class="ecrm-1000">0.298   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-57-6"  
class="td11">   <span 
class="ecrm-1000">0.182    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-57-7"  
class="td11">    <span 
class="ecrm-1000">0.284       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-58-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-58-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-58-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-58-3"  
class="td11">   <span 
class="ecrm-1000">0.140     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-58-4"  
class="td11">   <span 
class="ecrm-1000">0.116     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-58-5"  
class="td11">  <span 
class="ecrm-1000">0.242   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-58-6"  
class="td11">   <span 
class="ecrm-1000">0.114    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-58-7"  
class="td11">    <span 
class="ecrm-1000">0.223       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-59-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-59-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=0.5                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-59-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-59-3"  
class="td11">   <span 
class="ecrm-1000">0.229     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-59-4"  
class="td11">   <span 
class="ecrm-1000">0.190     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-59-5"  
class="td11">  <span 
class="ecrm-1000">0.290   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-59-6"  
class="td11">   <span 
class="ecrm-1000">0.155    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-59-7"  
class="td11">    <span 
class="ecrm-1000">0.279       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-60-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-60-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-60-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-60-3"  
class="td11">   <span 
class="ecrm-1000">0.247     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-60-4"  
class="td11">   <span 
class="ecrm-1000">0.209     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-60-5"  
class="td11">  <span 
class="ecrm-1000">0.300   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-60-6"  
class="td11">   <span 
class="ecrm-1000">0.183    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-60-7"  
class="td11">    <span 
class="ecrm-1000">0.290       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-61-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-61-1"  
class="td11"> <span 
class="ecrm-1000">Text-based sampling with max score, </span><span 
class="cmmi-10">&#x03B1;</span><span 
class="ecrm-1000">=1.2                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-61-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-61-3"  
class="td11">   <span 
class="ecrm-1000">0.235     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-61-4"  
class="td11">   <span 
class="ecrm-1000">0.200     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-61-5"  
class="td11">  <span 
class="ecrm-1000">0.298   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-61-6"  
class="td11">   <span 
class="ecrm-1000">0.178    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-61-7"  
class="td11">    <span 
class="ecrm-1000">0.285       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-62-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-62-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP B32 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-62-2"  
class="td11">   <span 
class="ecrm-1000">14.2M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-62-3"  
class="td11">   <span 
class="ecrm-1000">0.305     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-62-4"  
class="td11">   <span 
class="ecrm-1000">0.243     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-62-5"  
class="td11">  <span 
class="ecrm-1000">0.342   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-62-6"  
class="td11">   <span 
class="ecrm-1000">0.182    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-62-7"  
class="td11">    <span 
class="ecrm-1000">0.322       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-63-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-63-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP L14 score top 30%    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-63-2"  
class="td11">   <span 
class="ecrm-1000">14.0M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-63-3"  
class="td11">   <span 
class="ecrm-1000">0.297     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-63-4"  
class="td11">   <span 
class="ecrm-1000">0.239     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-63-5"  
class="td11">  <span 
class="ecrm-1000">0.346   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-63-6"  
class="td11">   <span 
class="ecrm-1000">0.170    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-63-7"  
class="td11">    <span 
class="ecrm-1000">0.323       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-64-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-64-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP B32 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-64-2"  
class="td11">   <span 
class="ecrm-1000">21.1M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-64-3"  
class="td11">   <span 
class="ecrm-1000">0.298     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-64-4"  
class="td11">   <span 
class="ecrm-1000">0.244     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-64-5"  
class="td11">  <span 
class="ecrm-1000">0.347   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-64-6"  
class="td11">   <span 
class="ecrm-1000">0.184    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-64-7"  
class="td11">    <span 
class="ecrm-1000">0.330       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-65-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-65-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP L14 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-65-2"  
class="td11">   <span 
class="ecrm-1000">20.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-65-3"  
class="td11">   <span 
class="ecrm-1000">0.290     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-65-4"  
class="td11">   <span 
class="ecrm-1000">0.241     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-65-5"  
class="td11">  <span 
class="ecrm-1000">0.339   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-65-6"  
class="td11">   <span 
class="ecrm-1000">0.182    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-65-7"  
class="td11">    <span 
class="ecrm-1000">0.323       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-66-"><td  style="white-space:nowrap; text-align:left;" id="TBL-25-66-1"  
class="td11">                                                      </td></tr></table>                                                                            </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
<!--l. 1266--><p class="noindent" >
                                                                                         
                                                                                         
                                                                                         
                                                                                         
<!--l. 1268--><p class="noindent" ><a 
 id="x1-110019r23"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110020"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;23: </span><span  
class="content">Baseline results for the filtering track, <span 
class="ectt-1000">large </span>scale.</span></div><!--tex4ht:label?: x1-110019rQ -->
<!--l. 1272--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-26" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-26-1g"><col 
id="TBL-26-1"><col 
id="TBL-26-2"><col 
id="TBL-26-3"><col 
id="TBL-26-4"><col 
id="TBL-26-5"><col 
id="TBL-26-6"><col 
id="TBL-26-7"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-26-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div>                                                                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-2"  
class="td11">  <span 
class="ecrm-1000">Training    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-3"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-4"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-7"  
class="td11"> <span 
class="ecrm-1000">Average over  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-2-1"  
class="td11">                                                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-2"  
class="td11"> <span 
class="ecrm-1000">dataset size  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-3"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-4"  
class="td11"> <span 
class="ecrm-1000">dist. shifts  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-5"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-6"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-7"  
class="td11">  <span 
class="ecrm-1000">38 datasets   </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-26-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-3-1"  
class="td11"> <span 
class="ecrm-1000">No filtering </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-26-3-2"  
class="td11"> <span 
class="ecrm-1000">1.28B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-26-3-3"  
class="td11"> <span 
class="ecrm-1000">0.459 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-26-3-4"  
class="td11"> <span 
class="ecrm-1000">0.378 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-26-3-5"  
class="td11"> <span 
class="ecrm-1000">0.426 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-26-3-6"  
class="td11"> <span 
class="ecrm-1000">0.305 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-26-3-7"  
class="td11"> <span 
class="ecrm-1000">0.428</span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-4-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (75%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-4-2"  
class="td11">    <span 
class="ecrm-1000">960M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-4-3"  
class="td11">   <span 
class="ecrm-1000">0.456     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-4-4"  
class="td11">   <span 
class="ecrm-1000">0.379     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-4-5"  
class="td11">  <span 
class="ecrm-1000">0.435   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-4-6"  
class="td11">   <span 
class="ecrm-1000">0.302    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-4-7"  
class="td11">    <span 
class="ecrm-1000">0.434       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-5-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (50%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-5-2"  
class="td11">    <span 
class="ecrm-1000">640M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-5-3"  
class="td11">   <span 
class="ecrm-1000">0.453     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-5-4"  
class="td11">   <span 
class="ecrm-1000">0.377     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-5-5"  
class="td11">  <span 
class="ecrm-1000">0.427   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-5-6"  
class="td11">   <span 
class="ecrm-1000">0.298    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-5-7"  
class="td11">    <span 
class="ecrm-1000">0.424       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-6-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (25%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-6-2"  
class="td11">    <span 
class="ecrm-1000">320M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-6-3"  
class="td11">   <span 
class="ecrm-1000">0.447     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-6-4"  
class="td11">   <span 
class="ecrm-1000">0.373     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-6-5"  
class="td11">  <span 
class="ecrm-1000">0.424   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-6-6"  
class="td11">   <span 
class="ecrm-1000">0.294    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-6-7"  
class="td11">    <span 
class="ecrm-1000">0.425       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-7-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (10%)                                                       </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-7-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-7-3"  
class="td11">   <span 
class="ecrm-1000">0.426     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-7-4"  
class="td11">   <span 
class="ecrm-1000">0.350     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-7-5"  
class="td11">  <span 
class="ecrm-1000">0.417   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-7-6"  
class="td11">   <span 
class="ecrm-1000">0.286    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-7-7"  
class="td11">    <span 
class="ecrm-1000">0.414       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-8-1"  
class="td11"> <span 
class="ecrm-1000">Random subset (1%)                                                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-8-2"  
class="td11">   <span 
class="ecrm-1000">12.8M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-8-3"  
class="td11">   <span 
class="ecrm-1000">0.135     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-8-4"  
class="td11">   <span 
class="ecrm-1000">0.118     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-8-5"  
class="td11">  <span 
class="ecrm-1000">0.219   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-8-6"  
class="td11">   <span 
class="ecrm-1000">0.105    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-8-7"  
class="td11">    <span 
class="ecrm-1000">0.216       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-9-1"  
class="td11"> <span 
class="ecrm-1000">Caption length                                                                </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-9-2"  
class="td11">    <span 
class="ecrm-1000">874M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-9-3"  
class="td11">   <span 
class="ecrm-1000">0.474     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-9-4"  
class="td11">   <span 
class="ecrm-1000">0.392     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-9-5"  
class="td11">  <span 
class="ecrm-1000">0.438   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-9-6"  
class="td11">   <span 
class="ecrm-1000">0.322    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-9-7"  
class="td11">    <span 
class="ecrm-1000">0.435       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-10-1"  
class="td11"> <span 
class="ecrm-1000">Image size                                                                      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-10-2"  
class="td11">    <span 
class="ecrm-1000">777M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-10-3"  
class="td11">   <span 
class="ecrm-1000">0.466     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-10-4"  
class="td11">   <span 
class="ecrm-1000">0.375     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-10-5"  
class="td11">  <span 
class="ecrm-1000">0.421   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-10-6"  
class="td11">   <span 
class="ecrm-1000">0.316    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-10-7"  
class="td11">    <span 
class="ecrm-1000">0.419       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-11-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext)                                                             </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-11-2"  
class="td11">    <span 
class="ecrm-1000">630M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-11-3"  
class="td11">   <span 
class="ecrm-1000">0.500     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-11-4"  
class="td11">   <span 
class="ecrm-1000">0.414     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-11-5"  
class="td11">  <span 
class="ecrm-1000">0.449   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-11-6"  
class="td11">   <span 
class="ecrm-1000">0.337    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-11-7"  
class="td11">    <span 
class="ecrm-1000">0.452       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-12-1"  
class="td11"> <span 
class="ecrm-1000">English (fasttext), caption length, and image size                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-12-2"  
class="td11">    <span 
class="ecrm-1000">298M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-12-3"  
class="td11">   <span 
class="ecrm-1000">0.516     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-12-4"  
class="td11">   <span 
class="ecrm-1000">0.423     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-12-5"  
class="td11">  <span 
class="ecrm-1000">0.446   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-12-6"  
class="td11">   <span 
class="ecrm-1000">0.353    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-12-7"  
class="td11">    <span 
class="ecrm-1000">0.448       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-13-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-13-1"  
class="td11"> <span 
class="ecrm-1000">English (cld3)                                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-13-2"  
class="td11">    <span 
class="ecrm-1000">256M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-13-3"  
class="td11">   <span 
class="ecrm-1000">0.486     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-13-4"  
class="td11">   <span 
class="ecrm-1000">0.405     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-13-5"  
class="td11">  <span 
class="ecrm-1000">0.462   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-13-6"  
class="td11">   <span 
class="ecrm-1000">0.343    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-13-7"  
class="td11">    <span 
class="ecrm-1000">0.448       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-14-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-14-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 10%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-14-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-14-3"  
class="td11">   <span 
class="ecrm-1000">0.543     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-14-4"  
class="td11">   <span 
class="ecrm-1000">0.440     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-14-5"  
class="td11">  <span 
class="ecrm-1000">0.471   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-14-6"  
class="td11">   <span 
class="ecrm-1000">0.307    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-14-7"  
class="td11">    <span 
class="ecrm-1000">0.473       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-15-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-15-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 20%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-15-2"  
class="td11">    <span 
class="ecrm-1000">257M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-15-3"  
class="td11">   <span 
class="ecrm-1000">0.578     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-15-4"  
class="td11">   <span 
class="ecrm-1000">0.465     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-15-5"  
class="td11">  <span 
class="ecrm-1000">0.516   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-15-6"  
class="td11">   <span 
class="ecrm-1000">0.338    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-15-7"  
class="td11">    <span 
class="ecrm-1000">0.505       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-16-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-16-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 30%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-16-2"  
class="td11">    <span 
class="ecrm-1000">384M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-16-3"  
class="td11">   <span 
class="ecrm-1000">0.578     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-16-4"  
class="td11">   <span 
class="ecrm-1000">0.466     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-16-5"  
class="td11">  <span 
class="ecrm-1000">0.525   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-16-6"  
class="td11">   <span 
class="ecrm-1000">0.349    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-16-7"  
class="td11">    <span 
class="ecrm-1000">0.517       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-17-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-17-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 40%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-17-2"  
class="td11">    <span 
class="ecrm-1000">512M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-17-3"  
class="td11">   <span 
class="ecrm-1000">0.560     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-17-4"  
class="td11">   <span 
class="ecrm-1000">0.454     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-17-5"  
class="td11">  <span 
class="ecrm-1000">0.512   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-17-6"  
class="td11">   <span 
class="ecrm-1000">0.352    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-17-7"  
class="td11">    <span 
class="ecrm-1000">0.501       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-18-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-18-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 50%                                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-18-2"  
class="td11">    <span 
class="ecrm-1000">640M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-18-3"  
class="td11">   <span 
class="ecrm-1000">0.546     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-18-4"  
class="td11">   <span 
class="ecrm-1000">0.450     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-18-5"  
class="td11">  <span 
class="ecrm-1000">0.504   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-18-6"  
class="td11">   <span 
class="ecrm-1000">0.353    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-18-7"  
class="td11">    <span 
class="ecrm-1000">0.494       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-19-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-19-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3 + English filter                            </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-19-2"  
class="td11">   <span 
class="ecrm-1000">94.3M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-19-3"  
class="td11">   <span 
class="ecrm-1000">0.553     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-19-4"  
class="td11">   <span 
class="ecrm-1000">0.447     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-19-5"  
class="td11">  <span 
class="ecrm-1000">0.511   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-19-6"  
class="td11">   <span 
class="ecrm-1000">0.351    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-19-7"  
class="td11">    <span 
class="ecrm-1000">0.491       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-20-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-20-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.28 + English filter                          </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-20-2"  
class="td11">    <span 
class="ecrm-1000">130M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-20-3"  
class="td11">   <span 
class="ecrm-1000">0.553     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-20-4"  
class="td11">   <span 
class="ecrm-1000">0.453     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-20-5"  
class="td11">  <span 
class="ecrm-1000">0.510   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-20-6"  
class="td11">   <span 
class="ecrm-1000">0.365    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-20-7"  
class="td11">    <span 
class="ecrm-1000">0.491       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-21-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-21-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.3                                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-21-2"  
class="td11">    <span 
class="ecrm-1000">258M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-21-3"  
class="td11">   <span 
class="ecrm-1000">0.579     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-21-4"  
class="td11">   <span 
class="ecrm-1000">0.464     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-21-5"  
class="td11">  <span 
class="ecrm-1000">0.501   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-21-6"  
class="td11">   <span 
class="ecrm-1000">0.338    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-21-7"  
class="td11">    <span 
class="ecrm-1000">0.495       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-22-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-22-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 10%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-22-2"  
class="td11">    <span 
class="ecrm-1000">128M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-22-3"  
class="td11">   <span 
class="ecrm-1000">0.528     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-22-4"  
class="td11">   <span 
class="ecrm-1000">0.444     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-22-5"  
class="td11">  <span 
class="ecrm-1000">0.482   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-22-6"  
class="td11">   <span 
class="ecrm-1000">0.293    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-22-7"  
class="td11">    <span 
class="ecrm-1000">0.477       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-23-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-23-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 20%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-23-2"  
class="td11">    <span 
class="ecrm-1000">257M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-23-3"  
class="td11">   <span 
class="ecrm-1000">0.570     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-23-4"  
class="td11">   <span 
class="ecrm-1000">0.466     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-23-5"  
class="td11">  <span 
class="ecrm-1000">0.524   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-23-6"  
class="td11">   <span 
class="ecrm-1000">0.331    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-23-7"  
class="td11">    <span 
class="ecrm-1000">0.511       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-24-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-24-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 30%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-24-2"  
class="td11">    <span 
class="ecrm-1000">384M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-24-3"  
class="td11">   <span 
class="ecrm-1000">0.578     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-24-4"  
class="td11">   <span 
class="ecrm-1000">0.474     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-24-5"  
class="td11">  <span 
class="ecrm-1000">0.538   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-24-6"  
class="td11">   <span 
class="ecrm-1000">0.342    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-24-7"  
class="td11">    <span 
class="ecrm-1000">0.520       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-25-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-25-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 40%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-25-2"  
class="td11">    <span 
class="ecrm-1000">512M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-25-3"  
class="td11">   <span 
class="ecrm-1000">0.564     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-25-4"  
class="td11">   <span 
class="ecrm-1000">0.462     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-25-5"  
class="td11">  <span 
class="ecrm-1000">0.533   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-25-6"  
class="td11">   <span 
class="ecrm-1000">0.346    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-25-7"  
class="td11">    <span 
class="ecrm-1000">0.520       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-26-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-26-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 50%                                                    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-26-2"  
class="td11">    <span 
class="ecrm-1000">641M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-26-3"  
class="td11">   <span 
class="ecrm-1000">0.548     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-26-4"  
class="td11">   <span 
class="ecrm-1000">0.455     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-26-5"  
class="td11">  <span 
class="ecrm-1000">0.539   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-26-6"  
class="td11">   <span 
class="ecrm-1000">0.345    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-26-7"  
class="td11">    <span 
class="ecrm-1000">0.518       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-27-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-27-1"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet1k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-27-2"  
class="td11">    <span 
class="ecrm-1000">294M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-27-3"  
class="td11">   <span 
class="ecrm-1000">0.572     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-27-4"  
class="td11">   <span 
class="ecrm-1000">0.454     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-27-5"  
class="td11">  <span 
class="ecrm-1000">0.483   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-27-6"  
class="td11">   <span 
class="ecrm-1000">0.353    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-27-7"  
class="td11">    <span 
class="ecrm-1000">0.471       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-28-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-28-1"  
class="td11"> <span 
class="ecrm-1000">Image-based clustering (ImageNet21k)                                 </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-28-2"  
class="td11">    <span 
class="ecrm-1000">450M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-28-3"  
class="td11">   <span 
class="ecrm-1000">0.527     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-28-4"  
class="td11">   <span 
class="ecrm-1000">0.433     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-28-5"  
class="td11">  <span 
class="ecrm-1000">0.468   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-28-6"  
class="td11">   <span 
class="ecrm-1000">0.337    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-28-7"  
class="td11">    <span 
class="ecrm-1000">0.461       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-29-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-29-1"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet1k)                                     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-29-2"  
class="td11">   <span 
class="ecrm-1000">42.7M     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-29-3"  
class="td11">   <span 
class="ecrm-1000">0.419     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-29-4"  
class="td11">   <span 
class="ecrm-1000">0.355     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-29-5"  
class="td11">  <span 
class="ecrm-1000">0.340   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-29-6"  
class="td11">   <span 
class="ecrm-1000">0.210    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-29-7"  
class="td11">    <span 
class="ecrm-1000">0.353       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-30-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-30-1"  
class="td11"> <span 
class="ecrm-1000">Text-based clustering (ImageNet21k)                                   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-30-2"  
class="td11">    <span 
class="ecrm-1000">317M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-30-3"  
class="td11">   <span 
class="ecrm-1000">0.561     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-30-4"  
class="td11">   <span 
class="ecrm-1000">0.465     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-30-5"  
class="td11">  <span 
class="ecrm-1000">0.465   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-30-6"  
class="td11">   <span 
class="ecrm-1000">0.352    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-30-7"  
class="td11">    <span 
class="ecrm-1000">0.466       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-31-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-31-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP B32 score top 30%   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-31-2"  
class="td11">    <span 
class="ecrm-1000">143M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-31-3"  
class="td11">   <span 
class="ecrm-1000">0.632     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-31-4"  
class="td11">   <span 
class="ecrm-1000">0.498     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-31-5"  
class="td11">  <span 
class="ecrm-1000">0.525   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-31-6"  
class="td11">   <span 
class="ecrm-1000">0.371    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-31-7"  
class="td11">    <span 
class="ecrm-1000">0.517       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-32-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-32-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP L14 score top 30%    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-32-2"  
class="td11">    <span 
class="ecrm-1000">140M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-32-3"  
class="td11">   <span 
class="ecrm-1000">0.631     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-32-4"  
class="td11">   <span 
class="ecrm-1000">0.508     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-32-5"  
class="td11">  <span 
class="ecrm-1000">0.546   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-32-6"  
class="td11">   <span 
class="ecrm-1000">0.369    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-32-7"  
class="td11">    <span 
class="ecrm-1000">0.527       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-33-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-33-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP B32 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-33-2"  
class="td11">    <span 
class="ecrm-1000">211M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-33-3"  
class="td11">   <span 
class="ecrm-1000">0.605     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-33-4"  
class="td11">   <span 
class="ecrm-1000">0.481     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-33-5"  
class="td11">  <span 
class="ecrm-1000">0.531   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-33-6"  
class="td11">   <span 
class="ecrm-1000">0.363    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-33-7"  
class="td11">    <span 
class="ecrm-1000">0.509       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-34-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-34-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN21k image clustering and CLIP L14 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-34-2"  
class="td11">    <span 
class="ecrm-1000">208M      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-34-3"  
class="td11">   <span 
class="ecrm-1000">0.506     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-34-4"  
class="td11">   <span 
class="ecrm-1000">0.416     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-34-5"  
class="td11">  <span 
class="ecrm-1000">0.466   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-34-6"  
class="td11">   <span 
class="ecrm-1000">0.300    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-34-7"  
class="td11">    <span 
class="ecrm-1000">0.461       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-35-"><td  style="white-space:nowrap; text-align:left;" id="TBL-26-35-1"  
class="td11">                                                      </td></tr></table>                                                                            </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<!--l. 1315--><p class="noindent" ><a 
 id="x1-110021r24"></a><hr class="float"><div class="float" 
>
                                                                                         
                                                                                         
<a 
 id="x1-110022"></a>
<br /> <div class="caption" 
><span class="id">Table&#x00A0;24: </span><span  
class="content">Baseline results for the filtering track, <span 
class="ectt-1000">xlarge </span>scale.</span></div><!--tex4ht:label?: x1-110021rQ -->
<!--l. 1320--><p class="noindent" > <!--tex4ht:inline--><div class="tabular"> <table id="TBL-27" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-27-1g"><col 
id="TBL-27-1"><col 
id="TBL-27-2"><col 
id="TBL-27-3"><col 
id="TBL-27-4"><col 
id="TBL-27-5"><col 
id="TBL-27-6"><col 
id="TBL-27-7"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-27-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-1-1"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Filtering</span></div>                                                                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-2"  
class="td11">  <span 
class="ecrm-1000">Training    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-3"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">ImageNet</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-4"  
class="td11"> <span 
class="ecrm-1000">ImageNet  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-5"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">VTAB</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-6"  
class="td11"> <div class="multirow"><!-- rows=0 -->
<span 
class="ecrm-1000">Retrieval</span></div>  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-7"  
class="td11"> <span 
class="ecrm-1000">Average over  </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-2-1"  
class="td11">                                                     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-2"  
class="td11"> <span 
class="ecrm-1000">dataset size  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-3"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-4"  
class="td11"> <span 
class="ecrm-1000">dist. shifts  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-5"  
class="td11">        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-6"  
class="td11">          </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-7"  
class="td11">  <span 
class="ecrm-1000">38 datasets   </span></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-27-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-3-1"  
class="td11"> <span 
class="ecrm-1000">No filtering </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-27-3-2"  
class="td11"> <span 
class="ecrm-1000">12.8B </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-27-3-3"  
class="td11"> <span 
class="ecrm-1000">0.723 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-27-3-4"  
class="td11"> <span 
class="ecrm-1000">0.612 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-27-3-5"  
class="td11"> <span 
class="ecrm-1000">0.611 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-27-3-6"  
class="td11"> <span 
class="ecrm-1000">0.441 </span></td> <td  style="white-space:nowrap; text-align:center;" id="TBL-27-3-7"  
class="td11"> <span 
class="ecrm-1000">0.611</span></td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-4-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 score top 30%                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-4-2"  
class="td11">    <span 
class="ecrm-1000">3.84B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-4-3"  
class="td11">   <span 
class="ecrm-1000">0.764     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-4-4"  
class="td11">   <span 
class="ecrm-1000">0.640     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-4-5"  
class="td11">  <span 
class="ecrm-1000">0.628   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-4-6"  
class="td11">   <span 
class="ecrm-1000">0.474    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-4-7"  
class="td11">    <span 
class="ecrm-1000">0.628       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-5-1"  
class="td11"> <span 
class="ecrm-1000">CLIP B32 threshold at 0.28 + English filter                        </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-5-2"  
class="td11">    <span 
class="ecrm-1000">1.3B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-5-3"  
class="td11">   <span 
class="ecrm-1000">0.755     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-5-4"  
class="td11">   <span 
class="ecrm-1000">0.637     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-5-5"  
class="td11">  <span 
class="ecrm-1000">0.624   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-5-6"  
class="td11">   <span 
class="ecrm-1000">0.503    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-5-7"  
class="td11">    <span 
class="ecrm-1000">0.627       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-6-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 20%                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-6-2"  
class="td11">    <span 
class="ecrm-1000">2.56B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-6-3"  
class="td11">   <span 
class="ecrm-1000">0.761     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-6-4"  
class="td11">   <span 
class="ecrm-1000">0.649     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-6-5"  
class="td11">  <span 
class="ecrm-1000">0.630   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-6-6"  
class="td11">   <span 
class="ecrm-1000">0.452    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-6-7"  
class="td11">    <span 
class="ecrm-1000">0.626       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-7-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 25%                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-7-2"  
class="td11">    <span 
class="ecrm-1000">3.2B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-7-3"  
class="td11">   <span 
class="ecrm-1000">0.768     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-7-4"  
class="td11">   <span 
class="ecrm-1000">0.656     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-7-5"  
class="td11">  <span 
class="ecrm-1000">0.621   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-7-6"  
class="td11">   <span 
class="ecrm-1000">0.465    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-7-7"  
class="td11">    <span 
class="ecrm-1000">0.628       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-8-1"  
class="td11"> <span 
class="ecrm-1000">CLIP L14 score top 30%                                                  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-8-2"  
class="td11">    <span 
class="ecrm-1000">3.84B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-8-3"  
class="td11">   <span 
class="ecrm-1000">0.764     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-8-4"  
class="td11">   <span 
class="ecrm-1000">0.655     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-8-5"  
class="td11">  <span 
class="ecrm-1000">0.643   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-8-6"  
class="td11">   <span 
class="ecrm-1000">0.468    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-8-7"  
class="td11">    <span 
class="ecrm-1000">0.641       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-9-1"  
class="td11"> <span 
class="ecrm-1000">Intersect IN1k image clustering and CLIP L14 score top 30%  </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-9-2"  
class="td11">    <span 
class="ecrm-1000">1.38B      </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-9-3"  
class="td11">   <span 
class="ecrm-1000">0.792     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-9-4"  
class="td11">   <span 
class="ecrm-1000">0.679     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-9-5"  
class="td11">  <span 
class="ecrm-1000">0.652   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-9-6"  
class="td11">   <span 
class="ecrm-1000">0.489    </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-9-7"  
class="td11">    <span 
class="ecrm-1000">0.653       </span></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-27-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-27-10-1"  
class="td11">                                                     </td></tr></table>                                                                            </div>
                                                                                         
                                                                                         
</div><hr class="endfloat" />
                                                                                         
                                                                                         
<h3 class="sectionHead"><span class="titlemark">R   </span> <a 
 id="x1-111000R"></a>Datasheet</h3>
<!--l. 3--><p class="noindent" >
          <h4 class="subsectionHead"><span class="titlemark">R.1   </span> <a 
 id="x1-112000R.1"></a>Motivation</h4> <span 
class="ecbx-1095">For what purpose was the dataset created? </span>Was there a specific
          task  in  mind?  Was  there  a  specific  gap  that  needed  to  be  filled?  Please  provide  a
          description.
          <dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
  Q1    <span 
class="tcrm-1095">&#8226;</span> </dt><dd 
class="enumerate-enumitem">The purpose of <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>and the associated <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>dataset is to enable study
          of what makes a strong image-text dataset, which supports a broad range of applications.
          Prior work mainly focuses on data curation in the context of supervised datasets and
          smaller scales. For a fuller treatment see Section&#x00A0;<a 
href="#x1-20002">2<!--tex4ht:ref: sec:relatedwork --></a>. In our initial release of <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>
          we focus on 38 downstream image classification and image retrieval tasks. We additionally
          explore two fairness datasets. For details see Section <a 
href="#x1-190003.5">3.5<!--tex4ht:ref: sec:evaluation --></a> and Appendix <a 
href="#x1-91000N">N<!--tex4ht:ref: sec:app-eval --></a>.
     </dd><dt class="enumerate-enumitem">
  Q2 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Who created the dataset (e.g., which team, research group) and on behalf of which</span>
     <span 
class="ecbx-1095">entity (e.g., company, institution, organization)?</span>
          <ul class="itemize1">
          <li class="itemize"><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span>  </span>and  <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span>  </span>were  created  by  a  group  of  researchers  with  the
          following affiliations, listed in alphabetical order: Allen Institute for Artificial Intelligence
          (AI2), Apple, Columbia University, Graz University of Technology, Hebrew University,
          Juelich Supercomputing Center, LAION, Research Center Juelich, StabilityAI, Tel Aviv
          University,  University  of  Illinois  Urbana-Champaign,  University  of  Texas  at  Austin,
          University of Washington.</li></ul>
     </dd><dt class="enumerate-enumitem">
  Q3 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Who funded the creation of the dataset? </span>If there is an associated grant, please provide the
     name of the grantor and the grant name and number.
          <ul class="itemize1">
          <li class="itemize">Compute for this research was generously provided by StabilityAI. For more specific
          acknowledgments, see the acknowledgment section at the end of the main paper.</li></ul>
     </dd><dt class="enumerate-enumitem">
  Q4 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
                                                                                         
                                                                                         
     <!--l. 30--><p class="noindent" >
     <h4 class="subsectionHead"><span class="titlemark">R.2   </span> <a 
 id="x1-113000R.2"></a>Composition</h4>
     </dd><dt class="enumerate-enumitem">
  Q5 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">What do the instances that comprise the dataset represent (e.g., documents,</span>
     <span 
class="ecbx-1095">photos, people, countries)? </span><span 
class="ecti-1095">Are there multiple types of instances (e.g., movies, users,</span>
     <span 
class="ecti-1095">and ratings; people and interactions between them; nodes and edges)? Please provide a</span>
     <span 
class="ecti-1095">description.</span>
          <ul class="itemize1">
          <li class="itemize">Each instance is a pair of url and corresponding image alt-text. The url points to an
          image that a user can then try to download. Each sample is also tagged with metadata,
          discussed in Q25.</li></ul>
     </dd><dt class="enumerate-enumitem">
  Q6 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">How many instances are there in total (of each type, if appropriate)?</span>
          <ul class="itemize1">
          <li class="itemize">There are 12.8B instances in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. For breakdowns and statistics see Appendix
          <a 
href="#x1-86000I">I<!--tex4ht:ref: app:pool-stats --></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
  Q7 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset contain all possible instances or is it a sample (not necessarily</span>
     <span 
class="ecbx-1095">random) of instances from a larger set? </span><span 
class="ecti-1095">If the dataset is a sample, then what is the larger set?</span>
     <span 
class="ecti-1095">Is the sample representative of the larger set (e.g., geographic coverage)? If so, please describe how</span>
     <span 
class="ecti-1095">this representativeness was validated/verified. If it is not representative of the larger set, please</span>
     <span 
class="ecti-1095">describe why not (e.g., to cover a more diverse range of instances, because instances were withheld or</span>
     <span 
class="ecti-1095">unavailable).</span>
          <ul class="itemize1">
          <li class="itemize">We find <span 
class="cmsy-10x-x-109">~</span>88B possible samples in common crawl. These samples are globally shuffled to
          ensure i.i.d. sampling for all sampling based parts of the downstream pipeline. Of these
          samples we attempt to download <span 
class="cmsy-10x-x-109">~</span>40B samples. Due to various download issues, such
          as dead links and throttling, we are able to successfully download <span 
class="cmsy-10x-x-109">~</span>16.8B samples. After
          NSFW filtering and evaluation set deduplication we end up with <span 
class="cmsy-10x-x-109">~</span>13.1B viable samples,
          from which we randomly sample 12.8B for <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. For a complete treatment
          and visualization of our data processing funnel, see Appendix <a 
href="#x1-85000H">H<!--tex4ht:ref: app:metadata --></a>. For each sample we also
          release metadata shown in Table <a 
href="#x1-85001r9">9<!--tex4ht:ref: tab:app_metadata --></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
  Q8 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">What data does each instance consist of? </span><span 
class="ecti-1095">&#8220;Raw&#8221; data (e.g., unprocessed text or images) or</span>
     <span 
class="ecti-1095">features? In either case, please provide a description.</span>
                                                                                         
                                                                                         
          <ul class="itemize1">
          <li class="itemize">Each sample contains an image url for download and an associated alt-text caption.
          Additionally, each sample contains metadata fields shown in Table <a 
href="#x1-85001r9">9<!--tex4ht:ref: tab:app_metadata --></a> (e.g., image aspect
          ratio and CLIP features).</li></ul>
     </dd><dt class="enumerate-enumitem">
  Q9 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is there a label or target associated with each instance? </span><span 
class="ecti-1095">If so, please provide a</span>
     <span 
class="ecti-1095">description.</span>
          <ul class="itemize1">
          <li class="itemize">We do not provide any category labels; however, the text associated with each image
          can  be  considered  a  soft,  noisy  label  for  each  sample.  Such  labels  are  common  in
          modern image-text training paradigms (e.g., image-text representation alignment, image
          captioning objectives, text-conditional image generation objectives, etc.).</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q10 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is any information missing from individual instances? </span><span 
class="ecti-1095">If so, please provide a</span>
     <span 
class="ecti-1095">description, explaining why this information is missing (e.g., because it was unavailable). This</span>
     <span 
class="ecti-1095">does not include intentionally removed information, but might include, e.g., redacted</span>
     <span 
class="ecti-1095">text.</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q11 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Are relationships between individual instances made explicit (e.g., users&#8217; movie</span>
     <span 
class="ecbx-1095">ratings, social network links)? </span><span 
class="ecti-1095">If so, please describe how these relationships are made</span>
     <span 
class="ecti-1095">explicit.</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q12 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Are there recommended data splits (e.g., training, development/validation,</span>
     <span 
class="ecbx-1095">testing)? </span><span 
class="ecti-1095">If so, please provide a description of these splits, explaining the rationale behind</span>
     <span 
class="ecti-1095">them.</span>
          <ul class="itemize1">
          <li class="itemize">No. The test tasks are existing image classification tasks. We run a deduplication model
          to try to prevent test set contamination in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q13 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Are there any errors, sources of noise, or redundancies in the dataset? </span><span 
class="ecti-1095">If so, please provide</span>
     <span 
class="ecti-1095">a description.</span>
                                                                                         
                                                                                         
          <ul class="itemize1">
          <li class="itemize"><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is sourced from Common Crawl, which can be thought of as a snapshot
          of the internet. Hence, there can be considerable noise (e.g., alt-text being unrelated to
          its associated image), duplicate data, etc.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q14 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is the dataset self-contained, or does it link to or otherwise rely on external resources</span>
     <span 
class="ecbx-1095">(e.g., websites, tweets, other datasets)? </span><span 
class="ecti-1095">If it links to or relies on external resources, a) are there</span>
     <span 
class="ecti-1095">guarantees that they will exist, and remain constant, over time; b) are there official archival versions</span>
     <span 
class="ecti-1095">of the complete dataset (i.e., including the external resources as they existed at the time the dataset</span>
     <span 
class="ecti-1095">was created); c) are there any restrictions (e.g., licenses, fees) associated with any of the external</span>
     <span 
class="ecti-1095">resources that might apply to a future user? Please provide descriptions of all external resources</span>
     <span 
class="ecti-1095">and any restrictions associated with them, as well as links or other access points, as</span>
     <span 
class="ecti-1095">appropriate.</span>
          <ul class="itemize1">
          <li class="itemize">The data is not self-contained and rather links other external resources on the internet.
          Links point to resources distributed across the internet. There is no guarantee that the
          resources will exist in perpetuity or that that the resources will not change. To mitigate
          against data poisoning in future <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>downloads, we release SHA256 hashes
          of images. Due to the size of the dataset, it is not possible to provide it in an archival
          form.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q15 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset contain data that might be considered confidential (e.g., data that is</span>
     <span 
class="ecbx-1095">protected by legal privilege or by doctor&#8211;patient confidentiality, data that includes</span>
     <span 
class="ecbx-1095">the content of individuals&#8217; non-public communications)? </span><span 
class="ecti-1095">If so, please provide a</span>
     <span 
class="ecti-1095">description.</span>
          <ul class="itemize1">
          <li class="itemize">The dataset is comprised of data that was readily available on the internet at the time of
          our download. However, it is possible that the dataset contains confidential information
          (e.g., private data that is hosted publicly for nefarious reasons or out of ignorance of said
          data being confidential).</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q16 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset contain data that, if viewed directly, might be offensive,</span>
     <span 
class="ecbx-1095">insulting, threatening, or might otherwise cause anxiety? </span><span 
class="ecti-1095">If so, please describe</span>
     <span 
class="ecti-1095">why.</span>
          <ul class="itemize1">
          <li class="itemize">Considering the plurality of people and their backgrounds across the world, it is highly
                                                                                         
                                                                                         
          likely that there is content in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>that may upset people. Common Crawl
          scrapes  the  internet,  which  has  pornographic,  hateful,  racist,  sexist,  and  otherwise
          abhorrent and toxic material. While we attempt to do thorough NSFW filtering, these
          methods are not 100% accurate. At the 12.8B scale at which we operate it is highly likely
          that there is still toxic content in the dataset. We consider the dataset as a research
          artifact and hope future work will look critically at <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>in the hopes of
          developing even better safety filters.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q17 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset relate to people? </span><span 
class="ecti-1095">If not, you may skip the remaining questions in this</span>
     <span 
class="ecti-1095">section.</span>
          <ul class="itemize1">
          <li class="itemize">People  may  appear  in  the  dataset;  however,  in  an  effort  to  preserve  privacy,  our
          downloading tooling automatically blurs all detected faces in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>images.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q18 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset identify any subpopulations (e.g., by age, gender)?</span>
          <ul class="itemize1">
          <li class="itemize">While <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>does not explicitly identify subpopulations in its metadata, it is
          plausible to extract such information for some images using the corresponding textual
          caption.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q19 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is it possible to identify individuals (i.e., one or more natural persons), either directly</span>
     <span 
class="ecbx-1095">or indirectly (i.e., in combination with other data) from the dataset? </span><span 
class="ecti-1095">If so, please describe</span>
     <span 
class="ecti-1095">how.</span>
          <ul class="itemize1">
          <li class="itemize">We conjecture that even with our face blurring procedure, it may still be possible to
          identify individuals. Face blurring relies of a face detection model, which could fail (See
          Appendix <a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a> for experimental validation of the employed detector). It is also possible
          to  identify  certain  celebrities  or  athletes,  who  may  wear  distinctive  clothing  that  is
          associated with them. It is also likely that names are contained in textual captions,
          though it is not guaranteed that these names correspond to people in images due to the
          inherent noisiness of internet captions.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q20 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset contain data that might be considered sensitive in any way (e.g., data</span>
     <span 
class="ecbx-1095">that reveals racial or ethnic origins, sexual orientations, religious beliefs, political</span>
     <span 
class="ecbx-1095">opinions or union memberships, or locations; financial or health data; biometric or</span>
     <span 
class="ecbx-1095">genetic data; forms of government identification, such as social security numbers;</span>
     <span 
class="ecbx-1095">criminal history)? </span><span 
class="ecti-1095">If so, please provide a description.</span>
                                                                                         
                                                                                         
          <ul class="itemize1">
          <li class="itemize">Yes. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is created using images and corresponding alt-text that are available
          on the public internet. Given the 12.8B scale of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>, it is highly likely that
          there is sensitive data in the dataset. To mitigate against making sensitive content more
          accessible, we 1) run NSFW image filtering and 2) NSFW text filtering when generating
          <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>,  discarding  all  samples  that  are  flagged.  Additionally  we  3)  provide
          automatic face blurring in our <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>download scripts to blur all detected faces.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q21 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     <!--l. 135--><p class="noindent" >
     <h4 class="subsectionHead"><span class="titlemark">R.3   </span> <a 
 id="x1-114000R.3"></a>Collection Process</h4>
     </dd><dt class="enumerate-enumitem">
 Q22 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">How was the data associated with each instance acquired? </span><span 
class="ecti-1095">Was the data directly observable</span>
     <span 
class="ecti-1095">(e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or indirectly</span>
     <span 
class="ecti-1095">inferred/derived from other data (e.g., part-of-speech tags, model-based guesses for age or language)?</span>
     <span 
class="ecti-1095">If data was reported by subjects or indirectly inferred/derived from other data, was the data</span>
     <span 
class="ecti-1095">validated/verified? If so, please describe how.</span>
          <ul class="itemize1">
          <li class="itemize">Data is directly downloaded from the public internet.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q23 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">What mechanisms or procedures were used to collect the data (e.g., hardware</span>
     <span 
class="ecbx-1095">apparatus or sensor, manual human curation, software program, software API)? </span><span 
class="ecti-1095">How</span>
     <span 
class="ecti-1095">were these mechanisms or procedures validated?</span>
          <ul class="itemize1">
          <li class="itemize">We iterate on the LAION-5B data collection process, making an effort to emphasize
          safety. We ran python based processing scripts to parse Common Crawl dumps, download
          images, filter our NSFW content, deduplicate samples against downstream tests sets,
          blur faces, and compute CLIP features. We ran processes on 100s of AWS CPU nodes for
          Common Crawl parsing and data download. Other steps were run on one of StabilityAI&#8217;s
          GPU cluster. For software links see Q37. For software validation related to NSFW content
          filtering and face blurring see Appendices <a 
href="#x1-82000E">E<!--tex4ht:ref: app:nsfw --></a> and <a 
href="#x1-84000G">G<!--tex4ht:ref: app:face --></a> respectively. In brief, for NSFW image
                                                                                         
                                                                                         
          filtering, we validate against commercial APIs and on the NSFW test set introduced in
          LAION-5B. For face detection (used for face blurring), we evaluate against commercial
          APIs and on the FairFace dataset. We find strong performance for both modules.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q24 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">If the dataset is a sample from a larger set, what was the sampling strategy (e.g.,</span>
     <span 
class="ecbx-1095">deterministic, probabilistic with specific sampling probabilities)?</span>
          <ul class="itemize1">
          <li class="itemize">See Q7.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q25 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Who was involved in the data collection process (e.g., students, crowdworkers,</span>
     <span 
class="ecbx-1095">contractors) and how were they compensated (e.g., how much were crowdworkers</span>
     <span 
class="ecbx-1095">paid)?</span>
          <ul class="itemize1">
          <li class="itemize">The researching authors were involved in the data collection as an open source effort. No
          researchers were compensated specifically for their involvement in this project.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q26 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Over what timeframe was the data collected? Does this timeframe match the creation</span>
     <span 
class="ecbx-1095">timeframe of the data associated with the instances (e.g., recent crawl of old news</span>
     <span 
class="ecbx-1095">articles)? </span><span 
class="ecti-1095">If not, please describe the timeframe in which the data associated with the instances was</span>
     <span 
class="ecti-1095">created.</span>
          <ul class="itemize1">
          <li class="itemize">Data was downloaded between December 2022 and March 2023. The urls are collected
          from Common Crawl dumps between 2014 and 2022. Common Crawl dumps may include
          urls from the early days of the internet. Hence, the download/collection timeframe does
          not match the creation timeframe. Additionally, future users of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>and its
          subsets will have to download data themselves using our tooling.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q27 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Were any ethical review processes conducted (e.g., by an institutional review board)? </span><span 
class="ecti-1095">If</span>
     <span 
class="ecti-1095">so, please provide a description of these review processes, including the outcomes, as well as a link or</span>
     <span 
class="ecti-1095">other access point to any supporting documentation.</span>
          <ul class="itemize1">
          <li class="itemize">Our dataset collection process iterates on the LAION-5B process, which found IRB review
          was not necessary as they &#8220;do not intervene with the people depicted in the data as
          well as the data being public." Additionally, the NeurIPS ethics review found no serious
          ethical issues with LAION-5B. We take even more stringent safety measures than the
                                                                                         
                                                                                         
          original LAION-5B dataset, in that we filter out data that is flagged as NSFW by our
          detection pipeline and blur detected faces in <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>in our download scripts. All
          this being said, a formal ethics review has not been conducted to date.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q28 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Does the dataset relate to people? </span><span 
class="ecti-1095">If not, you may skip the remaining questions in this</span>
     <span 
class="ecti-1095">section.</span>
          <ul class="itemize1">
          <li class="itemize">Yes. People may appear in the dataset. Detected faces are blurred when downloading
          <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>with our tooling.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q29 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Did you collect the data from the individuals in question directly, or obtain it via third</span>
     <span 
class="ecbx-1095">parties or other sources (e.g., websites)?</span>
          <ul class="itemize1">
          <li class="itemize">We collect data from websites across the internet.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q30 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Were the individuals in question notified about the data collection? </span><span 
class="ecti-1095">If so, please describe</span>
     <span 
class="ecti-1095">(or show with screenshots or other information) how notice was provided, and provide a link</span>
     <span 
class="ecti-1095">or other access point to, or otherwise reproduce, the exact language of the notification</span>
     <span 
class="ecti-1095">itself.</span>
          <ul class="itemize1">
          <li class="itemize">Individuals were not notified about the data collection.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q31 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Did the individuals in question consent to the collection and use of their data? </span><span 
class="ecti-1095">If so,</span>
     <span 
class="ecti-1095">please describe (or show with screenshots or other information) how consent was requested and</span>
     <span 
class="ecti-1095">provided, and provide a link or other access point to, or otherwise reproduce, the exact language to</span>
     <span 
class="ecti-1095">which the individuals consented.</span>
          <ul class="itemize1">
          <li class="itemize">Following our usage of Common Crawl and <a 
href="https://github.com/rom1504/img2dataset" class="url" ><span 
class="ectt-1095">https://github.com/rom1504/img2dataset</span></a>
          for download images, we respect <span 
class="ectt-1095">robots.txt </span>files, which specify parts of websites that a
          crawler may access. It is, however, possible that images of people, medical images, etc.
          were uploaded to the internet without a person&#8217;s consent. To mitigate against such safety
          concerns we make an effort to do rigorous NSFW filtering and blur all detected faces
          automatically in our download tooling.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q32 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">If consent was obtained, were the consenting individuals provided with a</span>
                                                                                         
                                                                                         
     <span 
class="ecbx-1095">mechanism to revoke their consent in the future or for certain uses? </span><span 
class="ecti-1095">If so,</span>
     <span 
class="ecti-1095">please provide a description, as well as a link or other access point to the mechanism (if</span>
     <span 
class="ecti-1095">appropriate).</span>
          <ul class="itemize1">
          <li class="itemize">In conjunction with LAION, we use <a 
href="https://laion.ai/dataset-requests/" class="url" ><span 
class="ectt-1095">https://laion.ai/dataset-requests/</span></a> to monitor
          user takedown requests. We will also make an effort to provide a user with the url at
          which their sensitive content is hosted&#8212;if they do not have this information already&#8212;,
          so they can take further action as they see fit (e.g., contacting the host to request that
          the content is taken down from the internet).</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q33 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Has an analysis of the potential impact of the dataset and its use on data subjects (e.g.,</span>
     <span 
class="ecbx-1095">a data protection impact analysis) been conducted? </span><span 
class="ecti-1095">If so, please provide a description of this</span>
     <span 
class="ecti-1095">analysis, including the outcomes, as well as a link or other access point to any supporting</span>
     <span 
class="ecti-1095">documentation.</span>
          <ul class="itemize1">
          <li class="itemize">We conduct a fairness evaluation on models trained on <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>and its derivative.
          See  Appendix  <a 
href="#x1-107000P">P<!--tex4ht:ref: app:fairness --></a>  for  details.  Birhane  et&#x00A0;al.&#x00A0;[<a 
href="#XBirhane2021MultimodalDM">11</a>]  conduct  an  extensive  study  in  the
          context of LAION-400M, which is an image-text dataset also sourced from Common
          Crawl, finding a plethora of dangerous and unsafe content. Our dataset differs from
          LAION-400M in that we conduct NSFW preprocessing and face blurring for detected
          faces. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>only contains samples that pass our NSFW safety checks and our
          download tooling automatically blurs detected faces. However, since <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is
          created from the internet, it is still likely that it contains some harmful data.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q34 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     <!--l. 215--><p class="noindent" >
     <h4 class="subsectionHead"><span class="titlemark">R.4   </span> <a 
 id="x1-115000R.4"></a>Preprocessing, Cleaning, and/or Labeling</h4>
     </dd><dt class="enumerate-enumitem">
 Q35 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or</span>
     <span 
class="ecbx-1095">bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of</span>
     <span 
class="ecbx-1095">instances, processing of missing values)? </span><span 
class="ecti-1095">If so, please provide a description. If not, you may</span>
     <span 
class="ecti-1095">skip the remainder of the questions in this section.</span>
                                                                                         
                                                                                         
          <ul class="itemize1">
          <li class="itemize">Yes. See Q7. For more details see Appendix <a 
href="#x1-85000H">H<!--tex4ht:ref: app:metadata --></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q36 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Was the &#8220;raw&#8221; data saved in addition to the preprocessed/cleaned/labeled data (e.g., to</span>
     <span 
class="ecbx-1095">support unanticipated future uses)? </span><span 
class="ecti-1095">If so, please provide a link or other access point to the</span>
     <span 
class="ecti-1095">&#8220;raw&#8221; data.</span>
          <ul class="itemize1">
          <li class="itemize">Raw data is not available or distributed due to safety considerations. We distribute only
          urls that are in the dataset on HuggingFace&#8212;and not urls of images our preprocessing
          flagged as NSFW.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q37 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is the software used to preprocess/clean/label the instances available? </span><span 
class="ecti-1095">If so, please provide</span>
     <span 
class="ecti-1095">a link or other access point.</span>
          <ul class="itemize1">
          <li class="itemize">We use the following, open-source software to aid in data processing:
              <ul class="itemize2">
              <li class="itemize">Apache Spark: <a 
href="https://spark.apache.org" class="url" ><span 
class="ectt-1095">https://spark.apache.org</span></a>
              </li>
              <li class="itemize">Ray: <a 
href="https://www.ray.io" class="url" ><span 
class="ectt-1095">https://www.ray.io</span></a>
              </li>
              <li class="itemize">img2dataset: <a 
href="https://github.com/rom1504/img2dataset" class="url" ><span 
class="ectt-1095">https://github.com/rom1504/img2dataset</span></a>
              </li>
              <li class="itemize">OpenAI CLIP: <a 
href="https://github.com/openai/CLIP" class="url" ><span 
class="ectt-1095">https://github.com/openai/CLIP</span></a>
              </li>
              <li class="itemize">Near                                       dedulicate                                       detector:
              <a 
href="https://github.com/lyakaap/ISC21-Descriptor-Track-1st" class="url" ><span 
class="ectt-1095">https://github.com/lyakaap/ISC21-Descriptor-Track-1st</span></a>
              </li>
              <li class="itemize">Face detector: <a 
href="https://github.com/deepinsight/insightface" class="url" ><span 
class="ectt-1095">https://github.com/deepinsight/insightface</span></a>
              </li>
              <li class="itemize">Detoxify, for detecting toxic language: <a 
href="https://github.com/unitaryai/detoxify" class="url" ><span 
class="ectt-1095">https://github.com/unitaryai/detoxify</span></a>
              </li>
              <li class="itemize">A     modified     version     of     the     following     NSFW     image     detector:
              <a 
href="https://github.com/LAION-AI/CLIP-based-NSFW-Detector" class="url" ><span 
class="ectt-1095">https://github.com/LAION-AI/CLIP-based-NSFW-Detector</span></a>. Specifically, we use
              the dataset used to train this model to train our own 4-layer MLP classifier.</li></ul>
                                                                                         
                                                                                         
          </li></ul>
     </dd><dt class="enumerate-enumitem">
 Q38 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     <!--l. 253--><p class="noindent" >
     <h4 class="subsectionHead"><span class="titlemark">R.5   </span> <a 
 id="x1-116000R.5"></a>Uses</h4>
     </dd><dt class="enumerate-enumitem">
 Q39 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Has the dataset been used for any tasks already? </span><span 
class="ecti-1095">If so, please provide a description.</span>
          <ul class="itemize1">
          <li class="itemize">The full dataset (and subsets) have been used to train several CLIP models at various
          scales and compute budgets as presented in our main paper. We evaluate these models
          zero-shot on 38 downstream image classification and retrieval tasks. We additionally
          evaluate on 2 fairness datasets. See Section <a 
href="#x1-190003.5">3.5<!--tex4ht:ref: sec:evaluation --></a> and Appendix <a 
href="#x1-91000N">N<!--tex4ht:ref: sec:app-eval --></a> for more details.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q40 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is there a repository that links to any or all papers or systems that use the dataset? </span><span 
class="ecti-1095">If</span>
     <span 
class="ecti-1095">so, please provide a link or other access point.</span>
          <ul class="itemize1">
          <li class="itemize">No. However, there is a leaderboard associated with <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span></span>. Interested parties can
          investigate the submissions and further study publications that make use of our data.
          See: <a 
href="https://www.datacomp.ai/leaderboard.html" class="url" ><span 
class="ectt-1095">https://www.datacomp.ai/leaderboard.html</span></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q41 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">What (other) tasks could the dataset be used for?</span>
          <ul class="itemize1">
          <li class="itemize">The   dataset   could   also   be   used   for   training   image   captioning   models   and
          language-conditional image generation models. Note: generative image models trained on
          <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>are not expected to generate recognizable human faces as our download
          tooling automatically blurs detected faces. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>could be used for sociological
          studies, for example, examining societal biases or to better understand what is on the
          public internet.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q42 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is there anything about the composition of the dataset or the way it was</span>
                                                                                         
                                                                                         
     <span 
class="ecbx-1095">collected and preprocessed/cleaned/labeled that might impact future uses?</span>
     <span 
class="ecti-1095">For example, is there anything that a future user might need to know to avoid uses that</span>
     <span 
class="ecti-1095">could result in unfair treatment of individuals or groups (e.g., stereotyping, quality of</span>
     <span 
class="ecti-1095">service issues) or other undesirable harms (e.g., financial harms, legal risks) If so, please</span>
     <span 
class="ecti-1095">provide a description. Is there anything a future user could do to mitigate these undesirable</span>
     <span 
class="ecti-1095">harms?</span>
          <ul class="itemize1">
          <li class="itemize">In our initial analysis of models trained on <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>and its subsets, we notice
          disproportionate misclassification rates for identifying Black women (see Section <a 
href="#x1-107000P">P<!--tex4ht:ref: app:fairness --></a> for
          more details on our fairness and bias evaluation). <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>and its derivatives are
          not intended for production ready products, including but not limited to those related
          to race, gender identity or expression, ethnicity, sexual orientation, age, socioeconomic
          status, disability, religion, national origin or creed. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is not suitable for
          any software that makes decisions involving people. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is collected from
          the internet and hence reflects many of the biases, unfairness, and stereotypes currently
          existing in our societies.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q43 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Are there tasks for which the dataset should not be used? </span><span 
class="ecti-1095">If so, please provide a</span>
     <span 
class="ecti-1095">description.</span>
          <ul class="itemize1">
          <li class="itemize"><span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>in its current form or the subsets presented in this paper should not be
          used in software that makes decisions related to people. The known biases make deploying
          software, especially widely decimated production-level products, built on <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>
          incredibly irresponsible. <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>is designed as a research artifact for academic
          exploration. We also do not condone the use of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>in surveillance or military
          applications.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q44 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     <!--l. 290--><p class="noindent" >
     <h4 class="subsectionHead"><span class="titlemark">R.6   </span> <a 
 id="x1-117000R.6"></a>Distribution</h4>
     </dd><dt class="enumerate-enumitem">
 Q45 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Will the dataset be distributed to third parties outside of the entity (e.g., company,</span>
     <span 
class="ecbx-1095">institution, organization) on behalf of which the dataset was created? </span><span 
class="ecti-1095">If so, please provide</span>
     <span 
class="ecti-1095">a description.</span>
                                                                                         
                                                                                         
          <ul class="itemize1">
          <li class="itemize">Yes. We use HuggingFace datasets for public release.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q46 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">How will the dataset be distributed (e.g., tarball on website, API, GitHub)? </span><span 
class="ecti-1095">Does the</span>
     <span 
class="ecti-1095">dataset have a digital object identifier (DOI)?</span>
          <ul class="itemize1">
          <li class="itemize">The      dataset      will      be      distributed      via      HuggingFace      datasets      at
          <a 
href="https://huggingface.co/datasets/mlfoundations/datacomp_pools/tree/main" ><a 
href="https://huggingface.co/datasets/mlfoundations/datacomp_pools/tree/main" class="url" ><span 
class="ectt-1095">https://huggingface.co/datasets/mlfoundations/datacomp_pools/tree/main</span></a></a></li></ul>
     </dd><dt class="enumerate-enumitem">
 Q47 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">When will the dataset be distributed?</span>
          <ul class="itemize1">
          <li class="itemize"><span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>will be available starting May 2023.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q48 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Will the dataset be distributed under a copyright or other intellectual property (IP)</span>
     <span 
class="ecbx-1095">license, and/or under applicable terms of use (ToU)? </span><span 
class="ecti-1095">If so, please describe this license and/or</span>
     <span 
class="ecti-1095">ToU, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms</span>
     <span 
class="ecti-1095">or ToU, as well as any fees associated with these restrictions.</span>
          <ul class="itemize1">
          <li class="itemize">We distribute the url-text sample and metadata under a standard CC-BY-4.0 licence.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q49 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Have any third parties imposed IP-based or other restrictions on the data associated</span>
     <span 
class="ecbx-1095">with the instances? </span><span 
class="ecti-1095">If so, please describe these restrictions, and provide a link or other access</span>
     <span 
class="ecti-1095">point to, or otherwise reproduce, any relevant licensing terms, as well as any fees associated with</span>
     <span 
class="ecti-1095">these restrictions.</span>
          <ul class="itemize1">
          <li class="itemize">We do not copyright samples in the dataset.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q50 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Do any export controls or other regulatory restrictions apply to the dataset or to</span>
     <span 
class="ecbx-1095">individual instances? </span><span 
class="ecti-1095">If so, please describe these restrictions, and provide a link or other access</span>
     <span 
class="ecti-1095">point to, or otherwise reproduce, any supporting documentation.</span>
          <ul class="itemize1">
                                                                                         
                                                                                         
          <li class="itemize">No.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q51 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     <!--l. 334--><p class="noindent" >
     <h4 class="subsectionHead"><span class="titlemark">R.7   </span> <a 
 id="x1-118000R.7"></a>Maintenance</h4>
     </dd><dt class="enumerate-enumitem">
 Q52 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Who will be supporting/hosting/maintaining the dataset?</span>
          <ul class="itemize1">
          <li class="itemize">HuggingFace currently hosts the url-text pairs and metadata. The <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>team will
          be responsible for maintaining the dataset.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q53 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">How can the owner/curator/manager of the dataset be contacted (e.g., email</span>
     <span 
class="ecbx-1095">address)?</span>
          <ul class="itemize1">
          <li class="itemize">We can be contacted at <a 
href="contact@datacomp.ai" class="url" ><span 
class="ectt-1095">contact@datacomp.ai</span></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q54 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Is there an erratum? </span><span 
class="ecti-1095">If so, please provide a link or other access point.</span>
          <ul class="itemize1">
          <li class="itemize">Currently there are no errata. If issues are discovered, we will communicate with the
          public via our website <a 
href="https://datacomp.ai" class="url" ><span 
class="ectt-1095">https://datacomp.ai</span></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q55 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete</span>
     <span 
class="ecbx-1095">instances)? </span><span 
class="ecti-1095">If so, please describe how often, by whom, and how updates will be communicated to</span>
     <span 
class="ecti-1095">users (e.g., mailing list, GitHub)?</span>
          <ul class="itemize1">
          <li class="itemize">At the present time there is no intention to update <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>for scientific reasons.
          However,  we  will  respond  to  user  takedown  requests  (see  Q56).  <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span>  </span>is
          inherently  noisy  and  the  purpose  of  releasing  it  is  to  encourage  researchers  in  the
                                                                                         
                                                                                         
          community to study dataset cleaning in the context of image-text samples.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q56 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">If the dataset relates to people, are there applicable limits on the retention of the data</span>
     <span 
class="ecbx-1095">associated with the instances (e.g., were individuals in question told that their data</span>
     <span 
class="ecbx-1095">would be retained for a fixed period of time and then deleted)? </span><span 
class="ecti-1095">If so, please describe these</span>
     <span 
class="ecti-1095">limits and explain how they will be enforced.</span>
          <ul class="itemize1">
          <li class="itemize">We  will  use  the  following  website,  <a 
href=" https://laion.ai/dataset-requests" class="url" ><span 
class="ectt-1095">https://laion.ai/dataset-requests</span></a>,  for  user
          takedown requests, where &#8220;Sample ID&#8221; is the sample uid.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q57 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Will older versions of the dataset continue to be supported/hosted/maintained? </span><span 
class="ecti-1095">If so,</span>
     <span 
class="ecti-1095">please describe how. If not, please describe how its obsolescence will be communicated to</span>
     <span 
class="ecti-1095">users.</span>
          <ul class="itemize1">
          <li class="itemize">This is the first version of <span 
class="eccc1095-"><span 
class="small-caps">d</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">a</span><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">p</span> </span>and the associated <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span> </span>dataset. We
          do not intend to maintain deprecated version of <span 
class="eccc1095-"><span 
class="small-caps">c</span><span 
class="small-caps">o</span><span 
class="small-caps">m</span><span 
class="small-caps">m</span><span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">p</span><span 
class="small-caps">o</span><span 
class="small-caps">o</span><span 
class="small-caps">l</span></span>. We will communicate
          deprication notices through our website: <a 
href="https://datacomp.ai" class="url" ><span 
class="ectt-1095">https://datacomp.ai</span></a>.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q58 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">If others want to extend/augment/build on/contribute to the dataset, is there a</span>
     <span 
class="ecbx-1095">mechanism for them to do so? </span><span 
class="ecti-1095">If so, please provide a description. Will these contributions</span>
     <span 
class="ecti-1095">be validated/verified? If so, please describe how. If not, why not? Is there a process for</span>
     <span 
class="ecti-1095">communicating/distributing these contributions to other users? If so, please provide a</span>
     <span 
class="ecti-1095">description.</span>
          <ul class="itemize1">
          <li class="itemize">All alterations to the dataset will be handled on a case-by-case basis.</li></ul>
     </dd><dt class="enumerate-enumitem">
 Q59 </dt><dd 
class="enumerate-enumitem"><span 
class="ecbx-1095">Any other comments?</span>
          <ul class="itemize1">
          <li class="itemize">No.</li></ul>
     </dd></dl>
 
</body></html> 

                                                                                         
                                                                                         
                                                                                         


